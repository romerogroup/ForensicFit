 1/1: import pyprocar
 1/2: pyprocar.scriptFermi3D?
 1/3: pyprocar.scriptFermi3D??
 1/4: pyprocar.scriptFermi3D('PROCAR-repaired','OUTCAR',bands=-1)
 1/5: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=-1)
 1/6: pyprocar.scriptFermi3D?
 1/7: pyprocar.scriptFermi3D.fermi3D?
 1/8: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89,90,91],mode='plain',scale=4)
 1/9: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89,90,91],mode='parametric',scale=4)
1/10: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88],mode='parametric',scale=4)
1/11: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='parametric',scale=4)
 2/1: import pyprocar
 3/1: import pyprocar
 3/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='parametric',scale=4)
 3/3: pyprocar.__path__
 3/4: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='parametric',scale=4)
 4/1: import pyprocar
 4/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='parametric',scale=4)
 4/3: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='parametric',scale=4)
 4/4: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='parametric',scale=4)
 4/5: pyprocar.scriptFermi3D.fermi3D?
 4/6: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='parametric',scale=4,plotting_package='matplotlib')
 4/7: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4,plotting_package='matplotlib')
 4/8: a = pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4,plotting_package='matplotlib')
 4/9: a
4/10: a
 5/1: import pyprocar
 5/2: import pyprocar
 5/3: import pyprocar
 6/1: import pyprocar
 6/2: import pyprocar
 7/1: import pyprocar
 8/1: import pyprocar
 8/2: pyprocar__path__
 8/3: pyprocar.__path__
 9/1: import pyprocar
 9/2: a = pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4,plotting_package='matplotlib')
10/1: import pyprocar
10/2: a = pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4,plotting_package='matplotlib')
10/3: a
10/4: a.min()
10/5: a.max
11/1: import pyprocar
11/2: import pyprocar
11/3: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4,plotting_package='matplotlib')
12/1: import pyprocar
12/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4,plotting_package='matplotlib')
13/1: import pyprocar
13/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4,plotting_package='matplotlib')
14/1: import pyprocar
14/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4,plotting_package='matplotlib')
14/3: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4,plotting_package='matplotlib')
15/1: import pyprocar
15/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4,plotting_package='matplotlib')
16/1: import pyprocar
16/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4,plotting_package='matplotlib')
17/1: import pyprocar
17/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4,plotting_package='matplotlib')
17/3: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4,plotting_package='mayavi')
17/4: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4)
18/1: import pyprocar
18/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4)
19/1: import pyprocar
19/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4)
20/1: import pyprocar
20/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4)
20/3: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4)
21/1: import pyprocar
21/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4)
22/1: import pyprocar
22/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4)
23/1: import pyprocar
23/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4)
23/3: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4)
24/1: import pyprocar
24/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4)
25/1: import pyprocar
25/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4)
25/3: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[88,89],mode='plain',scale=4)
25/4: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[89],mode='plain',scale=4)
26/1: import ConfigParser
26/2:         from ConfigParser import SafeConfigParser
27/1:         from ConfigParser import SafeConfigParser
28/1:         from ConfigParser import SafeConfigParser
28/2: import configparser
29/1:         from ConfigParser import SafeConfigParser
29/2:         from ConfigParser import SafeConfigParser
29/3:         from configparser import SafeConfigParser
30/1: import pyprocar
30/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[89],mode='plain',scale=4)
30/3: pyprocar.__path__
31/1: import pyprocar
31/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[89],mode='plain',scale=4)
32/1: import pyprocar
32/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[89],mode='plain',scale=4)
33/1: import pyprocar
33/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[89],mode='plain',scale=4)
34/1: import pyprocar
34/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[89],mode='plain',scale=4)
35/1: import pyprocar
35/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[89],mode='plain',scale=4)
36/1: import pyprocar
36/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[89],mode='plain',scale=4)
37/1: import pyprocar
37/2: pyprocar.scriptFermi3D.fermi3D('PROCAR-repaired','OUTCAR',bands=[89],mode='plain',scale=4)
38/1:
from pymatgen import MPRester
import itertools
import string
import pandas as pd
38/2:
def anonymized_formula(formula):
    anon = ""
    for ele,val in  zip(string.ascii_uppercase, sorted(formula.values())):
        if val == 1:
            val_str = ""
        else :
            val_str = str(int(val))
        anon += "{}{}".format(ele,val_str)
    return anon

def search_formula(listOfElements, formula, spg ):
    i = 0
    listOfIndex = []
    for item  in listOfElements:
        if item['formula'] == formula and item['spacegroup.number'] == spg:
            listOfIndex.append(i)
        i += 1
    return  listOfIndex
38/3: mpr =  MPRester("NADK2mefgRatslWT")
38/4: ele3 = mpr.query({"nelements": 3},properties=['spacegroup.number',"formula","material_id",'pretty_formula'],chunk_size=10000)
38/5: ele3
38/6: ele3[0]
38/7: x = ele3[0]
38/8:     anon = anonymized_formula(x['formula'])
38/9: anon
38/10:
        temp = {1:[],3:[]}
        for y in x['formula'] :
            if x['formula'][y] == 3:
                temp[3].append(y)
            elif x['formula'][y] == 1:
                temp[1].append(y)
38/11: temp
38/12: temp[3]
38/13: temp[3]
39/1: from pymatgen import MPRester
39/2: mpr =  MPRester("NADK2mefgRatslWT")
39/3: mpr.get_structure_by_material_id('mp-1225128')
39/4: a = mpr.get_structure_by_material_id('mp-1225128')
39/5: a
39/6: a[0]
39/7: a.sites
39/8: a.sites[0]
39/9: a[0]
39/10: b = a[0]
39/11: b
39/12: b.a
39/13: b.species
39/14: b.species[0]
39/15: b.species
39/16: b.specie
39/17: c = b.specie
39/18: c.average_cationic_radius
39/19: c.common_oxidation_states
39/20: c.row
39/21: c.value
39/22: c.valence
39/23: c.term_symbols
39/24: c.print_periodic_table()
39/25: c.name
39/26: c.is_rare_earth_metal
39/27: c.is_actinoid
39/28: c.is_metal
39/29: c.is_metalloid
39/30: import pymatgen.core.periodic_table
39/31: import pymatgen.core.periodic_table as pt
39/32: pt
39/33: pt.Element
39/34: pt.Element['P']
39/35: pt.Element['P'].is_metal
39/36: pt.Element['Si'].is_metal
39/37: a = pt.Element['Si']
39/38: a.is_metalloid
39/39: a.is_post_transition_metal
39/40: a = pt.Element['O']
39/41: a.is_lanthanoid
39/42: a.is_chalcogen
39/43: a.is_chalcogen
39/44: a.is_halogen
39/45: a.
40/1:
import pychemia
from pymatgen import MPRester
import pandas as pd
import os

mpr =  MPRester("trEVLRi9pmXId5MC")
40/2:
from pymatgen import MPRester
import pandas as pd
import os

mpr =  MPRester("trEVLRi9pmXId5MC")
40/3: _id
40/4: _id = 'mp-1013534'
40/5:     doc = mpr.get_doc(_id)
40/6: doc['input']['kpoints']
40/7: doc['input']['kpoints']['kpoints']
40/8: doc['input']['kpoints']['kpoints'][0]
40/9: doc['input']['kpoints']['kpoints'][0]
41/1: import os
41/2: os.environ["CUDA_DEVICE_ORDER"]
41/3: import keras
41/4: from keras.layers import Conv3D, MaxPool3D , UpSampling3D
42/1:
def extract_data(filename, num_images):
    with gzip.open(filename) as bytestream:
        bytestream.read(16)
        buf = bytestream.read(28 * 28 * num_images)
        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)
        data = data.reshape(num_images, 28,28)
        return data
42/2: train_data = extract_data('notMNIST-to-MNIST-master.zip', 1)
42/3: cd notMNIST-to-MNIST-master/
42/4: ls
42/5: train_data = extract_data('train-images-idx3-ubyte.gz', 1)
42/6: import gzip
42/7: train_data = extract_data('train-images-idx3-ubyte.gz', 1)
42/8:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D
from keras.models import Model
from keras.optimizers import RMSprop
42/9: train_data = extract_data('train-images-idx3-ubyte.gz', 1)
42/10: train_data
42/11: train_data.shape
44/1:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D
from keras.models import Model
from keras.optimizers import RMSprop
44/2:
def extract_data(filename, num_images):
    with gzip.open(filename) as bytestream:
        bytestream.read(16)
        buf = bytestream.read(28 * 28 * num_images)
        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)
        data = data.reshape(num_images, 28,28)
        return data
44/3: train_data = extract_data('train-images-idx3-ubyte.gz', 1)
44/4: train_data
44/5: train_data.shape
45/1: import os
45/2:
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="1"
45/3:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D
from keras.models import Model
from keras.optimizers import RMSprop
45/4:
def extract_data(filename, num_images):
    with gzip.open(filename) as bytestream:
        bytestream.read(16)
        buf = bytestream.read(28 * 28 * num_images)
        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)
        data = data.reshape(num_images, 28,28)
        return data
45/5:
train_data = extract_data('notMNIST-to-MNIST/train-images-idx3-ubyte.gz', 60000)
test_data = extract_data('notMNIST-to-MNIST/t10k-images-idx3-ubyte.gz', 10000)
45/6: test_data
45/7: test_data.shape
45/8: train_data.shape
45/9:
def extract_labels(filename, num_images):
    with gzip.open(filename) as bytestream:
        bytestream.read(8)
        buf = bytestream.read(1 * num_images)
        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)
        return labels
45/10:
train_labels = extract_labels('train-labels-idx1-ubyte.gz',60000)
test_labels = extract_labels('t10k-labels-idx1-ubyte.gz',10000)
45/11:
train_labels = extract_labels('notMNIST-to-MNIST/train-labels-idx1-ubyte.gz',60000)
test_labels = extract_labels('notMNIST-to-MNIST/t10k-labels-idx1-ubyte.gz',10000)
45/12: train_labels
45/13: train_labels.shape
45/14:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
45/15:
label_dict = {
 0: 'A',
 1: 'B',
 2: 'C',
 3: 'D',
 4: 'E',
 5: 'F',
 6: 'G',
 7: 'H',
 8: 'I',
 9: 'J',
}
45/16:
plt.figure(figsize=[5,5])

# Display the first image in training data
plt.subplot(121)
curr_img = np.reshape(train_data[0], (28,28))
curr_lbl = train_labels[0]
plt.imshow(curr_img, cmap='gray')
plt.title("(Label: " + str(label_dict[curr_lbl]) + ")")

# Display the first image in testing data
plt.subplot(122)
curr_img = np.reshape(test_data[0], (28,28))
curr_lbl = test_labels[0]
plt.imshow(curr_img, cmap='gray')
plt.title("(Label: " + str(label_dict[curr_lbl]) + ")")
45/17:
plt.figure(figsize=[5,5])

# Display the first image in training data
plt.subplot(121)
curr_img = np.reshape(train_data[1], (28,28))
curr_lbl = train_labels[1]
plt.imshow(curr_img, cmap='gray')
plt.title("(Label: " + str(label_dict[curr_lbl]) + ")")

# Display the first image in testing data
plt.subplot(122)
curr_img = np.reshape(test_data[1], (28,28))
curr_lbl = test_labels[1]
plt.imshow(curr_img, cmap='gray')
plt.title("(Label: " + str(label_dict[curr_lbl]) + ")")
45/18:
train_data = train_data.reshape(-1, 28,28, 1)
test_data = test_data.reshape(-1, 28,28, 1)
train_data.shape, test_data.shape
45/19: train_data.dtype, test_data.dtype
45/20: np.max(train_data), np.max(test_data)
45/21:
train_data = train_data / np.max(train_data)
test_data = test_data / np.max(test_data)
45/22: np.max(train_data), np.max(test_data)
45/23:
from sklearn.model_selection import train_test_split
train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
45/24: tain_X.shape,valid_X.shape
45/25: train_X.shape,valid_X.shape
45/26:
batch_size = 128
epochs = 50
inChannel = 1
x, y = 28, 28
input_img = Input(shape = (x, y, inChannel))
45/27: input_img
45/28: Input?
45/29:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32
    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64
    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling2D((2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 64
    up2 = UpSampling2D((2,2))(conv5) # 28 x 28 x 64
    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
45/30: autoencoder = Model(input_img, autoencoder(input_img))
45/31: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
45/32: autoencoder.summary()
45/33: train_ground.shape
45/34: train_X.shape
45/35: train_X == train_ground
45/36: sum(train_X == train_ground)
45/37: autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))
45/38:
loss = autoencoder_train.history['loss']
val_loss = autoencoder_train.history['val_loss']
epochs = range(epochs)
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()
45/39: pred = autoencoder.predict(test_data)
45/40:
plt.figure(figsize=(20, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i, ..., 0], cmap='gray')
    curr_lbl = test_labels[i]
    plt.title("(Label: " + str(label_dict[curr_lbl]) + ")")
plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i, ..., 0], cmap='gray')  
plt.show()
46/1: pwd
46/2:
import os
import pymatgen.io.vasp as vasp
46/3: ls = os.listdir('ML-Antiperovskite/')
46/4:
for idir in ls:
    if 'mp-' in idir :
        path = 'ML-Antiperovskite' + os.sep + idir
46/5: path
46/6: path + os.sep + 'ELFCAR'
46/7: elfcar = vasp.Elfcar.from_file(path + os.sep + 'ELFCAR')
46/8: elfcar
46/9: elfcar.data_aug
46/10: elfcar.data
46/11: elfcar.data['total']
46/12: elfcar.data['total'].shape
46/13: elfcar.data['total']
46/14:
count = 1
for idir in ls:
    if 'mp-' in idir :
        path = 'ML-Antiperovskite' + os.sep + idir
        coutn += 1
46/15:
count = 1
for idir in ls:
    if 'mp-' in idir :
        path = 'ML-Antiperovskite' + os.sep + idir
        count += 1
46/16: count
45/41: train_data.shape
46/17:
import os
import numpy as np
import pymatgen.io.vasp as vasp
46/18:
def get_data(path, num_dirs,ngx,ngy,ngz):
    data = np.zeros(shape=(num_dirs,ngx,ngy,ngz))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if 'mp-' in idir:
            elfcar = vasp.Elfcar.from_file('ML-Antiperovskite' + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = elfcar.data['total']
    return data
46/19:
def get_data(path, num_dirs,ngx,ngy,ngz):
    data = np.zeros(shape=(num_dirs,ngx,ngy,ngz))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if 'mp-' in idir:
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = elfcar.data['total']
    return data
46/20: data = get_data('ML-Antiperovskite',576)
46/21: data = get_data('ML-Antiperovskite',576,50,50,50)
46/22:
count = 1
for idir in os.listdir('ML-Antiperovskite'):
    if 'mp-' in idir and os.path.exists('ML-Antiperovskite'+ os.sep + idir+os.sep+'ELFCAR'):
        count += 1
46/23: count
46/24: data = get_data('ML-Antiperovskite',544,50,50,50)
46/25:
def get_data(path, num_dirs,ngx,ngy,ngz):
    data = np.zeros(shape=(num_dirs,ngx,ngy,ngz))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = elfcar.data['total']
    return data
46/26: data = get_data('ML-Antiperovskite',544,50,50,50)
46/27: data.shape
46/28: data
46/29: data[0]
46/30: data[0][1,:,:]
46/31: data[0][1,1,:]
46/32: max(data)
46/33: data.max()
46/34:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
46/35:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
46/36:
train_data = data[400,:,:,:]
test_data = data[544-400,:,:,:]
46/37:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
46/38:
train_data = data[:400,:,:,:]
test_data = data[(544-400):,:,:,:]
46/39:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
46/40:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
46/41:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
46/42:
plt.figure(figsize=[5,5])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,25,:,:]

plt.imshow(curr_img, cmap='gray')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,25,:,:]

plt.imshow(curr_img, cmap='gray')
46/43:
plt.figure(figsize=[5,5])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,10,:,:]

plt.imshow(curr_img, cmap='gray')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,10,:,:]

plt.imshow(curr_img, cmap='gray')
46/44:
plt.figure(figsize=[5,5])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,10,:,:]

plt.imshow(curr_img, cmap='gray')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,20,:,:]

plt.imshow(curr_img, cmap='gray')
46/45:
plt.figure(figsize=[5,5])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,10,:,:]

plt.imshow(curr_img, cmap='gray')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,50,:,:]

plt.imshow(curr_img, cmap='gray')
46/46:
plt.figure(figsize=[5,5])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,10,:,:]

plt.imshow(curr_img, cmap='gray')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='gray')
46/47: test_data[0]
46/48: test_data[1]
46/49: data[401]
46/50: data[402]
46/51: data[400]
46/52: data[1]
46/53: data[2]
46/54: data[0]
46/55:
def get_data(path, num_dirs,ngx,ngy,ngz):
    data = np.zeros(shape=(num_dirs,ngx,ngy,ngz))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = elfcar.data['total']
            i+=1
    return data
46/56: data = get_data('ML-Antiperovskite',544,50,50,50)
46/57: data[1]
46/58:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
46/59:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
46/60:
plt.figure(figsize=[20,20])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,10,:,:]

plt.imshow(curr_img, cmap='gray')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='gray')
46/61:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,10,:,:]

plt.imshow(curr_img, cmap='gray')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='gray')
46/62:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,10,:,:]

plt.imshow(curr_img, cmap='gray')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,10,:,:]

plt.imshow(curr_img, cmap='gray')
46/63:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,10,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,10,:,:]

plt.imshow(curr_img, cmap='jet')
46/64:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,0,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,0,:,:]

plt.imshow(curr_img, cmap='jet')
46/65:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,20,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,20,:,:]

plt.imshow(curr_img, cmap='jet')
46/66:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,30,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,30,:,:]

plt.imshow(curr_img, cmap='jet')
46/67:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,40,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,40,:,:]

plt.imshow(curr_img, cmap='jet')
46/68:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,50,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,50,:,:]

plt.imshow(curr_img, cmap='jet')
46/69:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')
46/70:
train_data = train_data.reshape(-1, 50,50,50, 1)
test_data = test_data.reshape(-1, 50,50,50, 1)
train_data.shape, test_data.shape
46/71: train_data.dtype, test_data.dtype
46/72: np.max(train_data), np.max(test_data)
46/73:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 50,50,50
input_img = Input(shape = (x, y,z, inChannel))
46/74:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2))(conv2) #7 x 7 x 64
    conv3 = Conv3D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv3D(128, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling3D((2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
46/75: autoencoder = Model(input_img, autoencoder(input_img))
46/76:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
46/77: autoencoder = Model(input_img, autoencoder(input_img))
46/78: autoencoder = Model(input_img, autoencoder(input_img))
46/79: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
46/80: autoencoder.summary()
46/81:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
46/82: autoencoder = Model(input_img, autoencoder(input_img))
46/83: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
46/84: autoencoder.summary()
46/85:
from sklearn.model_selection import train_test_split
train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
46/86: autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))
46/87:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
#    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
#    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
#    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
#    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
46/88: autoencoder = Model(input_img, autoencoder(input_img))
46/89:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
#    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
#    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
#    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
#    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
46/90: autoencoder = Model(input_img, autoencoder(input_img))
46/91: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
46/92: autoencoder.summary()
46/93: autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))
46/94:
loss = autoencoder_train.history['loss']
val_loss = autoencoder_train.history['val_loss']
epochs = range(epochs)
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()
46/95: pred = autoencoder.predict(test_data)
46/96:
plt.figure(figsize=(20, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[[i, ..., 0],49,:,:] cmap='jet')
    curr_lbl = test_labels[i]
    plt.title("(Label: " + str(label_dict[curr_lbl]) + ")")
plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[[i, ..., 0],49,:,:], cmap='jet')  
plt.show()
46/97:
plt.figure(figsize=(20, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[[i, ..., 0],49,:,:], cmap='jet')
    curr_lbl = test_labels[i]
    plt.title("(Label: " + str(label_dict[curr_lbl]) + ")")
plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[[i, ..., 0],49,:,:], cmap='jet')  
plt.show()
46/98:
plt.figure(figsize=(20, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i,49,:,:], cmap='jet')
    curr_lbl = test_labels[i]
    plt.title("(Label: " + str(label_dict[curr_lbl]) + ")")
plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,49,:,:], cmap='jet')  
plt.show()
46/99:
plt.figure(figsize=(20, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i,49,:,:], cmap='jet')
    plt.title("(Label: " + str(label_dict[curr_lbl]) + ")")
plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,49,:,:], cmap='jet')  
plt.show()
46/100: test_data.shape
46/101:
plt.figure(figsize=(20, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i,49,:,:,0], cmap='jet')
    plt.title("(Label: " + str(label_dict[curr_lbl]) + ")")
plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,49,:,:,0], cmap='jet')  
plt.show()
46/102:
plt.figure(figsize=(20, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i,49,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,49,:,:,0], cmap='jet')  
plt.show()
46/103:
plt.figure(figsize=(20, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
46/104:
plt.figure(figsize=(20, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 20, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 20, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
46/105:
plt.figure(figsize=(20, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 20, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 20, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
46/106:
plt.figure(figsize=(20, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 49, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 49, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
46/107: plt.clf()
46/108:
plt.figure(figsize=(20, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 49, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 49, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
46/109:
plt.figure(figsize=(10, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 49, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 49, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
46/110:
plt.figure(figsize=(40, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 49, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(40, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 49, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
46/111: plt.clf()
46/112: plt.clf()
46/113:
plt.figure(figsize=(40, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 49, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(40, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 49, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
46/114:
plt.figure(figsize=(40, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 49, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(40, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 49, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
46/115: from matplotlib import pyplot as plt
46/116:
plt.figure(figsize=(40, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 49, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(40, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 49, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
46/117:
plt.figure(figsize=(40, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(40, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
46/118:
plt.figure(figsize=(20, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
46/119:
plt.figure(figsize=(15, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(15, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
46/120:
plt.figure(figsize=(20, 4))
print("Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
46/121:
plt.figure(figsize=(20, 4))
print("Test Images cut 2")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i,35,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 2")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,35,:,:,0], cmap='jet')  
plt.show()
46/122:
plt.figure(figsize=(20, 4))
print("Test Images cut 2")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i,49,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 2")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,49,:,:,0], cmap='jet')  
plt.show()
46/123:
plt.figure(figsize=(20, 4))
print("Test Images cut 3")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 2")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
47/1:
import os
import pymatgen.io.vasp as vasp
47/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
47/3:
def get_data(path, num_dirs,ngx,ngy,ngz):
    data = np.zeros(shape=(num_dirs,ngx,ngy,ngz))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = elfcar.data['total']
            i+=1
    return data
47/4:
def get_data(path, num_dirs,ngx,ngy,ngz):
    data = np.zeros(shape=(num_dirs,ngx,ngy,ngz))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i > num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = elfcar.data['total']
            i+=1
            
    return data
47/5: data = get_data('ML-Antiperovskite',544,1,50,50)
47/6: data = get_data('ML-Antiperovskite',1,50,50,50)
47/7: data = get_data('ML-Antiperovskite',2,50,50,50)
47/8:
def get_data(path, num_dirs,ngx,ngy,ngz):
    data = np.zeros(shape=(num_dirs,ngx,ngy,ngz))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = elfcar.data['total']
            i+=1
            
    return data
47/9: data = get_data('ML-Antiperovskite',2,50,50,50)
47/10: data = get_data('ML-Antiperovskite',1,50,50,50)
47/11: data
47/12: data[0]
47/13: data[0].shape
47/14: np.pad([1,2,3,4], (2, 3), 'wrap')
47/15: np.pad([1,2,3,4], (0, 3), 'wrap')
47/16: np.pad([1,2,3,4], (0, 4), 'wrap')
47/17: a = np.array([[1,2],[3,4]])
47/18: a
47/19: np.pad(a, (0, 4), 'wrap')
47/20: np.pad(data, (0, 50), 'wrap')
47/21: np.pad(data, (0, 50), 'wrap').shape
47/22: np.pad(data[0], (0, 50), 'wrap').shape
47/23:
def get_data(path, num_dirs,ngx,ngy,ngz):
    data = np.zeros(shape=(num_dirs,ngx,ngy,ngz))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, 50), 'wrap') 
            i+=1
            
    return data
47/24: data = get_data('ML-Antiperovskite',1,50,50,50)
47/25:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
47/26: data = get_data('ML-Antiperovskite',1,50,50,50,50)
47/27: data[0].shape
47/28: data = get_data('ML-Antiperovskite',544,50,50,50)
47/29: data = get_data('ML-Antiperovskite',544,50,50,50,50)
47/30: data.shape
47/31:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
47/32:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
47/33:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')
47/34:
train_data = train_data.reshape(-1, 50,50,50, 1)
test_data = test_data.reshape(-1, 50,50,50, 1)
train_data.shape, test_data.shape
47/35:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
47/36:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
47/37:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')
47/38:
train_data = train_data.reshape(-1, 100,100,100, 1)
test_data = test_data.reshape(-1, 100,100,100, 1)
train_data.shape, test_data.shape
47/39: np.max(train_data), np.max(test_data)
47/40:
from sklearn.model_selection import train_test_split
train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
47/41:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 50,50,50
input_img = Input(shape = (x, y,z, inChannel))
47/42:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
47/43: autoencoder = Model(input_img, autoencoder(input_img))
47/44: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
47/45: autoencoder.summary()
47/46:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 100,100,100
input_img = Input(shape = (x, y,z, inChannel))
47/47:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
47/48: autoencoder = Model(input_img, autoencoder(input_img))
47/49: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
47/50: autoencoder.summary()
47/51: autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))
49/1:
import os
import pymatgen.io.vasp as vasp
49/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
49/3:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
49/4: data = get_data('ML-Antiperovskite',544,50,50,50,50)
49/5:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
49/6:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
49/7:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
49/8:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')
49/9:
train_data = train_data.reshape(-1, 100,100,100, 1)
test_data = test_data.reshape(-1, 100,100,100, 1)
train_data.shape, test_data.shape
49/10: np.max(train_data), np.max(test_data)
49/11:
from sklearn.model_selection import train_test_split
train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
49/12:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 100,100,100
input_img = Input(shape = (x, y,z, inChannel))
49/13:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
49/14: autoencoder = Model(input_img, autoencoder(input_img))
49/15: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
49/16: autoencoder.summary()
49/17: autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))
50/1:
import os
import pymatgen.io.vasp as vasp
50/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
50/3:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
50/4:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (25, wrap), 'wrap') 
            i+=1
            
    return data
50/5: data = get_data('ML-Antiperovskite',544,50,50,50,30)
50/6:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
50/7: data = get_data('ML-Antiperovskite',544,50,50,50,30)
50/8:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
50/9:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
50/10:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')
50/11:
train_data = train_data.reshape(-1, 100,100,100, 1)
test_data = test_data.reshape(-1, 100,100,100, 1)
train_data.shape, test_data.shape
50/12:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
50/13:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
50/14:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')
50/15:
train_data = train_data.reshape(-1, 80,80,80, 1)
test_data = test_data.reshape(-1, 80,80,80, 1)
train_data.shape, test_data.shape
50/16: np.max(train_data), np.max(test_data)
50/17:
from sklearn.model_selection import train_test_split
train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
50/18:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 100,100,100
input_img = Input(shape = (x, y,z, inChannel))
50/19:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
50/20: autoencoder = Model(input_img, autoencoder(input_img))
50/21: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
50/22: autoencoder.summary()
50/23: autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))
50/24:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 80,80,80
input_img = Input(shape = (x, y,z, inChannel))
50/25:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
50/26: autoencoder = Model(input_img, autoencoder(input_img))
50/27: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
50/28: autoencoder.summary()
50/29: autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))
50/30:
loss = autoencoder_train.history['loss']
val_loss = autoencoder_train.history['val_loss']
epochs = range(epochs)
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()
50/31: pred = autoencoder.predict(test_data)
50/32:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
50/33:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
50/34:
plt.figure(figsize=(20, 9))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
50/35:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/1:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
50/36:
plt.figure(figsize=(20, 10))
print("Test Images cut 2")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,35,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 2")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,35,:,:,0], cmap='jet')  
plt.show()
50/37:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
51/2:
import os
import pymatgen.io.vasp as vasp
51/3:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
51/4:
def get_data(path, num_dirs,ngx,ngy,ngz):
    data = np.zeros(shape=(num_dirs,ngx,ngy,ngz))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i > num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = elfcar.data['total']
            i+=1
            
    return data
51/5: data = get_data('ML-Antiperovskite',544,50,50,50)
51/6: data[1]
51/7:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
51/8:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
51/9:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')
51/10:
train_data = train_data.reshape(-1, 50,50,50, 1)
test_data = test_data.reshape(-1, 50,50,50, 1)
train_data.shape, test_data.shape
51/11: train_data.dtype, test_data.dtype
51/12: np.max(train_data), np.max(test_data)
51/13:
from sklearn.model_selection import train_test_split
train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
51/14:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 50,50,50
input_img = Input(shape = (x, y,z, inChannel))
51/15:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
#    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
#    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
#    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
#    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
51/16: autoencoder = Model(input_img, autoencoder(input_img))
51/17: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
51/18: autoencoder.summary()
51/19: autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))
51/20:
loss = autoencoder_train.history['loss']
val_loss = autoencoder_train.history['val_loss']
epochs = range(epochs)
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()
51/21: pred = autoencoder.predict(test_data)
51/22:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(10):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/23:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 10, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/24:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 10, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/25:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/26:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(10, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/27:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/28:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 1, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/29:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 6, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/30:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/31:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(4, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/32:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(5, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/33:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(20, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/34:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/35:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/36:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
51/37:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
51/38:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,35,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,35,:,:,0], cmap='jet')  
plt.show()
51/39:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
51/40:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')
    

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/41:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/42:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(.5, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/43:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/44:
plt.figure(figsize=(20, 5))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/45:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/46:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/47: ls = os.listdir('ML-Antiperovskite')
51/48: ls[401]
51/49:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/50:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,24,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,24,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/51:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,24,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/52:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,22,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,24,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/53:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,24,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/54:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,10,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,24,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/55:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,24,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/56:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,17,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,24,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/57:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,20,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,24,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/58:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,20,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,20,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/59:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
51/60:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,20,:,:,0], cmap='plasma')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,20,:,:,0], cmap='plasma')
    plt.axis('off')
plt.show()
51/61:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,20,:,:,0], cmap='summer')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,20,:,:,0], cmap='summer')
    plt.axis('off')
plt.show()
51/62:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,20,:,:,0], cmap='winter')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,20,:,:,0], cmap='winter')
    plt.axis('off')
plt.show()
51/63:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,20,:,:,0], cmap='jet')
    plt.axis('off')

plt.show()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,20,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/64: ls[402]
51/65: ls[400]
51/66: ls[403]
51/67: ls[404]
51/68:
def get_label(path, num_dirs):
    labels = []
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i > num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            #elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            #data[i,:,:,:] = elfcar.data['total']
            label.append(idir)
            i+=1
            
    return label
51/69: labels = get_label('ML-Antiperovskite',544)
51/70:
def get_label(path, num_dirs):
    label = []
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i > num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            #elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            #data[i,:,:,:] = elfcar.data['total']
            label.append(idir)
            i+=1
            
    return label
51/71: labels = get_label('ML-Antiperovskite',544)
51/72: labels[400]
51/73: labels[401]
51/74: labels[402]
51/75: labels[403]
51/76: labels.shape
51/77: len(labels)
51/78: data.shape
51/79: data[-1]
51/80: data[-2]
51/81: labels[400:]
51/82:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,24,:,:,0], cmap='jet')
    plt.axis('off')

#plt.savefig()    
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,24,:,:,0], cmap='jet')
    plt.axis('off')
plt.show()
51/83:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,24,:,:,0], cmap='jet')
    plt.axis('off')

plt.savefig('test_image.pdf')    
#plt.show()
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,24,:,:,0], cmap='jet')
    plt.axis('off')
plt.savefig('test_image_reconstructed.pdf')    
#plt.show()
51/84: autoencoder.history
51/85: autoencoder.history()
51/86: autoencoder.get_layer
51/87: autoencoder.get_layer?
51/88: autoencoder.get_layer?
51/89: autoencoder.weights
51/90: autoencoder.weights[2]
51/91: autoencoder.weights
51/92: autoencoder.get_layer?
51/93: autoencoder.outputs?
51/94: autoencoder.outputs
51/95: autoencoder.outputs[0]
51/96: autoencoder.outputs
51/97: autoencoder.outputs()
51/98: autoencoder.outputs[0]
51/99:
layer_name = 'conv2'
intermediate_layer_model = autoencoder.Model(inputs=autoencoder.input,
                                 outputs=autoencoder.get_layer(layer_name).output)
51/100:
layer_name = 'conv2'
intermediate_layer_model = autoencoder(inputs=autoencoder.input,
                                 outputs=autoencoder.get_layer(layer_name).output)
51/101: autoencoder.layers
51/102: autoencoder.layers[3]
51/103: autoencoder.layers[3].name
51/104:
layer_name = 'conv3d_3'
intermediate_layer_model = autoencoder(inputs=autoencoder.input,
                                 outputs=autoencoder.get_layer(layer_name).output)
51/105:
layer_name = 'conv3d_3'
intermediate_layer_model = autoencoder(inputs=autoencoder.input,autoencoder.get_layer(layer_name).output)
51/106:
layer_name = 'conv3d_3'
intermediate_layer_model = autoencoder(autoencoder.input,autoencoder.get_layer(layer_name).output)
51/107:
layer_name = 'conv3d_3'
intermediate_layer_model = autoencoder(inputs=autoencoder.input,
                                 outputs=autoencoder.get_layer(layer_name).output)
51/108: autoencoder.layers
51/109:
from keras import backend as K
get_3rd_layer_output = K.function([autoencoder.layers[0].input],
                                  [model.layers[3].output])
51/110:
from keras import backend as K
get_3rd_layer_output = K.function([autoencoder.layers[0].input],
                                  [autoencoder.layers[3].output])
51/111: layer_output = get_3rd_layer_output([test_data])[0]
51/112: layer_output
51/113: layer_output.shape
51/114: test_data.shape
51/115: pred.shape
51/116:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 4))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i,0,:,:].reshape(25,25,25*64), cmap='jet')  
plt.show()
51/117: layer_output[0]
51/118: layer_output[0].shape
51/119: layer_output[0].reshape(25,25,25*64)
51/120:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 4))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(25,25,25*64).reshape(25,25,25*64)[0,:,:], cmap='jet')  
plt.show()
51/121:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(40, 4))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(25,25,25*64).reshape(25,25,25*64)[0,:,:], cmap='jet')  
plt.show()
51/122:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(40, 4))
print("Reconstruction code")
for i in range(4):
    plt.subplot(10, 4, i+1)
    plt.imshow(layer_output[i].reshape(25,25,25*64).reshape(25,25,25*64)[0,:,:], cmap='jet')  
plt.show()
51/123:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
plt.imshow(test_data[0,0,:,:,0], cmap='jet')
plt.show()    
plt.imshow(pred[0,0,:,:,0], cmap='jet')  
plt.show()
plt.imshow(layer_output[0].reshape(25,25,25*64).reshape(25,25,25*64)[0,:,:], cmap='jet')  
plt.show()
51/124:
#plt.figure(figsize=(20, 4))
print("Test Images cut 1")
plt.imshow(test_data[0,0,:,:,0], cmap='jet')
plt.show()    
plt.imshow(pred[0,0,:,:,0], cmap='jet')  
plt.show()
plt.imshow(layer_output[0].reshape(25,25,25*64).reshape(25,25,25*64)[0,:,:], cmap='jet')  
plt.show()
51/125:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
plt.imshow(test_data[0,0,:,:,0], cmap='jet')
plt.show()    
plt.imshow(pred[0,0,:,:,0], cmap='jet')  
plt.show()
plt.show(figsize=(20,20))
plt.imshow(layer_output[0].reshape(25,25,25*64).reshape(25,25,25*64)[0,:,:], cmap='jet')  
plt.show()
51/126:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
plt.imshow(test_data[0,0,:,:,0], cmap='jet')
plt.show()    
plt.imshow(pred[0,0,:,:,0], cmap='jet')  
plt.show()
plt.show(figsize=(20,10))
plt.imshow(layer_output[0].reshape(25,25,25*64).reshape(25,25,25*64)[0,:,:], cmap='jet')  
plt.show()
51/127:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
plt.imshow(test_data[0,0,:,:,0], cmap='jet')
plt.show()    
plt.imshow(pred[0,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20,10))
plt.imshow(layer_output[0].reshape(25,25,25*64).reshape(25,25,25*64)[0,:,:], cmap='jet')  
plt.show()
51/128:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
plt.imshow(test_data[0,0,:,:,0], cmap='jet')
plt.show()    
plt.imshow(pred[0,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20,20))
plt.imshow(layer_output[0].reshape(25,25,25*64).reshape(25,25,25*64)[0,:,:], cmap='jet')  
plt.show()
51/129:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 4))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(25*64,25,25)[0,:,:], cmap='jet')  
plt.show()
51/130:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 4))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(25,25*64,25)[0,:,:], cmap='jet')  
plt.show()
51/131:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(25,25*64,25)[0,:,:], cmap='jet')  
plt.show()
51/132:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 10))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(25,25*64,25)[0,:,:], cmap='jet')  
plt.show()
51/133:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(25,25*64,25)[0,:,:], cmap='jet')  
plt.show()
51/134:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 60))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(25,25*64,25)[0,:,:], cmap='jet')  
plt.show()
51/135:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(25,25*64,25)[25,:,:], cmap='jet')  
plt.show()
51/136:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(25,25*64,25)[20,:,:], cmap='jet')  
plt.show()
52/1:
import os
import pymatgen.io.vasp as vasp
52/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
52/3:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
52/4: data = get_data('ML-Antiperovskite',544,50,50,50,2)
52/5:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
52/6:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
52/7:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')
52/8:
train_data = train_data.reshape(-1, 80,80,80, 1)
test_data = test_data.reshape(-1, 80,80,80, 1)
train_data.shape, test_data.shape
52/9:
train_data = train_data.reshape(-1, 52,52,52, 1)
test_data = test_data.reshape(-1, 52,52,52, 1)
train_data.shape, test_data.shape
52/10: np.max(train_data), np.max(test_data)
52/11:
from sklearn.model_selection import train_test_split
train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
52/12:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 52,52,52
input_img = Input(shape = (x, y,z, inChannel))
52/13:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
52/14: autoencoder = Model(input_img, autoencoder(input_img))
52/15: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
52/16: autoencoder.summary()
52/17: autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))
54/1:
import os
import pymatgen.io.vasp as vasp
54/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
54/3:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
54/4: data = get_data('ML-Antiperovskite',544,50,50,50,6)
54/5: data = get_data('ML-Antiperovskite',544,50,50,50,2)
54/6:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
54/7:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
54/8:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')
54/9:
train_data = train_data.reshape(-1, 52,52,52, 1)
test_data = test_data.reshape(-1, 52,52,52, 1)
train_data.shape, test_data.shape
54/10: np.max(train_data), np.max(test_data)
54/11:
from sklearn.model_selection import train_test_split
train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
54/12:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 52,52,52
input_img = Input(shape = (x, y,z, inChannel))
54/13:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
54/14: autoencoder = Model(input_img, autoencoder(input_img))
54/15: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
54/16: autoencoder.summary()
54/17: autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))
54/18:
loss = autoencoder_train.history['loss']
val_loss = autoencoder_train.history['val_loss']
epochs = range(epochs)
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()
54/19: pred = autoencoder.predict(test_data)
54/20:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
54/21:
plt.figure(figsize=(20, 10))
print("Test Images cut 2")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,35,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 2")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,35,:,:,0], cmap='jet')  
plt.show()
54/22:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
54/23: autoencoder.layers
54/24:
from keras import backend as K
get_3rd_layer_output = K.function([autoencoder.layers[0].input],
                                  [autoencoder.layers[5].output])
54/25: layer_output = get_3rd_layer_output([test_data])[0]
54/26: layer_output.shape
54/27:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(13,13*128,13)[20,:,:], cmap='jet')  
plt.show()
54/28:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(13,13*128,13)[0,:,:], cmap='jet')  
plt.show()
54/29:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(13,13,13)[0,:,:], cmap='jet')  
plt.show()
54/30:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(13,13*128,13)[0,:,:], cmap='jet')  
plt.show()
54/31:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(13,13*128,13)[0,0,:], cmap='jet')  
plt.show()
54/32:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(13,13*128,13)[1,:,:], cmap='jet')  
plt.show()
54/33:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(13,13*128,13)[2,:,:], cmap='jet')  
plt.show()
54/34:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(13,13*128,13)[3,:,:], cmap='jet')  
plt.show()
54/35:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i][:,:,:,0], cmap='jet')  
    #plt.imshow(layer_output[i].reshape(13,13*128,13)[0,:,:], cmap='jet')  
plt.show()
54/36:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i][:,:,:], cmap='jet')  
    #plt.imshow(layer_output[i].reshape(13,13*128,13)[0,:,:], cmap='jet')  
plt.show()
54/37: layer_output[0].shape
54/38: layer_output[0][:,:,:,:].shape
54/39: layer_output[0][:,:,:,0].shape
54/40:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i][:,:,:,0], cmap='jet')  
    #plt.imshow(layer_output[i].reshape(13,13*128,13)[0,:,:], cmap='jet')  
plt.show()
54/41:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i][0,:,:,0], cmap='jet')  
    #plt.imshow(layer_output[i].reshape(13,13*128,13)[0,:,:], cmap='jet')  
plt.show()
54/42:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i][0,:,:,0], cmap='jet')  
    #plt.imshow(layer_output[i].reshape(13,13*128,13)[0,:,:], cmap='jet')  
plt.show()
54/43:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i][0,:,:,1], cmap='jet')  
    #plt.imshow(layer_output[i].reshape(13,13*128,13)[0,:,:], cmap='jet')  
plt.show()
54/44:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i][0,:,:,2], cmap='jet')  
    #plt.imshow(layer_output[i].reshape(13,13*128,13)[0,:,:], cmap='jet')  
plt.show()
54/45:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i][0,:,:,3], cmap='jet')  
    #plt.imshow(layer_output[i].reshape(13,13*128,13)[0,:,:], cmap='jet')  
plt.show()
54/46:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    #plt.imshow(layer_output[i][0,:,:,0], cmap='jet')  
    plt.imshow(layer_output[i].reshape(13,13*20,13)[0,:,:], cmap='jet')  
plt.show()
54/47:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    #plt.imshow(layer_output[i][0,:,:,0], cmap='jet')  
    plt.imshow(layer_output[i].reshape(13,13*64,13)[0,:,:], cmap='jet')  
plt.show()
54/48:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    #plt.imshow(layer_output[i][0,:,:,0], cmap='jet')  
    plt.imshow(layer_output[i].reshape(13,13*128,13)[0,20:28,:], cmap='jet')  
plt.show()
54/49:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    #plt.imshow(layer_output[i][0,:,:,0], cmap='jet')  
    plt.imshow(layer_output[i].reshape(13,13*128,13)[0,20:100,:], cmap='jet')  
plt.show()
54/50:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    #plt.imshow(layer_output[i][0,:,:,0], cmap='jet')  
    plt.imshow(layer_output[i].reshape(13,13*128,13)[0,0:100,:], cmap='jet')  
plt.show()
54/51:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    #plt.imshow(layer_output[i][0,:,:,0], cmap='jet')  
    plt.imshow(layer_output[i].reshape(13,13*128,13)[0,0:128,:], cmap='jet')  
plt.show()
54/52:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    #plt.imshow(layer_output[i][0,:,:,0], cmap='jet')  
    plt.imshow(layer_output[i].reshape(13,13*128,13)[0,0:256,:], cmap='jet')  
plt.show()
54/53:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    #plt.imshow(layer_output[i][0,:,:,0], cmap='jet')  
    plt.imshow(layer_output[i].reshape(13,13*128,13)[1,0:256,:], cmap='jet')  
plt.show()
54/54:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    #plt.imshow(layer_output[i][0,:,:,0], cmap='jet')  
    plt.imshow(layer_output[i].reshape(13,13*128,13)[2,0:256,:], cmap='jet')  
plt.show()
54/55:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    #plt.imshow(layer_output[i][0,:,:,0], cmap='jet')  
    plt.imshow(layer_output[i].reshape(13,13*128,13)[2,:,:], cmap='jet')  
plt.show()
54/56: autoencoder.save?
54/57: autoencoder.save('52x52x52-3conv.hdf5')
53/1:
import os
import pymatgen.io.vasp as vasp
53/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
53/3:
def get_data(path, num_dirs,ngx,ngy,ngz):
    data = np.zeros(shape=(num_dirs,ngx,ngy,ngz))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i > num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = elfcar.data['total']
            i+=1
            
    return data
53/4: data = get_data('ML-Antiperovskite',544,50,50,50)
53/5:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
53/6:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
53/7:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')
53/8:
train_data = train_data.reshape(-1, 50,50,50, 1)
test_data = test_data.reshape(-1, 50,50,50, 1)
train_data.shape, test_data.shape
53/9: train_data.dtype, test_data.dtype
53/10: np.max(train_data), np.max(test_data)
53/11:
from sklearn.model_selection import train_test_split
train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
53/12:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 50,50,50
input_img = Input(shape = (x, y,z, inChannel))
53/13:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
53/14:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
#    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
#    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
#    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
#    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
53/15: autoencoder = Model(input_img, autoencoder(input_img))
53/16: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
53/17: autoencoder.summary()
53/18: autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))
53/19:
loss = autoencoder_train.history['loss']
val_loss = autoencoder_train.history['val_loss']
epochs = range(epochs)
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()
53/20: pred = autoencoder.predict(test_data)
53/21:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
53/22:
plt.figure(figsize=(20, 6))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,24,:,:,0], cmap='jet')
    plt.axis('off')

plt.savefig('test_image.pdf')    
#plt.show()
plt.figure(figsize=(20, 6))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,24,:,:,0], cmap='jet')
    plt.axis('off')
plt.savefig('test_image_reconstructed.pdf')    
#plt.show()
53/23:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
53/24: ls = os.listdir('ML-Antiperovskite')
53/25:
def get_label(path, num_dirs):
    label = []
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i > num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            #elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            #data[i,:,:,:] = elfcar.data['total']
            label.append(idir)
            i+=1
            
    return label
53/26: labels = get_label('ML-Antiperovskite',544)
53/27: labels[400:]
53/28:
from keras import backend as K
get_3rd_layer_output = K.function([autoencoder.layers[0].input],
                                  [autoencoder.layers[3].output])
53/29: layer_output = get_3rd_layer_output([test_data])[0]
53/30:
plt.figure(figsize=(20, 4))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 4))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
plt.figure(figsize=(20, 40))
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(25,25*64,25)[20,:,:], cmap='jet')  
plt.show()
53/31: autoencoder.save("50x50x50-2conv.hdf5")
57/1:
import os
import pymatgen.io.vasp as vasp
57/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
57/3:
def get_data(path, num_dirs,ngx,ngy,ngz):
    data = np.zeros(shape=(num_dirs,ngx,ngy,ngz))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i > num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = elfcar.data['total']
            i+=1
            
    return data
57/4: data = get_data('ML-Antiperovskite',544,50,50,50)
57/5:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
57/6:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D, Dense
from keras.models import Model
from keras.optimizers import RMSprop
57/7:
def get_data(path, num_dirs,ngx,ngy,ngz):
    data = np.zeros(shape=(num_dirs,ngx,ngy,ngz))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i > num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = elfcar.data['total']
            i+=1
            
    return data
57/8:
batch_size = 128
original_dim = (50,50,50)
57/9:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
57/10:
batch_size = 128
original_dim = 50*50*50
57/11:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
57/12:
batch_size = 128
original_dim = 50*50*50
intermediate_dim = 25*25*25
57/13:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
57/14:
batch_size = 128
original_dim = 50*50*50
intermediate_dim = 25*25*25
latent_dim = 100
57/15:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
57/16:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
57/17:
def sampling(args):
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., std=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
57/18:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D, Dense,Lambda
from keras.models import Model
from keras.optimizers import RMSprop
57/19:
def get_data(path, num_dirs,ngx,ngy,ngz):
    data = np.zeros(shape=(num_dirs,ngx,ngy,ngz))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i > num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = elfcar.data['total']
            i+=1
            
    return data
57/20:
batch_size = 128
original_dim = 50*50*50
intermediate_dim = 25*25*25
latent_dim = 100
57/21:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
57/22:
def sampling(args):
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., std=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
57/23:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D, Dense,Lambda,K
from keras.models import Model
from keras.optimizers import RMSprop
57/24:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D, Dense,Lambda
from keras.models import Model
from keras.optimizers import RMSprop
from keras import backend as K
57/25:
batch_size = 128
original_dim = 50*50*50
intermediate_dim = 25*25*25
latent_dim = 100
57/26:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
57/27:
def sampling(args):
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., std=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
57/28:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., std=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
57/29: K.random_normal?
57/30:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
57/31:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
57/32:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
57/33:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
57/34: from keras import objectives
57/35:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
57/36: data.shape[1:]
57/37: np.prod(data.shape[1:])
57/38: np.prod(data.shape)
57/39: data.shape
57/40:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
57/41:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
57/42:
vae.fit(x_train, x_train,
        shuffle=True,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(x_test, x_test))
57/43: epochs = 50
57/44:
vae.fit(x_train, x_train,
        shuffle=True,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(x_test, x_test))
57/45: x_test.shape
57/46:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
57/47: epochs = 50
57/48:
vae.fit(x_train, x_train,
        shuffle=True,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(x_test, x_test))
58/1:
import os
import pymatgen.io.vasp as vasp
58/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D, Dense,Lambda
from keras.models import Model
from keras.optimizers import RMSprop
from keras import backend as K
58/3:
def get_data(path, num_dirs,ngx,ngy,ngz):
    data = np.zeros(shape=(num_dirs,ngx,ngy,ngz))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i > num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = elfcar.data['total']
            i+=1
            
    return data
58/4: data = get_data('ML-Antiperovskite',544,50,50,50)
58/5:
batch_size = 128
original_dim = 50*50*50
intermediate_dim = 25*25*25
latent_dim = 10
58/6:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
58/7:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
58/8:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
58/9:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
58/10: from keras import objectives
58/11:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
58/12:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
58/13:
x_train = np.reshape(x_train, [-1, original_dim])
x_test = np.reshape(x_test, [-1, original_dim])
58/14:
epochs = 50
x_train.shape
58/15:
vae.fit(x_train, x_train,
        shuffle=True,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(x_test, x_test))
62/1:
import os
import pymatgen.io.vasp as vasp
62/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D, Dense,Lambda
from keras.models import Model
from keras.optimizers import RMSprop
from keras import backend as K
62/3:
def get_data(path, num_dirs,ngx,ngy,ngz):
    data = np.zeros(shape=(num_dirs,ngx,ngy,ngz))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i > num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = elfcar.data['total']
            i+=1
            
    return data
62/4: data = get_data('ML-Antiperovskite',544,50,50,50)
62/5: np.savetxt?
62/6: np.savetxt('data.txt',data)
62/7: import h5py
62/8: wf = h5py.File('data.hdf5','w')
62/9: dset = wf.create_dataset("data",(544,50,50))
62/10: dset = wf.create_dataset("data",(544,50,50,50))
62/11: del dset
62/12: dset = wf.create_dataset("data",(544,50,50,50))
62/13: wf.close()
62/14: wf = h5py.File('data.hdf5','w')
62/15: dset = wf.create_dataset("data",(544,50,50,50))
62/16: dset[:,:,:,:] = data[:,:,:,:]
62/17: wf.close()
62/18:
batch_size = 128
original_dim = 50*50*50
intermediate_dim = 10*10*10
latent_dim = 10
62/19:
batch_size = 128
original_dim = 50*50*50
intermediate_dim = 10*10
latent_dim = 10
62/20:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
62/21:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
62/22:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
62/23:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
62/24: from keras import objectives
62/25:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
62/26:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
62/27:
x_train = np.reshape(x_train, [-1, original_dim])
x_test = np.reshape(x_test, [-1, original_dim])
62/28:
epochs = 50
x_train.shape
62/29:
vae.fit(x_train, x_train,
        shuffle=True,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(x_test, x_test))
62/30:
batch_size = 128
original_dim = 50*50*50
intermediate_dim = 10*10*10
latent_dim = 10
62/31:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
62/32:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
62/33:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
62/34:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
62/35: from keras import objectives
62/36:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
62/37:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
62/38:
x_train = np.reshape(x_train, [-1, original_dim])
x_test = np.reshape(x_test, [-1, original_dim])
62/39:
epochs = 50
x_train.shape
62/40:
vae.fit(x_train, x_train,
        shuffle=True,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(x_test, x_test))
62/41: vae.summary
62/42: vae.summary()
62/43:
batch_size = 20
original_dim = 50*50*50
intermediate_dim = 25*25*25
latent_dim = 10
62/44:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
62/45:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
62/46:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
62/47:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
62/48: from keras import objectives
62/49:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
62/50:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
62/51:
x_train = np.reshape(x_train, [-1, original_dim])
x_test = np.reshape(x_test, [-1, original_dim])
62/52:
epochs = 50
x_train.shape
62/53: vae.summary()
62/54:
batch_size = 20
original_dim = 50*50*50
intermediate_dim = 10*10*10
latent_dim = 10
62/55:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
62/56:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
62/57:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
62/58:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
62/59: from keras import objectives
62/60:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
62/61:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
62/62:
x_train = np.reshape(x_train, [-1, original_dim])
x_test = np.reshape(x_test, [-1, original_dim])
62/63:
epochs = 50
x_train.shape
62/64: vae.summary()
62/65:
batch_size = 25
original_dim = 50*50*50
intermediate_dim = 10*10*10
latent_dim = 10
62/66:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
62/67:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
62/68:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
62/69:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
62/70: from keras import objectives
62/71:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
62/72:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
62/73:
x_train = np.reshape(x_train, [-1, original_dim])
x_test = np.reshape(x_test, [-1, original_dim])
62/74:
epochs = 50
x_train.shape
62/75: vae.summary()
62/76:
batch_size = 25
original_dim = 50*50*50
intermediate_dim = 5*5*5
latent_dim = 10
62/77:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
62/78:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
62/79:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
62/80:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
62/81: from keras import objectives
62/82:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
62/83:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
62/84:
x_train = np.reshape(x_train, [-1, original_dim])
x_test = np.reshape(x_test, [-1, original_dim])
62/85:
epochs = 50
x_train.shape
62/86: vae.summary()
63/1:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
62/87: data = get_data('ML-Antiperovskite',544,50,50,50,6)
62/88:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
62/89: data = get_data('ML-Antiperovskite',544,50,50,50,6)
62/90:
batch_size = 20
original_dim = 56*56*56
intermediate_dim = 7*7*7
latent_dim = 14
62/91:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
62/92:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
62/93:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
62/94:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
62/95: from keras import objectives
62/96:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
62/97:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
62/98:
x_train = np.reshape(x_train, [-1, original_dim])
x_test = np.reshape(x_test, [-1, original_dim])
62/99:
epochs = 50
x_train.shape
62/100: vae.summary()
62/101:
vae.fit(x_train, x_train,
        shuffle=True,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(x_test, x_test))
65/1:
import os
import pymatgen.io.vasp as vasp
import h5py
65/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D, Dense,Lambda
from keras.models import Model
from keras.optimizers import RMSprop
from keras import backend as K
65/3:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
65/4:
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
65/5: data.shape
65/6:
batch_size = 20
original_dim = 50*50*50
intermediate_dim = 7*7*7
latent_dim = 14
65/7:
batch_size = 20
original_dim = 50*50*50
intermediate_dim = 25
latent_dim = 25
65/8:
batch_size = 20
original_dim = 50*50*50
intermediate_dim = 25*25*25
latent_dim = 25
65/9:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
65/10:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
65/11:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
65/12:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
65/13: from keras import objectives
65/14:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
65/15:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
65/16:
x_train = np.reshape(x_train, [-1, original_dim])
x_test = np.reshape(x_test, [-1, original_dim])
65/17:
epochs = 50
x_train.shape
65/18: vae.summary()
65/19:
vae.fit(x_train, x_train,
        shuffle=True,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(x_test, x_test))
66/1:
import os
import pymatgen.io.vasp as vasp
import h5py
66/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D, Dense,Lambda
from keras.models import Model
from keras.optimizers import RMSprop
from keras import backend as K
66/3:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
66/4:
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
66/5: data = get_data('ML-Antiperovskite',544,50,50,50,6)
67/1:
import os
import pymatgen.io.vasp as vasp
import h5py
67/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D, Dense,Lambda
from keras.models import Model
from keras.optimizers import RMSprop
from keras import backend as K
67/3:
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
67/4: data.shape
67/5:
batch_size = 20
original_dim = 50*50*50
intermediate_dim = 25*25*25
latent_dim = 25
67/6:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
67/7:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
67/8:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
67/9:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
67/10: from keras import objectives
67/11:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
67/12:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
67/13:
x_train = np.reshape(x_train, [-1, original_dim])
x_test = np.reshape(x_test, [-1, original_dim])
67/14:
epochs = 50
x_train.shape
67/15: vae.summary()
67/16:
vae.fit(x_train, x_train,
        shuffle=True,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(x_test, x_test))
68/1:
import os
import pymatgen.io.vasp as vasp
import h5py
68/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D, Dense,Lambda
from keras.models import Model
from keras.optimizers import RMSprop
from keras import backend as K
68/3:
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
68/4:
import os
import pymatgen.io.vasp as vasp
import h5py
68/5:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D, Dense,Lambda
from keras.models import Model
from keras.optimizers import RMSprop
from keras import backend as K
68/6: data.shape
68/7:
batch_size = 40
original_dim = 50*50*50
intermediate_dim = 5*5*5
latent_dim = 25
68/8:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
68/9:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
68/10:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
68/11:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
68/12: from keras import objectives
68/13:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
68/14:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
68/15:
x_train = np.reshape(x_train, [-1, original_dim])
x_test = np.reshape(x_test, [-1, original_dim])
68/16:
epochs = 50
x_train.shape
68/17: vae.summary()
68/18:
vae.fit(x_train, x_train,
        shuffle=True,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(x_test, x_test))
68/19: Input?
68/20:
batch_size = 40
original_dim = 50*50*50
intermediate_dim = 5*5*5
latent_dim = 25
68/21:
batch_size = 40
original_dim = 50*50*50
intermediate_dim = 10*10*10
latent_dim = 25
68/22:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
68/23:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
68/24:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
68/25:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
68/26: from keras import objectives
68/27:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
68/28:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
68/29:
epochs = 50
x_train.shape
68/30: vae.summary()
68/31:
batch_size = 40
original_dim = 50*50*50
intermediate_dim = 10*10*10
latent_dim = 20
68/32:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
68/33:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
68/34:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
68/35:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
68/36: from keras import objectives
68/37:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
68/38:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
68/39:
x_train = np.reshape(x_train, [-1, original_dim])
x_test = np.reshape(x_test, [-1, original_dim])
68/40:
epochs = 50
x_train.shape
68/41: vae.summary()
68/42: vae.summary()
68/43:
vae.fit(x_train, x_train,
        shuffle=True,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(x_test, x_test))
68/44:
batch_size = 40
original_dim = 50*50*50
intermediate_dim = 25*25
latent_dim = 5
68/45:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
68/46:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
68/47:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
68/48:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
68/49: from keras import objectives
68/50:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
68/51:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
68/52:
x_train = np.reshape(x_train, [-1, original_dim])
x_test = np.reshape(x_test, [-1, original_dim])
68/53:
epochs = 50
x_train.shape
68/54: vae.summary()
68/55:
vae.fit(x_train, x_train,
        shuffle=True,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(x_test, x_test))
69/1:
import os
import pymatgen.io.vasp as vasp
import h5py
69/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D, Dense,Lambda
from keras.models import Model
from keras.optimizers import RMSprop
from keras import backend as K
69/3:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
69/4: data = get_data('ML-Antiperovskite',544,50,50,50,6)
69/5:
batch_size = 40
original_dim = 56*56*56
intermediate_dim = 14*14*14
latent_dim = 7*7
69/6:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
69/7:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
69/8:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
69/9:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
69/10: from keras import objectives
69/11:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
69/12:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
69/13:
x_train = np.reshape(x_train, [-1, original_dim])
x_test = np.reshape(x_test, [-1, original_dim])
69/14:
epochs = 50
x_train.shape
69/15: vae.summary()
69/16:
batch_size = 40
original_dim = 56*56*56
intermediate_dim = 14*14*14
latent_dim = 7*7*7
69/17:
x = Input(batch_shape=(batch_size, original_dim))
h = Dense(intermediate_dim, activation='relu')(x)
z_mean = Dense(latent_dim)(h)
z_log_sigma = Dense(latent_dim)(h)
69/18:
epsilon_std = 0.1
def sampling(args):
    epsilon_std = 0.1
    z_mean, z_log_sigma = args
    epsilon = K.random_normal(shape=(batch_size, latent_dim),
                              mean=0., stddev=epsilon_std)
    return z_mean + K.exp(z_log_sigma) * epsilon

# note that "output_shape" isn't necessary with the TensorFlow backend
# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`
z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])
69/19:
decoder_h = Dense(intermediate_dim, activation='relu')
decoder_mean = Dense(original_dim, activation='sigmoid')
h_decoded = decoder_h(z)
x_decoded_mean = decoder_mean(h_decoded)
69/20:
# end-to-end autoencoder
vae = Model(x, x_decoded_mean)

# encoder, from inputs to latent space
encoder = Model(x, z_mean)

# generator, from latent space to reconstructed inputs
decoder_input = Input(shape=(latent_dim,))
_h_decoded = decoder_h(decoder_input)
_x_decoded_mean = decoder_mean(_h_decoded)
generator = Model(decoder_input, _x_decoded_mean)
69/21: from keras import objectives
69/22:
def vae_loss(x, x_decoded_mean):
    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)
    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)
    return xent_loss + kl_loss

vae.compile(optimizer='rmsprop', loss=vae_loss)
69/23:
x_train = data[:400,:,:,:]
x_test = data[400:,:,:,:]
69/24:
x_train = np.reshape(x_train, [-1, original_dim])
x_test = np.reshape(x_test, [-1, original_dim])
69/25:
epochs = 50
x_train.shape
69/26: vae.summary()
69/27:
vae.fit(x_train, x_train,
        shuffle=True,
        epochs=epochs,
        batch_size=batch_size,
        validation_data=(x_test, x_test))
70/1:
from keras.layers import Input, Dense
from keras.models import Model
70/2: encoding_dim = 32
70/3:
input_img = Input(shape=(50*50*50,))
# "encoded" is the encoded representation of the input
encoded = Dense(encoding_dim, activation='relu')(input_img)
# "decoded" is the lossy reconstruction of the input
decoded = Dense(50*50*50, activation='sigmoid')(encoded)

# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
70/4:
# this model maps an input to its encoded representation
encoder = Model(input_img, encoded)
70/5:
# create a placeholder for an encoded (32-dimensional) input
encoded_input = Input(shape=(encoding_dim,))
# retrieve the last layer of the autoencoder model
decoder_layer = autoencoder.layers[-1]
# create the decoder model
decoder = Model(encoded_input, decoder_layer(encoded_input))
70/6: autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
70/7:
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
70/8:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
70/9:
from sklearn.model_selection import train_test_split
x_train,_,x_test,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
70/10:
from sklearn.model_selection import train_test_split
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
x_train,_,x_test,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
70/11:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print x_train.shape
print x_test.shape
70/12:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
70/13:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
70/14:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
70/15: train_data
70/16: train_data.shape
70/17: _.shape
70/18:
from sklearn.model_selection import train_test_split
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
70/19:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
70/20: autoencoder.summary()
70/21: autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
70/22:
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test))
70/23:
encoded_imgs = encoder.predict(x_test)
decoded_imgs = decoder.predict(encoded_imgs)
70/24:
import matplotlib.pyplot as plt

n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[0,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[0,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
70/25:
#import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[0,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[0,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
70/26:
#import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[25,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[25,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
72/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
72/2: encoding_dim = 50
72/3:
input_img = Input(shape=(50*50*50,))
# "encoded" is the encoded representation of the input
encoded = Dense(encoding_dim, activation='relu')(input_img)
# "decoded" is the lossy reconstruction of the input
decoded = Dense(50*50*50, activation='relu')(encoded)

# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
72/4:
# this model maps an input to its encoded representation
encoder = Model(input_img, encoded)
72/5:
# create a placeholder for an encoded (32-dimensional) input
encoded_input = Input(shape=(encoding_dim,))
# retrieve the last layer of the autoencoder model
decoder_layer = autoencoder.layers[-1]
# create the decoder model
decoder = Model(encoded_input, decoder_layer(encoded_input))
72/6: autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
72/7:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
72/8:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
72/9:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
72/10: autoencoder.summary()
72/11:
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test))
72/12:
encoded_imgs = encoder.predict(x_test)
decoded_imgs = decoder.predict(encoded_imgs)
72/13:
#import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[25,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[25,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
72/14:
import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[25,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[25,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
72/15:
import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[0,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[0,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
73/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
73/2: encoding_dim = 200
73/3:
input_img = Input(shape=(50*50*50,))
# "encoded" is the encoded representation of the input
encoded = Dense(encoding_dim, activation='relu')(input_img)
# "decoded" is the lossy reconstruction of the input
decoded = Dense(50*50*50, activation='relu')(encoded)

# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
73/4:
# this model maps an input to its encoded representation
encoder = Model(input_img, encoded)
73/5:
# create a placeholder for an encoded (32-dimensional) input
encoded_input = Input(shape=(encoding_dim,))
# retrieve the last layer of the autoencoder model
decoder_layer = autoencoder.layers[-1]
# create the decoder model
decoder = Model(encoded_input, decoder_layer(encoded_input))
73/6: autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
73/7:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
73/8:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
73/9:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
73/10: autoencoder.summary()
73/11:
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test))
73/12:
encoded_imgs = encoder.predict(x_test)
decoded_imgs = decoder.predict(encoded_imgs)
73/13:
import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[0,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[0,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
73/14:
import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[25,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[25,:,:])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
73/15:
import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[25,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[25,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
76/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
76/2: encoding_dim = 200
76/3:
input_img = Input(shape=(50*50*50,))
# "encoded" is the encoded representation of the input
encoded = Dense(encoding_dim, activation='relu',activity_regularizer=regularizers.l1(10e-5))(input_img)
# "decoded" is the lossy reconstruction of the input
decoded = Dense(50*50*50, activation='relu')(encoded)

# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
76/4:
from keras import regularizers

input_img = Input(shape=(50*50*50,))
# "encoded" is the encoded representation of the input
encoded = Dense(encoding_dim, activation='relu',activity_regularizer=regularizers.l1(10e-5))(input_img)
# "decoded" is the lossy reconstruction of the input
decoded = Dense(50*50*50, activation='relu')(encoded)

# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
76/5:
# this model maps an input to its encoded representation
encoder = Model(input_img, encoded)
76/6:
# create a placeholder for an encoded (32-dimensional) input
encoded_input = Input(shape=(encoding_dim,))
# retrieve the last layer of the autoencoder model
decoder_layer = autoencoder.layers[-1]
# create the decoder model
decoder = Model(encoded_input, decoder_layer(encoded_input))
76/7: autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
76/8:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
76/9:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
76/10:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
76/11: autoencoder.summary()
76/12:
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test))
76/13:
encoded_imgs = encoder.predict(x_test)
decoded_imgs = decoder.predict(encoded_imgs)
76/14:
import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[25,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[25,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
76/15:
import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[0,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[0,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
76/16:
import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[10,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[10,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
76/17:
import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[15,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[15,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
78/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
78/2:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50*50, activation='relu')(input_img)
encoded = Dense(50, activation='relu')(encoded)
encoded = Dense(25, activation='relu')(encoded)

decoded = Dense(50, activation='relu')(encoded)
decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
78/3:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
78/4:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
78/5:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
78/6:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
78/7:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
78/8: autoencoder.summary()
78/9:
autoencoder.fit(x_train, x_train,
                epochs=100,
                batch_size=50,
                shuffle=True,
                validation_data=(x_test, x_test))
78/10:
encoded_imgs = encoder.predict(x_test)
decoded_imgs = decoder.predict(encoded_imgs)
78/11: encoded_imgs = autoencoder.predict(x_test)
78/12: decoded_imgs = autoencoder.predict(x_test)
78/13:
import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[15,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[15,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
79/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
79/2:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50*50, activation='relu')(input_img)
encoded = Dense(50*25, activation='relu')(encoded)
encoded = Dense(50, activation='relu')(encoded)

decoded = Dense(50*25, activation='relu')(encoded)
decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
79/3:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
79/4:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
79/5:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
79/6:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
79/7:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
79/8: autoencoder.summary()
79/9:
autoencoder.fit(x_train, x_train,
                epochs=100,
                batch_size=50,
                shuffle=True,
                validation_data=(x_test, x_test))
80/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
80/2:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50*50, activation='relu')(input_img)
encoded = Dense(50*25, activation='relu')(encoded)
encoded = Dense(50, activation='relu')(encoded)

decoded = Dense(50*25, activation='relu')(encoded)
decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
80/3:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
80/4:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
80/5:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
80/6:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
80/7:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
80/8: autoencoder.summary()
80/9:
autoencoder.fit(x_train, x_train,
                epochs=100,
                batch_size=50,
                shuffle=True,
                validation_data=(x_test, x_test))
80/10: decoded_imgs = autoencoder.predict(x_test)
80/11:
import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[15,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[15,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
80/12:
import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[0,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[0,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
81/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
81/2:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50*50, activation='relu')(input_img)
encoded = Dense(50*25, activation='relu')(encoded)
encoded = Dense(1000, activation='relu')(encoded)

decoded = Dense(50*25, activation='relu')(encoded)
decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
81/3:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
81/4:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
81/5:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
81/6:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
81/7:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
81/8: autoencoder.summary()
81/9:
autoencoder.fit(x_train, x_train,
                epochs=100,
                batch_size=50,
                shuffle=True,
                validation_data=(x_test, x_test))
82/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
82/2:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50*50, activation='relu')(input_img)
encoded = Dense(50*25, activation='relu')(encoded)
encoded = Dense(1000, activation='relu')(encoded)
encoded = Dense(100, activation='relu')(encoded)
decoded = Dense(1000, activation='relu')(encoded)
decoded = Dense(50*25, activation='relu')(encoded)
decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
82/3:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
82/4:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
82/5:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
from keras.optimizers import RMSprop
82/6:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50*50, activation='relu')(input_img)
encoded = Dense(50*25, activation='relu')(encoded)
encoded = Dense(1000, activation='relu')(encoded)
encoded = Dense(100, activation='relu')(encoded)
decoded = Dense(1000, activation='relu')(encoded)
decoded = Dense(50*25, activation='relu')(encoded)
decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
82/7:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
82/8:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer=RMSprop(), loss='mean_squared_error')
82/9:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
82/10:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
82/11:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
82/12: autoencoder.summary()
82/13:
autoencoder.fit(x_train, x_train,
                epochs=100,
                batch_size=20,
                shuffle=True,
                validation_data=(x_test, x_test))
83/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
from keras.optimizers import RMSprop
83/2:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50*50, activation='relu')(input_img)
encoded = Dense(50*25, activation='relu')(encoded)
encoded = Dense(1000, activation='relu')(encoded)
encoded = Dense(100, activation='relu')(encoded)
decoded = Dense(1000, activation='relu')(encoded)
decoded = Dense(50*25, activation='relu')(encoded)
decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
83/3:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
83/4:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer=RMSprop(), loss='mean_squared_error')
83/5:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
83/6:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
83/7:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
83/8: autoencoder.summary()
83/9:
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=20,
                shuffle=True,
                validation_data=(x_test, x_test))
83/10: decoded_imgs = autoencoder.predict(x_test)
83/11:
import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[0,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[0,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
83/12:
import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[15,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[15,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
84/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
from keras.optimizers import RMSprop
84/2:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50*50, activation='relu')(input_img)
encoded = Dense(50*25, activation='relu')(encoded)
encoded = Dense(1000, activation='relu')(encoded)
encoded = Dense(100, activation='relu')(encoded)
decoded = Dense(1000, activation='relu')(encoded)
decoded = Dense(50*25, activation='relu')(encoded)
decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
84/3:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
84/4:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer=RMSprop(), loss='mean_squared_error')
84/5:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
84/6:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
84/7:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
84/8: autoencoder.summary()
84/9:
autoencoder.fit(x_train, x_train,
                epochs=100,
                batch_size=20,
                shuffle=True,
                validation_data=(x_test, x_test))
85/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
from keras.optimizers import RMSprop
85/2:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50*50, activation='relu')(input_img)
encoded = Dense(50*25, activation='relu')(encoded)
encoded = Dense(1000, activation='relu')(encoded)
encoded = Dense(100, activation='relu')(encoded)
decoded = Dense(1000, activation='relu')(encoded)
decoded = Dense(50*25, activation='relu')(encoded)
decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
85/3:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
85/4:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
85/5:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
85/6:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
85/7:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
85/8: autoencoder.summary()
85/9:
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=20,
                shuffle=True,
                validation_data=(x_test, x_test))
85/10: decoded_imgs = autoencoder.predict(x_test)
85/11:
import matplotlib.pyplot as plt
%matplotlib inline
n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(50,50,50)[15,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(50,50,50)[15,:,:],cmap='jet')
    
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
86/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
from keras.optimizers import RMSprop
86/2:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50000, activation='relu')(input_img)
#encoded = Dense(50*25, activation='relu')(encoded)
encoded = Dense(15000, activation='relu')(encoded)
#encoded = Dense(625, activation='relu')(encoded)
decoded = Dense(50000, activation='relu')(encoded)
#decoded = Dense(50*25, activation='relu')(encoded)
#decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
86/3:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
86/4:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
86/5:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
86/6:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
86/7:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
86/8: autoencoder.summary()
86/9:
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=20,
                shuffle=True,
                validation_data=(x_test, x_test))
88/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
from keras.optimizers import RMSprop
88/2:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50000, activation='relu')(input_img)
#encoded = Dense(50*25, activation='relu')(encoded)
encoded = Dense(15000, activation='relu')(encoded)
#encoded = Dense(625, activation='relu')(encoded)
#decoded = Dense(50000, activation='relu')(encoded)
#decoded = Dense(50*25, activation='relu')(encoded)
#decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
88/3:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
88/4:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
88/5:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50000, activation='relu')(input_img)
#encoded = Dense(50*25, activation='relu')(encoded)
encoded = Dense(15000, activation='relu')(encoded)
#encoded = Dense(625, activation='relu')(encoded)
decoded = Dense(50000, activation='relu')(encoded)
#decoded = Dense(50*25, activation='relu')(encoded)
#decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
88/6:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
88/7:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
88/8:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
88/9:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
88/10:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
88/11: autoencoder.summary()
88/12:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50000, activation='relu')(input_img)
#encoded = Dense(50*25, activation='relu')(encoded)
encoded = Dense(15000, activation='relu')(encoded)
#encoded = Dense(625, activation='relu')(encoded)
#decoded = Dense(50000, activation='relu')(encoded)
#decoded = Dense(50*25, activation='relu')(encoded)
#decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(encoded)
88/13:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
88/14:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
88/15:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
88/16:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
88/17:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
88/18: autoencoder.summary()
88/19:
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=20,
                shuffle=True,
                validation_data=(x_test, x_test))
89/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
from keras.optimizers import RMSprop
89/2:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50000, activation='relu')(input_img)
encoded = Dense(50*25, activation='relu')(encoded)
#encoded = Dense(15000, activation='relu')(encoded)
encoded = Dense(3000, activation='relu')(encoded)
#decoded = Dense(50000, activation='relu')(encoded)
decoded = Dense(50*25, activation='relu')(encoded)
decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
89/3:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
89/4:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
89/5:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
89/6:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
89/7:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
89/8: autoencoder.summary()
89/9:
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=20,
                shuffle=True,
                validation_data=(x_test, x_test))
90/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
from keras.optimizers import RMSprop
90/2:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50000, activation='relu')(input_img)
encoded = Dense(50*25, activation='relu')(encoded)
#encoded = Dense(15000, activation='relu')(encoded)
encoded = Dense(3000, activation='relu')(encoded)
#decoded = Dense(50000, activation='relu')(encoded)
decoded = Dense(50*25, activation='relu')(encoded)
decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
90/3:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
90/4:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
90/5:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
90/6:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
90/7:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
90/8: autoencoder.summary()
90/9:
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=20,
                shuffle=True,
                validation_data=(x_test, x_test))
92/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
from keras.optimizers import RMSprop
92/2:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50000, activation='relu')(input_img)
encoded = Dense(50*25, activation='relu')(encoded)
#encoded = Dense(15000, activation='relu')(encoded)
encoded = Dense(3000, activation='relu')(encoded)
#decoded = Dense(50000, activation='relu')(encoded)
decoded = Dense(50*25, activation='relu')(encoded)
decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
92/3:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
92/4:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
92/5:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
92/6:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
92/7:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
92/8: autoencoder.summary()
92/9:
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=20,
                shuffle=True,
                validation_data=(x_test, x_test))
94/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
from keras.optimizers import RMSprop
94/2:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50000, activation='relu')(input_img)
encoded = Dense(50*25, activation='relu')(encoded)
#encoded = Dense(15000, activation='relu')(encoded)
encoded = Dense(3000, activation='relu')(encoded)
#decoded = Dense(50000, activation='relu')(encoded)
decoded = Dense(50*25, activation='relu')(encoded)
decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
94/3:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
94/4:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
94/5:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
94/6:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
94/7:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
94/8: autoencoder.summary()
94/9:
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=20,
                shuffle=True,
                validation_data=(x_test, x_test))
95/1:
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
from keras.optimizers import RMSprop
95/2:
input_img = Input(shape=(50*50*50,))
encoded = Dense(50000, activation='relu')(input_img)
encoded = Dense(50*25, activation='relu')(encoded)
#encoded = Dense(15000, activation='relu')(encoded)
encoded = Dense(3000, activation='relu')(encoded)
#decoded = Dense(50000, activation='relu')(encoded)
decoded = Dense(50*25, activation='relu')(encoded)
#decoded = Dense(50*50, activation='relu')(decoded)
decoded = Dense(50*50*50, activation='sigmoid')(decoded)
95/3:
# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)
95/4:
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
95/5:
import h5py
rf = h5py.File('data.hdf5')
dset = rf['data']
data = dset[:,:,:,:]
rf.close()
95/6:
from sklearn.model_selection import train_test_split
train_data = data[:,:,:,:]
test_data = data[400:,:,:,:]
x_train,x_test,_,_ = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
95/7:
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)
95/8: autoencoder.summary()
95/9:
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=20,
                shuffle=True,
                validation_data=(x_test, x_test))
97/1:
import os
import pymatgen.io.vasp as vasp
97/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
97/3:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
97/4: data = get_data('ML-Antiperovskite',544,50,50,50)
97/5: data = get_data('ML-Antiperovskite',544,50,50,50,0)
97/6: data = get_data('ML-Antiperovskite',544,50,50,50,6)
97/7:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
97/8:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
97/9:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')
97/10:
train_data = train_data.reshape(-1, 50,50,50, 1)
test_data = test_data.reshape(-1, 50,50,50, 1)
train_data.shape, test_data.shape
97/11:
train_data = train_data.reshape(-1, 56,56,56, 1)
test_data = test_data.reshape(-1, 56,56,56, 1)
train_data.shape, test_data.shape
97/12: train_data.dtype, test_data.dtype
97/13: np.max(train_data), np.max(test_data)
97/14:
from sklearn.model_selection import train_test_split
train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
97/15:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 50,50,50
input_img = Input(shape = (x, y,z, inChannel))
97/16:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 56,56,56
input_img = Input(shape = (x, y,z, inChannel))
97/17:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #56x56x56 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #28x28x28 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #28x28x28 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #14x14x14 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #14x14x14 x 128 (small and thick)
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 128
    conv4 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 256 (small and thick)
    #decoder
    conv5 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(conv4) #7 x 7 x 256 (small and thick)
    up1   = UpSampling3D((2,2,2))(conv5) # 14 x 14 x 14 x 128
    conv6 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(up1) #7 x 7 x 128
    up2 = UpSampling3D((2,2,2))(conv6) # 14 x 14 x 128
    conv7 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up2) # 14 x 14 x 64
    up4 = UpSampling3D((2,2,2))(conv7) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up4) # 28 x 28 x 1
    return decoded
97/18: autoencoder = Model(input_img, autoencoder(input_img))
97/19: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
97/20: autoencoder.summary()
97/21:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
97/22: autoencoder = Model(input_img, autoencoder(input_img))
97/23: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
97/24: autoencoder.summary()
97/25:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
97/26: autoencoder = Model(input_img, autoencoder(input_img))
97/27: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
97/28: autoencoder.summary()
97/29:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 56,56,56
input_img = Input(shape = (x, y,z, inChannel))
97/30:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
97/31: autoencoder = Model(input_img, autoencoder(input_img))
97/32: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
97/33: autoencoder.summary()
97/34:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 56,56,56
input_img = Input(shape = (x, y,z, inChannel))
97/35:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #56x56x56 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #28x28x28 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #28x28x28 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #14x14x14 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #14x14x14 x 128 (small and thick)
    pool3 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 128
    conv4 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(pool3) #7 x 7 x 256 (small and thick)
    #decoder
    
    
    
    
    
    conv5 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(conv4) #7 x 7 x 256 (small and thick)
    up1   = UpSampling3D((2,2,2))(conv5) # 14 x 14 x 14 x 128
    conv6 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(up1) #7 x 7 x 128
    up2 = UpSampling3D((2,2,2))(conv6) # 14 x 14 x 128
    conv7 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up2) # 14 x 14 x 64
    up4 = UpSampling3D((2,2,2))(conv7) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up4) # 28 x 28 x 1
    return decoded
97/36: autoencoder = Model(input_img, autoencoder(input_img))
97/37: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
97/38: autoencoder.summary()
97/39:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #56x56x56 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #28x28x28 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #28x28x28 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #14x14x14 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #14x14x14 x 128 (small and thick)
    pool3 = MaxPooling3D(pool_size=(2, 2,2))(conv3) #7 x 7 x 128
    conv4 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(pool3) #7 x 7 x 256 (small and thick)
    #decoder

    
    
    
    
    conv5 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(conv4) #7 x 7 x 256 (small and thick)
    up1   = UpSampling3D((2,2,2))(conv5) # 14 x 14 x 14 x 128
    conv6 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(up1) #7 x 7 x 128
    up2 = UpSampling3D((2,2,2))(conv6) # 14 x 14 x 128
    conv7 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up2) # 14 x 14 x 64
    up4 = UpSampling3D((2,2,2))(conv7) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up4) # 28 x 28 x 1
    return decoded
97/40: autoencoder = Model(input_img, autoencoder(input_img))
97/41: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
97/42: autoencoder.summary()
97/43: autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))
99/1:
import os
import pymatgen.io.vasp as vasp
99/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
99/3:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
99/4: data = get_data('ML-Antiperovskite',544,50,50,50,6)
99/5:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
99/6:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
99/7:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')
99/8:
train_data = train_data.reshape(-1, 56,56,56, 1)
test_data = test_data.reshape(-1, 56,56,56, 1)
train_data.shape, test_data.shape
99/9: train_data.dtype, test_data.dtype
99/10: np.max(train_data), np.max(test_data)
99/11:
from sklearn.model_selection import train_test_split
train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
99/12:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 56,56,56
input_img = Input(shape = (x, y,z, inChannel))
99/13:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #56x56x56 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #28x28x28 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #28x28x28 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #14x14x14 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #14x14x14 x 128 (small and thick)
    pool3 = MaxPooling3D(pool_size=(2, 2,2))(conv3) #7 x 7 x 128
    conv4 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(pool3) #7 x 7 x 256 (small and thick)
    #decoder

    
    
    
    
    conv5 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(conv4) #7 x 7 x 256 (small and thick)
    up1   = UpSampling3D((2,2,2))(conv5) # 14 x 14 x 14 x 128
    conv6 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(up1) #7 x 7 x 128
    up2 = UpSampling3D((2,2,2))(conv6) # 14 x 14 x 128
    conv7 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up2) # 14 x 14 x 64
    up4 = UpSampling3D((2,2,2))(conv7) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up4) # 28 x 28 x 1
    return decoded
99/14: autoencoder = Model(input_img, autoencoder(input_img))
99/15: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
99/16: autoencoder.summary()
99/17: autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))
100/1:
import os
import pymatgen.io.vasp as vasp
100/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
100/3:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
100/4: data = get_data('ML-Antiperovskite',544,50,50,50,6)
100/5:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
100/6:
# Shapes of training set
print("Training set (images) shape: {shape}".format(shape=train_data.shape))

# Shapes of test set
print("Test set (images) shape: {shape}".format(shape=test_data.shape))
100/7:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')
100/8:
train_data = train_data.reshape(-1, 56,56,56, 1)
test_data = test_data.reshape(-1, 56,56,56, 1)
train_data.shape, test_data.shape
100/9: train_data.dtype, test_data.dtype
100/10: np.max(train_data), np.max(test_data)
100/11:
from sklearn.model_selection import train_test_split
train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
100/12:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 56,56,56
input_img = Input(shape = (x, y,z, inChannel))
100/13:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #56x56x56 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #28x28x28 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #28x28x28 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #14x14x14 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #14x14x14 x 128 (small and thick)
    pool3 = MaxPooling3D(pool_size=(2, 2,2))(conv3) #7 x 7 x 128
    conv4 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(pool3) #7 x 7 x 256 (small and thick)
    #decoder

    
    
    
    
    conv5 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(conv4) #7 x 7 x 256 (small and thick)
    up1   = UpSampling3D((2,2,2))(conv5) # 14 x 14 x 14 x 128
    conv6 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(up1) #7 x 7 x 128
    up2 = UpSampling3D((2,2,2))(conv6) # 14 x 14 x 128
    conv7 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up2) # 14 x 14 x 64
    up4 = UpSampling3D((2,2,2))(conv7) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up4) # 28 x 28 x 1
    return decoded
100/14:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #28 x 28 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #14 x 14 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #14 x 14 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #7 x 7 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)

    #decoder
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(conv3) #7 x 7 x 128
    up1 = UpSampling3D((2,2,2))(conv4) # 14 x 14 x 128
    conv5 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) # 14 x 14 x 64
    up2 = UpSampling3D((2,2,2))(conv5) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1
    return decoded
100/15:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #56x56x56 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #28x28x28 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #28x28x28 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #14x14x14 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #14x14x14 x 128 (small and thick)
    pool3 = MaxPooling3D(pool_size=(2, 2,2))(conv3) #7 x 7 x 128
    conv4 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(pool3) #7 x 7 x 256 (small and thick)
    #decoder

    
    
    
    
    conv5 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(conv4) #7 x 7 x 256 (small and thick)
    up1   = UpSampling3D((2,2,2))(conv5) # 14 x 14 x 14 x 128
    conv6 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(up1) #7 x 7 x 128
    up2 = UpSampling3D((2,2,2))(conv6) # 14 x 14 x 128
    conv7 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up2) # 14 x 14 x 64
    up4 = UpSampling3D((2,2,2))(conv7) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up4) # 28 x 28 x 1
    return decoded
100/16: autoencoder = Model(input_img, autoencoder(input_img))
100/17: autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
100/18: autoencoder.summary()
100/19: autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_ground))
108/1:
import os
import pymatgen.io.vasp as vasp
108/2:
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
108/3:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
108/4: data = get_data('ML-Antiperovskite',544,50,50,50,6)
108/5: ls
108/6:
import h5py 
rf = h5py.File('data56x56x56.hdf5','r')
data = rf['data'][:,:,:,:]
108/7:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
108/8:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')
108/9:
train_data = train_data.reshape(-1, 52,52,52, 1)
test_data = test_data.reshape(-1, 52,52,52, 1)
train_data.shape, test_data.shape
108/10:
train_data = train_data.reshape(-1, 56,56,56, 1)
test_data = test_data.reshape(-1, 56,56,56, 1)
train_data.shape, test_data.shape
108/11: np.max(train_data), np.max(test_data)
108/12:
from sklearn.model_selection import train_test_split
train_X,valid_X,train_ground,valid_ground = train_test_split(train_data,
                                                             train_data, 
                                                             test_size=0.2, 
                                                             random_state=13)
108/13: Model.load_weights?
108/14: autoencoder = Model.load_weights('50x50x50->7x7x7conv.hdf5')
108/15: autoencoder = Model.load_weights(filepath='50x50x50->7x7x7conv.hdf5')
108/16: autoencoder = Model?
108/17:
def autoencoder(input_img):
    #encoder
    #input = 28 x 28 x 1 (wide and thin)
    conv1 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(input_img) #56x56x56 x 32
    pool1 = MaxPooling3D(pool_size=(2, 2,2))(conv1) #28x28x28 x 32
    conv2 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool1) #28x28x28 x 64
    pool2 = MaxPooling3D(pool_size=(2, 2,2))(conv2) #14x14x14 x 64
    conv3 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool2) #14x14x14 x 128 (small and thick)
    pool3 = MaxPooling3D(pool_size=(2, 2,2))(conv3) #7 x 7 x 128
    conv4 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(pool3) #7 x 7 x 256 (small and thick)
    #decoder





    conv5 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(conv4) #7 x 7 x 256 (small and thick)
    up1   = UpSampling3D((2,2,2))(conv5) # 14 x 14 x 14 x 128
    conv6 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(up1) #7 x 7 x 128
    up2 = UpSampling3D((2,2,2))(conv6) # 14 x 14 x 128
    conv7 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(up2) # 14 x 14 x 64
    up4 = UpSampling3D((2,2,2))(conv7) # 28 x 28 x 64
    decoded = Conv3D(1, (3, 3,3), activation='sigmoid', padding='same')(up4) # 28 x 28 x 1
    return decoded
108/18:
batch_size = 20
epochs = 50
inChannel = 1
x, y,z = 56,56,56
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
108/19: autoencoder.load_weights('50x50x50->7x7x7conv.hdf5')
108/20: pred = autoencoder.predict(test_data)
108/21:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,15,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,15,:,:,0], cmap='jet')  
plt.show()
108/22:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,0,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,0,:,:,0], cmap='jet')  
plt.show()
108/23:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,10,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,10,:,:,0], cmap='jet')  
plt.show()
108/24:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
108/25:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(25,25*256,25)[25,:,:], cmap='jet')  
plt.show()
108/26: autoencoder.layers
108/27: autoencoder.layers[7]
108/28:
from keras import backend as K
get_3rd_layer_output = K.function([autoencoder.layers[0].input],
                                  [autoencoder.layers[7].output])
108/29: layer_output = get_3rd_layer_output([test_data])[0]
108/30:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(25,25*256,25)[25,:,:], cmap='jet')  
plt.show()
108/31: layer_output.shape
108/32:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[25,:,:], cmap='jet')  
plt.show()
108/33:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:,:], cmap='jet')  
plt.show()
108/34:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*128,7)[0,:,:], cmap='jet')  
plt.show()
108/35:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:,:], cmap='jet')  
plt.show()
108/36:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0:25,:,:], cmap='jet')  
plt.show()
108/37:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:7,:], cmap='jet')  
plt.show()
108/38:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:20,:], cmap='jet')  
plt.show()
108/39:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1, 10, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:20,:], cmap='jet')  
plt.show()
108/40:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(20, 10, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:20,:], cmap='jet')  
plt.show()
108/41:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(2,4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:20,:], cmap='jet')  
plt.show()
108/42:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(2,4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:40,:], cmap='jet')  
plt.show()
108/43:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(4,4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:40,:], cmap='jet')  
plt.show()
108/44:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1,10, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:40,:], cmap='jet')  
plt.show()
108/45:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1,40, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:40,:], cmap='jet')  
plt.show()
108/46:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(20,40, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:40,:], cmap='jet')  
plt.show()
108/47:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1,1, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:40,:], cmap='jet')  
plt.show()
108/48:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1,2, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:40,:], cmap='jet')  
plt.show()
108/49:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1,4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:40,:], cmap='jet')  
plt.show()
108/50:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1,4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[25,:40,:], cmap='jet')  
plt.show()
108/51:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1,4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:40,:], cmap='jet')  
plt.show()
108/52:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1,4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:40,:], cmap='jet')  
plt.show()
108/53:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
for i in range(4):
    plt.subplot(1,4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:40,:], cmap='jet')  
plt.show()
108/54:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
plt.figure(figsize=(20, 10))
for i in range(4):
    plt.subplot(1,4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:40,:], cmap='jet')  
plt.show()
108/55:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
plt.figure(figsize=(20, 10))
for i in range(4):
    plt.subplot(1,4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:,:], cmap='jet')  
plt.show()
108/56:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
plt.figure(figsize=(20, 10))
for i in range(4):
    plt.subplot(1,4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:100,:], cmap='jet')  
plt.show()
108/57:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
plt.figure(figsize=(20, 10))
for i in range(4):
    plt.subplot(1,4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:150,:], cmap='jet')  
plt.show()
108/58:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
plt.figure(figsize=(20, 10))
for i in range(4):
    plt.subplot(1,4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:200,:], cmap='jet')  
plt.show()
108/59:
plt.figure(figsize=(20, 10))
print("Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(test_data[i,25,:,:,0], cmap='jet')

plt.show()    
plt.figure(figsize=(20, 10))
print("Reconstruction of Test Images cut 1")
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(pred[i,25,:,:,0], cmap='jet')  
plt.show()
print("Reconstruction code")
plt.figure(figsize=(20, 10))
for i in range(4):
    plt.subplot(1,4, i+1)
    plt.imshow(layer_output[i].reshape(7,7*256,7)[0,:200,:200], cmap='jet')  
plt.show()
108/60: import scipy.ndimage as ndimage
108/61: test = ndimage.affine_transform(train_data[0],matrix=np.array([[1,0.5,0],[0,1,0],[0,0,1]]),output_shape=(56,56,56))
108/62: train_data[0].SHAPE
108/63: train_data[0].shape
108/64:
train_data = data[:400,:,:,:]
test_data = data[400:,:,:,:]
108/65: test = ndimage.affine_transform(train_data[0],matrix=np.array([[1,0.5,0],[0,1,0],[0,0,1]]),output_shape=(56,56,56))
108/66:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,49,:,:]

plt.imshow(curr_img, cmap='jet')
108/67:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,0,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,0,:,:]

plt.imshow(curr_img, cmap='jet')
108/68:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,:,:]

plt.imshow(curr_img, cmap='jet')
108/69:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[49,:,:]

plt.imshow(curr_img, cmap='jet')
108/70:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,0,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,:,:]

plt.imshow(curr_img, cmap='jet')
108/71: test = ndimage.affine_transform(train_data[0],matrix=np.array([[1,0.5,0],[0,1,0],[0,0,1]]),output_shape=(56,56,20))
108/72:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,0,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,:,:]

plt.imshow(curr_img, cmap='jet')
108/73: test = ndimage.affine_transform(train_data[0],matrix=np.array([[1,0.5,0],[0,1,0],[0,0,1]]),output_shape=(56,10,20))
108/74:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,0,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,:,:]

plt.imshow(curr_img, cmap='jet')
108/75: test = ndimage.affine_transform(train_data[0],matrix=np.array([[1,0.5,0],[0,1,0],[0,0,1]]),output_shape=(56,56,56))
108/76:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,0,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,:,:]

plt.imshow(curr_img, cmap='jet')
108/77:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,49,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[49,:,:]

plt.imshow(curr_img, cmap='jet')
108/78:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,20,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[20,:,:]

plt.imshow(curr_img, cmap='jet')
108/79: test = ndimage.affine_transform(train_data[0],matrix=np.array([[1,0.5,0],[0.5,1,0],[0,0,1]]),output_shape=(56,56,56))
108/80:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,20,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[20,:,:]

plt.imshow(curr_img, cmap='jet')
108/81:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,0,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,:,:]

plt.imshow(curr_img, cmap='jet')
108/82: test = ndimage.affine_transform(train_data[0],matrix=np.array([[1,0.75,0],[0.75,1,0],[0,0,1]]),output_shape=(56,56,56))
108/83:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,0,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,:,:]

plt.imshow(curr_img, cmap='jet')
108/84:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,10,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[10,:,:]

plt.imshow(curr_img, cmap='jet')
108/85: test = ndimage.affine_transform(train_data[0],matrix=np.array([[1,0,0],[0,1,0],[0,0,1]]),output_shape=(56,56,56))
108/86:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,10,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[10,:,:]

plt.imshow(curr_img, cmap='jet')
108/87: test = ndimage.affine_transform(train_data[0],matrix=np.array([[1,0.1,0],[0,1,0],[0,0,1]]),output_shape=(56,56,56))
108/88:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,10,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[10,:,:]

plt.imshow(curr_img, cmap='jet')
108/89: train = train_data[0]
108/90: train = np.pad(train,(56,56),'wrap')
108/91: train.shape
108/92: test = ndimage.affine_transform(train,matrix=np.array([[1,0.1,0],[0,1,0],[0,0,1]]),output_shape=(168,168,168))
108/93:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,10,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[10,:,:]

plt.imshow(curr_img, cmap='jet')
108/94:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train_data[0,0,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,:,:]

plt.imshow(curr_img, cmap='jet')
108/95: test = ndimage.affine_transform(train,matrix=np.array([[1,0.5,0],[0,1,0],[0,0,1]]),output_shape=(168,168,168))
108/96:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[0,0,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,:,:]

plt.imshow(curr_img, cmap='jet')
108/97:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[0,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,:,:]

plt.imshow(curr_img, cmap='jet')
108/98: train = train_data[0][:50,:50,:50]
108/99: train = np.pad(train,(50,50),'wrap')
108/100: train.shape
108/101: test = ndimage.affine_transform(train,matrix=np.array([[1,0.5,0],[0,1,0],[0,0,1]]),output_shape=(150,150,150))
108/102:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[0,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,:,:]

plt.imshow(curr_img, cmap='jet')
108/103:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[10,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[10,:,:]

plt.imshow(curr_img, cmap='jet')
108/104: test = ndimage.affine_transform(train,matrix=np.array([[1,0.5,0],[0,0.5,0],[0,0,1]]),output_shape=(150,150,150))
108/105:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[10,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[10,:,:]

plt.imshow(curr_img, cmap='jet')
108/106: test = ndimage.affine_transform(train,matrix=np.array([[1,0.5,0],[0,1,0],[0,0,1]]),output_shape=(150,150,150))
108/107:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[10,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[10,:,:]

plt.imshow(curr_img, cmap='jet')
108/108: test = ndimage.affine_transform(train,matrix=np.array([[1,0.5,0],[0.5,1,0],[0,0,1]]),output_shape=(150,150,150))
108/109:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[10,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[10,:,:]

plt.imshow(curr_img, cmap='jet')
108/110:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[20,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[20,:,:]

plt.imshow(curr_img, cmap='jet')
108/111: test = ndimage.affine_transform(train,matrix=np.array([[np.cos(30),-1*np.sin(30),0],[np.sin(30),np.cos(30),0],[0,0,1]]),output_shape=(150,150,150))
108/112:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[20,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[20,:,:]

plt.imshow(curr_img, cmap='jet')
108/113:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[0,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,:,:]

plt.imshow(curr_img, cmap='jet')
108/114: np.sin(3)
108/115: np.sin(30)
108/116: np.pi/6
108/117: a = 0.5235987755982988
108/118: test = ndimage.affine_transform(train,matrix=np.array([[np.cos(a),-1*np.sin(a),0],[np.sin(a),np.cos(a),0],[0,0,1]]),output_shape=(150,150,150))
108/119:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[0,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,:,:]

plt.imshow(curr_img, cmap='jet')
108/120:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[10,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[10,:,:]

plt.imshow(curr_img, cmap='jet')
108/121:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[20,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[20,:,:]

plt.imshow(curr_img, cmap='jet')
108/122:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[100,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[100,:,:]

plt.imshow(curr_img, cmap='jet')
108/123:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[150,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[150,:,:]

plt.imshow(curr_img, cmap='jet')
108/124:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[125,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[125,:,:]

plt.imshow(curr_img, cmap='jet')
108/125:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[130,:,:]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[130,:,:]

plt.imshow(curr_img, cmap='jet')
108/126:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[0,:,130]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[0,:,130]

plt.imshow(curr_img, cmap='jet')
108/127:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,130]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,130]

plt.imshow(curr_img, cmap='jet')
108/128:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,0]

plt.imshow(curr_img, cmap='jet')
108/129: test = ndimage.affine_transform(train,matrix=np.array([[1,0.5,0],[0.5,1,0],[0,0,1]]),output_shape=(150,150,150))
108/130:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,0]

plt.imshow(curr_img, cmap='jet')
108/131:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,20]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,20]

plt.imshow(curr_img, cmap='jet')
108/132: test = ndimage.affine_transform(train,matrix=np.array([[1,0.5,0],[0,1,0],[0,0,1]]),output_shape=(150,150,150))
108/133:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,20]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,20]

plt.imshow(curr_img, cmap='jet')
108/134: test = ndimage.affine_transform(train,matrix=np.array([[np.cos(a),-1*np.sin(a),0],[np.sin(a),np.cos(a),0],[0,0,1]]),output_shape=(150,150,150))
108/135:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,20]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,20]

plt.imshow(curr_img, cmap='jet')
108/136: train = test_data[0][:50,:50,:50]
108/137: train = np.pad(train,(50,50),'wrap')
108/138: train.shape
108/139: test = ndimage.affine_transform(train,matrix=np.array([[np.cos(a),-1*np.sin(a),0],[np.sin(a),np.cos(a),0],[0,0,1]]),output_shape=(150,150,150))
108/140: test = ndimage.affine_transform(train,matrix=np.array([[1,0.5,0],[0,1,0],[0,0,1]]),output_shape=(150,150,150))
108/141:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,20]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,20]

plt.imshow(curr_img, cmap='jet')
108/142:
test = ndimage.affine_transform(train,matrix=np.array([[7.745840, 0.000012,-0.000025],
                                                       [-3.872910,6.708194, 0.000039],
                                                       [-0.000060 0.000069 19.740944]]),output_shape=(150,150,150))
108/143:
test = ndimage.affine_transform(train,matrix=np.array([[7.745840, 0.000012,-0.000025],
                                                       [-3.872910,6.708194, 0.000039],
                                                       [-0.000060,0.000069,19.740944]]),output_shape=(150,150,150))
108/144:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,20]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,20]

plt.imshow(curr_img, cmap='jet')
108/145:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,0]

plt.imshow(curr_img, cmap='jet')
108/146:
trans = np.linalg.inv(np.array([[7.745840, 0.000012,-0.000025],
                                                       [-3.872910,6.708194, 0.000039],
                                                       [-0.000060,0.000069,19.740944]])
108/147:
trans = np.linalg.inv(np.array([[7.745840, 0.000012,-0.000025],
                                                       [-3.872910,6.708194, 0.000039],
                                                       [-0.000060,0.000069,19.740944]]))
108/148: test = ndimage.affine_transform(train,matrix=trans,output_shape=(150,150,150))
108/149:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,0]

plt.imshow(curr_img, cmap='jet')
108/150:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,20]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,20]

plt.imshow(curr_img, cmap='jet')
108/151:
trans = np.linalg.inv(np.array([[7.745840, 0.000012,-0.000025],
                                                       [-3.872910,6.708194, 0.000039],
                                                       [-0.000060,0.000069,19.740944]]))
108/152: trans
108/153: trans*20
108/154: test = ndimage.affine_transform(train,matrix=trans*10,output_shape=(150,150,150))
108/155:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,20]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,20]

plt.imshow(curr_img, cmap='jet')
108/156:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,0]

plt.imshow(curr_img, cmap='jet')
108/157:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,100]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,100]

plt.imshow(curr_img, cmap='jet')
108/158: test = ndimage.affine_transform(train,matrix=trans*10,output_shape=(150,150,150),mode='wrap')
108/159:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,100]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,100]

plt.imshow(curr_img, cmap='jet')
108/160: train = test_data[0][:50,:50,:50]
108/161:
trans = np.linalg.inv(np.array([[7.745840, 0.000012,-0.000025],
                                                       [-3.872910,6.708194, 0.000039],
                                                       [-0.000060,0.000069,19.740944]]))
108/162: test = ndimage.affine_transform(train,matrix=trans*10,output_shape=(150,150,150),mode='wrap')
108/163:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,100]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,100]

plt.imshow(curr_img, cmap='jet')
108/164:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,0]

plt.imshow(curr_img, cmap='jet')
108/165: test = ndimage.affine_transform(train,matrix=trans*10,output_shape=(50,50,50),mode='wrap')
108/166:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = train[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = test[:,:,0]

plt.imshow(curr_img, cmap='jet')
110/1:
import os
import pymatgen.io.vasp as vasp
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
110/2:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
110/3: data = get_data('ML-Antiperovskite',544,50,50,50,0)
110/4:
def get_label(path, num_dirs):
    label = []
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i > num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            #elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            #data[i,:,:,:] = elfcar.data['total']
            label.append(idir)
            i+=1
            
    return label
110/5: labels = get_label('ML-Antiperovskite',544)
110/6: labels
110/7: data_before = data[1]
110/8: import scipy.ndimage as ndimage
110/9:
trans = np.linalg.inv(np.array([[7.745840, 0.000012,-0.000025],
                                                       [-3.872910,6.708194, 0.000039],
                                                       [-0.000060,0.000069,19.740944]]))
110/10: test = ndimage.affine_transform(train,matrix=trans*10,output_shape=(50,50,50),mode='wrap')
110/11: data_after = ndimage.affine_transform(data_before,matrix=trans*10,output_shape=(50,50,50),mode='wrap')
110/12:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
110/13:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,10]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,10]

plt.imshow(curr_img, cmap='jet')
110/14:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:210]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,20]

plt.imshow(curr_img, cmap='jet')
110/15:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:20]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,20]

plt.imshow(curr_img, cmap='jet')
110/16:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,20]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,20]

plt.imshow(curr_img, cmap='jet')
110/17:
import scipy.ndimage as ndimage
import pychemia
110/18:
import scipy.ndimage as ndimage
import pychemia
110/19:

trans = np.linalg.inv(np.array([[7.745840, 0.000012,-0.000025],
                                                       [-3.872910,6.708194, 0.000039],
                                                       [-0.000060,0.000069,19.740944]]))
110/20: st = vasp.Poscar.from_file('ML-Antiperovskite/mp-772199_194/POSCAR')
110/21: st
110/22: st = st.structure
110/23: st = vasp.Poscar.from_file('ML-Antiperovskite/mp-772199_194/POSCAR').structure
110/24: st.lattice
110/25: st.lattice.a
110/26: st.lattice
110/27: a = st.lattice
110/28: a.cubic
110/29: a.cubic()
110/30: a.find_mapping
110/31: a.get_wigner_seitz_cell
110/32: a.abc
110/33: a.dot
110/34: a.get_recp_symmetry_operation
110/35: a.get_recp_symmetry_operation()
110/36: a.reciprocal_lattice
110/37: a.matrix
110/38: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(50,50,50),mode='wrap')
110/39:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,20]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,20]

plt.imshow(curr_img, cmap='jet')
110/40:

trans = np.linalg.inv(a.matrix)
110/41: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(50,50,50),mode='wrap')
110/42:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,20]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,20]

plt.imshow(curr_img, cmap='jet')
110/43: a = st.lattice.reciprocal_lattice
110/44: a.matrix
110/45: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(50,50,50),mode='wrap')
110/46:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,20]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,20]

plt.imshow(curr_img, cmap='jet')
110/47:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,10]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,10]

plt.imshow(curr_img, cmap='jet')
110/48:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
110/49: data_after = ndimage.affine_transform(data_before,matrix=np.linalg.inv(a.matrix),output_shape=(50,50,50),mode='wrap')
110/50:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
110/51: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(50,50,50),mode='wrap')
110/52:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
110/53:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,10]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,10]

plt.imshow(curr_img, cmap='jet')
110/54: data_before = np.pad(data[1],(50,50),'wrap')
110/55: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(50,50,50),mode='wrap')
110/56:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,10]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,10]

plt.imshow(curr_img, cmap='jet')
110/57: data_before.shape
110/58: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(150,150,150),mode='wrap')
110/59:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,10]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,10]

plt.imshow(curr_img, cmap='jet')
110/60:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
110/61:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,1]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,1]

plt.imshow(curr_img, cmap='jet')
110/62:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,2]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,2]

plt.imshow(curr_img, cmap='jet')
110/63:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,2]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,3]

plt.imshow(curr_img, cmap='jet')
110/64:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,2]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/65:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:42]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/66:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/67:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
111/1: import pymatge.io.vasp as vasp
111/2: import pymatgen.io.vasp as vasp
111/3: procar = vasp.Procar('PROCAR')
111/4: procar
111/5: procar.data
111/6: procar.data.shape
111/7: procar.data.keys
111/8: procar.data.keys()
111/9: procar.data.keys()[0]
111/10: procar.data.keys()[0]
111/11: procar.nkpoints
111/12: procar.phase_factors
111/13: procar.data
112/1:
from pyprocar import ProcarSelect
from pyprocar import ProcarParser
from pyprocar import repair
112/2: repair('PROCAR','PROCAR-rep')
112/3:
                procarFile = ProcarParser()
                procarFile.readFile('PROCAR-rep', False)
                data = ProcarSelect(procarFile, deepCopy=True)
112/4: data
112/5: data.bands
112/6: data.bands.shape
112/7: data.kpoints
112/8: data.kpoints.shape
110/68:
import scipy.ndimage as ndimage
#import pychemia
110/69: st = vasp.Poscar.from_file('ML-Antiperovskite/mp-772199_194/POSCAR').structure
110/70: a = st.lattice.reciprocal_lattice
110/71: a.matrix
110/72: data_before.shape
110/73:
data_before = np.pad(data[1],(50,50),'wrap')
data_before = data[1]
110/74:
import scipy.ndimage as ndimage
#import pychemia
110/75: st = vasp.Poscar.from_file('ML-Antiperovskite/mp-772199_194/POSCAR').structure
110/76: a = st.lattice.reciprocal_lattice
110/77: a.matrix
110/78: data_before.shape
110/79: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(150,150,150),mode='wrap')
110/80:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/81: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(200,200,200),mode='wrap')
110/82:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/83: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(400,400,400),mode='wrap')
110/84:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/85: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(50,50,50),mode='wrap')
110/86:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/87: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(80,80,80),mode='wrap')
110/88:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/89: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(100,100,100),mode='wrap')
110/90:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/91: 100/2/2
110/92: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
110/93:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/94: 128/2/2/2
110/95: 128/2/2/2/2
110/96: 128/2/2/2/2/2
110/97:
data_before = np.pad(data[1],(50,50),'wrap')
data_before = data[2]
110/98:
import scipy.ndimage as ndimage
#import pychemia
110/99: st = vasp.Poscar.from_file('ML-Antiperovskite/mp-772199_194/POSCAR').structure
110/100: a = st.lattice.reciprocal_lattice
110/101: a.matrix
110/102: data_before.shape
110/103: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
110/104:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/105: st = vasp.Poscar.from_file('ML-Antiperovskite/mp-1018635_221/POSCAR').structure
110/106: a = st.lattice.reciprocal_lattice
110/107: a.matrix
110/108: data_before.shape
110/109: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
110/110:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/111: 1.49159983*4
110/112: 20/1.49159983
110/113: 1.49159983*4
110/114: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(256,256,256),mode='wrap')
110/115:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/116: 1.49159983*8
110/117: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
110/118:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/119:
data_before = np.pad(data[1],(50,50),'wrap')
data_before = data[5]
110/120: st = vasp.Poscar.from_file('ML-Antiperovskite/mp-3779_221/POSCAR').structure
110/121: a = st.lattice.reciprocal_lattice
110/122: a.matrix
110/123: data_before.shape
110/124: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
110/125:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/126:
data_before = np.pad(data[1],(50,50),'wrap')
data_before = data[0]
110/127:
import scipy.ndimage as ndimage
#import pychemia
110/128: st = vasp.Poscar.from_file('ML-Antiperovskite/mp-579496_221/POSCAR').structure
110/129: a = st.lattice.reciprocal_lattice
110/130: a.matrix
110/131: data_before.shape
110/132: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
110/133:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/134: 1.49159983*4
110/135: 1.6278184*4
110/136: 1.49159983*5
110/137:
data_before = np.pad(data[1],(50,50),'wrap')
data_before = data[2]
110/138:
import scipy.ndimage as ndimage
#import pychemia
110/139: st = vasp.Poscar.from_file('ML-Antiperovskite/mp-1018635_221/POSCAR').structure
110/140: a = st.lattice.reciprocal_lattice
110/141: a.matrix
110/142: data_before.shape
110/143: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
110/144:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/145: 1.49159983*4
110/146:
data_before = np.pad(data[1],(50,50),'wrap')
data_before = data[4]
110/147: st = vasp.Poscar.from_file('ML-Antiperovskite/mp-648984_61/POSCAR').structure
110/148: a = st.lattice.reciprocal_lattice
110/149: a.matrix
110/150: data_before.shape
110/151: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
110/152:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/153:
#data_before = np.pad(data[1],(50,50),'wrap')
j = 20
data_before = data[j]
110/154:
import scipy.ndimage as ndimage
#import pychemia
110/155: st = vasp.Poscar.from_file('ML-Antiperovskite/'+labels[j]+'/POSCAR').structure
110/156: st = vasp.Poscar.from_file('ML-Antiperovskite/'+labels[j]+'/POSCAR').structure
110/157: a = st.lattice.reciprocal_lattice
110/158: a.matrix
110/159: data_before.shape
110/160: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
110/161:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/162: print(labels[j])
110/163:
j = 22
print(labels[j])
110/164:
#data_before = np.pad(data[1],(50,50),'wrap')

data_before = data[j]
110/165: st = vasp.Poscar.from_file('ML-Antiperovskite/'+labels[j]+'/POSCAR').structure
110/166: a = st.lattice.reciprocal_lattice
110/167: a.matrix
110/168: data_before.shape
110/169: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
110/170:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/171: 128/2/2/2/2/2
110/172:
j = 23
print(labels[j])
110/173:
j = 24
print(labels[j])
110/174:
j = 26
print(labels[j])
110/175:
j = 90
print(labels[j])
110/176:
j = 91

print(labels[j])
110/177:
j = 96

print(labels[j])
110/178:
j = 23

print(labels[j])
110/179:
j = 45

print(labels[j])
110/180:
j = 46

print(labels[j])
110/181:
#data_before = np.pad(data[1],(50,50),'wrap')

data_before = data[j]
110/182: st = vasp.Poscar.from_file('ML-Antiperovskite/'+labels[j]+'/POSCAR').structure
110/183: a = st.lattice.reciprocal_lattice
110/184: a.matrix
110/185: data_before.shape
110/186: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
110/187:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/188:
j = 47

print(labels[j])
110/189:
j = 48

print(labels[j])
110/190:
j = 49

print(labels[j])
110/191:
j = 50

print(labels[j])
110/192:
j = 63

print(labels[j])
110/193:
j = 62

print(labels[j])
110/194:
j = 68

print(labels[j])
110/195:
j = 69

print(labels[j])
110/196:
j = 70

print(labels[j])
110/197:
j = 71

print(labels[j])
110/198:
j = 72

print(labels[j])
110/199:
j = 73

print(labels[j])
110/200:
j = 74

print(labels[j])
110/201:
#data_before = np.pad(data[1],(50,50),'wrap')

data_before = data[j]
110/202: st = vasp.Poscar.from_file('ML-Antiperovskite/'+labels[j]+'/POSCAR').structure
110/203: a = st.lattice.reciprocal_lattice
110/204: a.matrix
110/205: data_before.shape
110/206: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
110/207:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,4]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,4]

plt.imshow(curr_img, cmap='jet')
110/208:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,15]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,15]

plt.imshow(curr_img, cmap='jet')
110/209:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
110/210:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,30]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,30]

plt.imshow(curr_img, cmap='jet')
110/211:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,50]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,50]

plt.imshow(curr_img, cmap='jet')
110/212:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,49]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,49]

plt.imshow(curr_img, cmap='jet')
110/213:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,29]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,29]

plt.imshow(curr_img, cmap='jet')
110/214:
data_before = np.pad(data[j],(50,50),'wrap')

#data_before = data[j]
110/215: st = vasp.Poscar.from_file('ML-Antiperovskite/'+labels[j]+'/POSCAR').structure
110/216: a = st.lattice.reciprocal_lattice
110/217: a.matrix
110/218: data_before.shape
110/219: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
110/220:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,29]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,29]

plt.imshow(curr_img, cmap='jet')
110/221:
data_before = np.pad(data[j],(128,128),'wrap')

#data_before = data[j]
110/222: st = vasp.Poscar.from_file('ML-Antiperovskite/'+labels[j]+'/POSCAR').structure
110/223: a = st.lattice.reciprocal_lattice
110/224: a.matrix
110/225: data_before.shape
110/226: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
110/227:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,29]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,29]

plt.imshow(curr_img, cmap='jet')
110/228:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,29]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,29]

plt.imshow(curr_img, cmap='jet')
110/229:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,30]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,30]

plt.imshow(curr_img, cmap='jet')
110/230:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,40]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,40]

plt.imshow(curr_img, cmap='jet')
110/231: data_before.shape
114/1:
import h5py
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_455_729_160.hdf5')
data_procar = rf['data']
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
114/2: pwd
114/3: ls
114/4: cd ML-Antiperovskite/
114/5: cd "ML-Antiperovskite/"
115/1:
import h5py
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_455_729_160.hdf5')
data_procar = rf['data']
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
115/2:
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
115/3:
train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 128,128,128, 1)
test_data_elf  = test_data_elf.reshape(-1,128,128,128,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
115/4: from keras.models import load_model
115/5: autoencoder = load_model('ELF2PROCAR-1stTry.hdf5')
115/6: pred = autoencoder.predict(test_data_elf)
117/1:

import h5py
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_455_729_160.hdf5')
data_procar = rf['data']
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
117/2:
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
117/3:
train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 128,128,128, 1)
test_data_elf  = test_data_elf.reshape(-1,128,128,128,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
117/4: from keras.models import load_model
117/5: autoencoder = load_model('ELF2PROCAR-1stTry.hdf5')
117/6: pred = autoencoder.predict(test_data_elf)
117/7: pred
117/8: pred.shape
117/9: test_data_procar.shape
117/10: test_data_procar
117/11: pred
117/12: pred[0]
117/13: pred[0][0]
117/14: pred[0][0][0]
117/15: pred
118/1:
import h5py
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_455_729_160.hdf5')
data_procar = rf['data']
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
118/2:
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
118/3:
train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 128,128,128, 1)
test_data_elf  = test_data_elf.reshape(-1,128,128,128,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
118/4: from keras.models import load_model
118/5: autoencoder = load_model('ELF2PROCAR-1stTry.hdf5')
118/6: pred = autoencoder.predict(test_data_elf)
118/7: pred
119/1:
import h5py
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
119/2:
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
119/3:
train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 128,128,128, 1)
test_data_elf  = test_data_elf.reshape(-1,128,128,128,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
119/4: from keras.models import load_model
119/5: autoencoder = load_model('ELF2PROCAR-1stTry.hdf5')
119/6: pred = autoencoder.predict(test_data_elf)
119/7: pred
119/8: pred = autoencoder.predict(train_data_elf[0])
119/9: test_data_elf.shape
119/10: train_data_elf.shape
119/11: train_data_elf[0].shape
119/12: train_data_elf[0].reshape(1,-1,-1,-1,1).reshape
119/13: train_data_elf[0].reshape(1,-1,-1,-1,1).shape
119/14:
train_data_elf[0].reshape((1,128,128,128,1
                          )).shape
119/15: pred = autoencoder.predict(train_data_elf[0].reshape((1,128,128,128,1)))
119/16: pred
120/1:
import h5py
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
120/2:
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
120/3:
train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 128,128,128, 1)
test_data_elf  = test_data_elf.reshape(-1,128,128,128,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
120/4: from keras.models import load_model
120/5: autoencoder = load_model('ELF2PROCAR-net-1-batch10.hdf5')
120/6: pred = autoencoder.predict(test_data_elf)
120/7: pred
120/8: test_data_procar
120/9: pred[0]
120/10: test_data_procar[0]
120/11: pred[1]
120/12: test_data_procar[1]
120/13: pred[2]
120/14: test_data_procar[3]
120/15: test_data_procar[2]
120/16: pred[3]
120/17: test_data_procar[3]
120/18: pred[4]
120/19: test_data_procar[5]
120/20: pred[4].abs()
120/21: np.absolute(pred[4])-np.absolute(test_data_procar[4])
120/22: np.absolute(pred[4]-test_data_procar[4])
120/23: np.absolute(pred[4]-test_data_procar[4]).sum()
120/24:
for i in range(len(pred)):
    print(np.absolute(pred[i]-test_data_procar[i]).sum())
120/25:
for i in range(len(pred)):
    print(np.absolute(pred[i]-test_data_procar[i]).sum(),i)
120/26: test_data_procar[35]
120/27: pred[35]
120/28: pred[0]
120/29: pred[4]
120/30: test_data_procar[4]
120/31: pred[3]
120/32: test_data_procar[3]
120/33: test_data_procar[4]
120/34: test_data_procar[0]
120/35: test_data_procar[1]
120/36: test_data_procar[2]
120/37: pred[2]
121/1:
import os
import pymatgen.io.vasp as vasp
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
121/2:
import scipy.ndimage as ndimage
#import pychemia
121/3: data = get_data('ML-Antiperovskite',544,50,50,50,0)
121/4:
def get_data(path, num_dirs,ngx,ngy,ngz,wrap):
    data = np.zeros(shape=(num_dirs,ngx+wrap,ngy+wrap,ngz+wrap))
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i >= num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data[i,:,:,:] = np.pad(elfcar.data['total'], (0, wrap), 'wrap') 
            i+=1
            
    return data
121/5: data = get_data('ML-Antiperovskite',544,50,50,50,0)
121/6:
def get_label(path, num_dirs):
    label = []
    ls = os.listdir(path)
    i = 0
    for idir in ls :
        if i > num_dirs :
            continue
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            #elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            #data[i,:,:,:] = elfcar.data['total']
            label.append(idir)
            i+=1
            
    return label
121/7: labels = get_label('ML-Antiperovskite',544)
121/8: labels
121/9:
j = 74

print(labels[j])
121/10:
data_before = np.pad(data[j],(128,128),'wrap')

#data_before = data[j]
121/11: data_before.shape
121/12: st = vasp.Poscar.from_file('ML-Antiperovskite/'+labels[j]+'/POSCAR').structure
121/13: a = st.lattice.reciprocal_lattice
121/14: a.matrix
121/15: data_before.shape
121/16: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
121/17:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,40]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,40]

plt.imshow(curr_img, cmap='jet')
121/18: a.a
121/19: a.b
121/20: a.c
121/21:
def get_data(path):
    data = []
    ls = os.listdir(path)
    
    for idir in ls :
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data.append(elfcar.data['total'])
    return data
121/22: data = get_data('isym-1_nbands80/')
121/23:
def get_label(path):
    label = []
    ls = os.listdir(path)
    
    for idir in ls :
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            label.append(idir)
    return label
121/24: labels = get_label('ML-Antiperovskite',544)
121/25: labels = get_label('isym-1_nbands80/')
121/26: labels
121/27:
#data_before = np.pad(data[j],(128,128),'wrap')

data_before = data[j]
121/28: data_before.shape
121/29: st = vasp.Poscar.from_file('ML-Antiperovskite/'+labels[j]+'/POSCAR').structure
121/30: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/31: a = st.lattice.reciprocal_lattice
121/32: a.matrix
121/33: a.c
121/34: data_before.shape
121/35: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
121/36:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,40]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,40]

plt.imshow(curr_img, cmap='jet')
121/37:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/38: data
121/39:
for idata in data:
    print(idata.shape)
121/40:
#data_before = np.pad(data[j],(128,128),'wrap')
j
data_before = data[j]
121/41:
#data_before = np.pad(data[j],(128,128),'wrap')
print(j)

data_before = data[j]
121/42:
#data_before = np.pad(data[j],(128,128),'wrap')
j=0

data_before = data[j]
121/43:
for idata in data:
    print(idata.shape)
121/44: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/45: a = st.lattice.reciprocal_lattice
121/46: a.matrix
121/47: a.c
121/48: data_before.shape
121/49: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(128,128,128),mode='wrap')
121/50:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/51: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(100,100,100),mode='wrap')
121/52:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/53: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(50,50,50),mode='wrap')
121/54:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/55: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(48,48,48),mode='wrap')
121/56:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/57:
#data_before = np.pad(data[j],(128,128),'wrap')
j=20

data_before = data[j]
121/58:
for idata in data:
    print(idata.shape)
121/59:
for idata in data:
    print(idata.shape)
121/60: data[20].shape
121/61:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 30

data_before = data[j]
121/62:
for idata in data:
    print(idata.shape)
121/63: data[j].shape
121/64: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/65: a = st.lattice.reciprocal_lattice
121/66: a.matrix
121/67: a.c
121/68: data_before.shape
121/69: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(36,36,36),mode='wrap')
121/70:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/71: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(45,45,45),mode='wrap')
121/72:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/73: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(36,36,36),mode='wrap')
121/74:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/75:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 12

data_before = data[j]
121/76:
for idata in data:
    print(idata.shape)
121/77: data[j].shape
121/78: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/79: a = st.lattice.reciprocal_lattice
121/80: a.matrix
121/81: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=data_before.shape,mode='wrap')
121/82:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/83:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 60

data_before = data[j]
121/84:
for idata in data:
    print(idata.shape)
121/85: data[j].shape
121/86: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/87: a = st.lattice.reciprocal_lattice
121/88: a.matrix
121/89: a.c
121/90: data_before.shape
121/91: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=data_before.shape,mode='wrap')
121/92:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/93:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 89

data_before = data[j]
121/94:
for idata in data:
    print(idata.shape)
121/95: data[j].shape
121/96: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/97: a = st.lattice.reciprocal_lattice
121/98: a.matrix
121/99: a.c
121/100: data_before.shape
121/101: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=data_before.shape,mode='wrap')
121/102:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/103:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 120

data_before = data[j]
121/104:
for idata in data:
    print(idata.shape)
121/105: data[j].shape
121/106:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 123

data_before = data[j]
121/107:
for idata in data:
    print(idata.shape)
121/108: data[j].shape
121/109: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/110: a = st.lattice.reciprocal_lattice
121/111: a.matrix
121/112: a.c
121/113: data_before.shape
121/114: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=data_before.shape,mode='wrap')
121/115:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/116:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 124

data_before = data[j]
121/117:
for idata in data:
    print(idata.shape)
121/118: data[j].shape
121/119:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 125

data_before = data[j]
121/120:
for idata in data:
    print(idata.shape)
121/121: data[j].shape
121/122:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 126

data_before = data[j]
121/123:
for idata in data:
    print(idata.shape)
121/124: data[j].shape
121/125:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 127

data_before = data[j]
121/126:
for idata in data:
    print(idata.shape)
121/127: data[j].shape
121/128:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 128

data_before = data[j]
121/129:
for idata in data:
    print(idata.shape)
121/130: data[j].shape
121/131: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/132: a = st.lattice.reciprocal_lattice
121/133: a.matrix
121/134: a.c
121/135: data_before.shape
121/136: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=data_before.shape,mode='wrap')
121/137:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/138:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 130

data_before = data[j]
121/139:
for idata in data:
    print(idata.shape)
121/140: data[j].shape
121/141: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/142: a = st.lattice.reciprocal_lattice
121/143: a.matrix
121/144: a.c
121/145: data_before.shape
121/146: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=data_before.shape,mode='wrap')
121/147:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/148:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 18

data_before = data[j]
121/149:
for idata in data:
    print(idata.shape)
121/150: data[j].shape
121/151: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/152: a = st.lattice.reciprocal_lattice
121/153: a.matrix
121/154: a.c
121/155: data_before.shape
121/156: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=data_before.shape,mode='wrap')
121/157:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/158:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 19

data_before = data[j]
121/159:
for idata in data:
    print(idata.shape)
121/160: data[j].shape
121/161: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/162: a = st.lattice.reciprocal_lattice
121/163: a.matrix
121/164: a.c
121/165: data_before.shape
121/166: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=data_before.shape,mode='wrap')
121/167:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/168:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 17

data_before = data[j]
121/169:
for idata in data:
    print(idata.shape)
121/170: data[j].shape
121/171: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/172: a = st.lattice.reciprocal_lattice
121/173: a.matrix
121/174: a.c
121/175: data_before.shape
121/176: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=data_before.shape,mode='wrap')
121/177:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/178:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 16

data_before = data[j]
121/179:
for idata in data:
    print(idata.shape)
121/180: data[j].shape
121/181: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/182: a = st.lattice.reciprocal_lattice
121/183: a.matrix
121/184: a.c
121/185: data_before.shape
121/186: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=data_before.shape,mode='wrap')
121/187:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/188: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
121/189:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/190:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 30

data_before = data[j]
121/191:
for idata in data:
    print(idata.shape)
121/192: data[j].shape
121/193:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 100

data_before = data[j]
121/194:
for idata in data:
    print(idata.shape)
121/195:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 98

data_before = data[j]
121/196:
for idata in data:
    print(idata.shape)
121/197: data[j].shape
121/198:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 62

data_before = data[j]
121/199:
for idata in data:
    print(idata.shape)
121/200: data[j].shape
121/201: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/202: a = st.lattice.reciprocal_lattice
121/203: a.matrix
121/204: a.c
121/205: data_before.shape
121/206: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
121/207:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/208: lattice = st.lattice.matrix
121/209:
lattice = st.lattice.matrix
lattice
121/210:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 62

data_before = data[j]
121/211:
for idata in data:
    print(idata.shape)
121/212: data[j].shape
121/213: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/214: a = st.lattice.reciprocal_lattice
121/215:
lattice = st.lattice.matrix
lattice
121/216: data_before.shape
121/217: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
121/218:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/219:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 30

data_before = data[j]
121/220:
for idata in data:
    print(idata.shape)
121/221: data[j].shape
121/222: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/223:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 10

data_before = data[j]
121/224:
for idata in data:
    print(idata.shape)
121/225: data[j].shape
121/226:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 9

data_before = data[j]
121/227:
for idata in data:
    print(idata.shape)
121/228: data[j].shape
121/229:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 3

data_before = data[j]
121/230:
for idata in data:
    print(idata.shape)
121/231: data[j].shape
121/232: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/233: a = st.lattice.reciprocal_lattice
121/234:
lattice = st.lattice.matrix
lattice
121/235: data_before.shape
121/236: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
121/237:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/238:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 23

data_before = data[j]
121/239:
for idata in data:
    print(idata.shape)
121/240: data[j].shape
121/241:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 60

data_before = data[j]
121/242:
for idata in data:
    print(idata.shape)
121/243: data[j].shape
121/244:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 120
data_before = data[j]
121/245:
for idata in data:
    print(idata.shape)
121/246: data[j].shape
121/247:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 16array([[[-67.60236 ],
        [-67.60235 ],
        [-67.60233 ],
        ...,
        [ 35.72254 ],
        [ 35.722565],
        [ 35.970333]],
data_before = data[j]
121/248:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 16
data_before = data[j]
121/249:
for idata in data:
    print(idata.shape)
121/250: data[j].shape
121/251:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 160
data_before = data[j]
121/252:
for idata in data:
    print(idata.shape)
121/253: data[j].shape
121/254: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/255: a = st.lattice.reciprocal_lattice
121/256:
lattice = st.lattice.matrix
lattice
121/257: data_before.shape
121/258: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
121/259:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/260:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 230
data_before = data[j]
121/261:
for idata in data:
    print(idata.shape)
121/262: data[j].shape
121/263: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
121/264: a = st.lattice.reciprocal_lattice
121/265:
lattice = st.lattice.matrix
lattice
121/266: data_before.shape
121/267: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
121/268:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
121/269:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 420
data_before = data[j]
121/270:
for idata in data:
    print(idata.shape)
121/271: data[j].shape
123/1:
import h5py
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_455_729_160.hdf5')
data_procar = rf['data']
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
123/2:
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
123/3:
train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 128,128,128, 1)
test_data_elf  = test_data_elf.reshape(-1,128,128,128,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
123/4:
def autoencoder(input_img):
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3) # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(972, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(486, (3, 3), activation='linear', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(243, (3, 3), activation='linear', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
123/5:

batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
123/6:
def autoencoder(input_img):
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3) # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(972, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(486, (3, 3), activation='linear', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(243, (3, 3), activation='linear', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
123/7:
def autoencoder(input_img): # 128x128x128 >>>> 729x160
    #encoder
    #input = 128 x 128 x 128 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #128x128x128 x 30
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 64x64x64 x 30
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #64x64x64 x 60
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #32x32x32 x 60
    conv3 = Conv3D(90, (3, 3,3), activation='relu', padding='same')(pool2) #32x32x32 x 90 (small and thick)
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #16x16x16 x 90
    conv4 = Conv3D(180, (3, 3,3), activation='relu', padding='same')(pool3) # 16x16x16 x 180 (small and thick)
    #decoder


    flat = Flatten()(conv4) # 737280 x 1
    reshape = Reshape((9,5,16384))(flat) # 9x5x16384
    conv5 = Conv2D(4096, (3, 3), activation='relu', padding='same')(reshape) # 9x5x4096 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x4096
    conv6 = Conv2D(1024, (3, 3), activation='linear', padding='same')(up1) # 27x10x1024
    up2 = UpSampling2D((3,4))(conv6) # 81x40x1024
    conv7 = Conv2D(256, (3, 3), activation='linear', padding='same')(up2) # 81x40x256
    up4 = UpSampling2D((9,4))(conv7) # 729x160x256

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
123/8:

batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 128,128,128
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
123/9:
def autoencoder(input_img):
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
#    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
   flat = Flatten()(pool2) #43740 x 1 # 87480 x 1
    reshape = Reshape((9,5,972))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='linear', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='linear', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
123/11:

batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
123/12:

batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
123/13:
def autoencoder(input_img):
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
#    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
   flat = Flatten()(pool2) #43740 x 1 # 87480 x 1
    reshape = Reshape((9,5,972))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='linear', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(120, (3, 3), activation='linear', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
123/15:
def autoencoder(input_img):
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
#    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
   flat = Flatten()(pool2) #43740 x 1 # 87480 x 1
    reshape = Reshape((9,5,972))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='linear', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(120, (3, 3), activation='linear', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
123/17:
def autoencoder(input_img):
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
#    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(pool2) #43740 x 1 # 87480 x 1
    reshape = Reshape((9,5,972))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='linear', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(120, (3, 3), activation='linear', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
123/18:

batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
123/19:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
123/20: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
123/21: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
123/22:

train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
123/23:
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_455_729_160.hdf5')
data_procar = rf['data']
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
123/24:

train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
123/25: data_elf.shape
123/26:
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
123/27:

train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
123/28: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
123/29:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
123/30: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
123/31: autoencoder.save('ELF2PROCAR-2ndTry-81>729x160.hdf5')
123/32: pred = autoencoder.predict(test_data_elf)
123/33: pred[0]
123/34: train_data_procar[0]
123/35: pred - train_data_procar
123/36: pred - test_data_procar
123/37: abs(pred) - abs(test_data_procar)
123/38: (abs(pred) - abs(test_data_procar))[0]
123/39: pred[0]
123/40: train_data_procar[0]
123/41: pred[1]
123/42: pred[2]
123/43: pred[3]
123/44: pred[4]
123/45: pred[5]
123/46: train[5]
123/47: train_data_procar[5]
124/1:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
124/2:
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 128,128,128, 1)
test_data_elf  = test_data_elf.reshape(-1,128,128,128,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
124/3:
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
124/4:
def autoencoder(input_img): # 3rdTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
   flat = Flatten()(pool2)  # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='linear', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='linear', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
124/6:
def autoencoder(input_img): # 3rdTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(pool2)  # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='linear', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='linear', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
124/7:


batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
124/8:

def autoencoder(input_img): # 3rdTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='linear', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='linear', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
124/9:


batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
124/10: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
124/11: pred = autoencoder.predict(test_data_elf)
124/12: pred[0]
124/13: test_data_procar
124/14: pred[0]
124/15: test_data_procar[0]
124/16: autoencoder.save('ELF2PROCAR-3rdTry-81>729x160.hdf5')
125/1:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
125/2:
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
125/3:
def autoencoder(input_img): # 4th Try
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='linear', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='linear', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='linear', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='linear', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='linear', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='linear', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
125/4:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
125/5: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
125/6: autoencoder.save('ELF2PROCAR-4thTry-81>729x160-Linear.hdf5')
125/7: loss = autoencoder_train.history['loss']
125/8: val_loss = autoencoder_train['val_loss']
125/9: val_loss = autoencoder_train.history['val_loss']
125/10: a = np.zeros((50,2))
125/11: a[:,0]=loss
125/12: a[:,1] = val_loss
125/13: np.savetxt?
125/14: np.savetxt('loss34Try.txt',a)
125/15: np.savetxt('loss4thTry.txt',a,fmt='%4.5f',header = 'loss,val_loss')
125/16: cat loss4thTry.txt
126/1:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
126/2:
def autoencoder(input_img): # 5th Try
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='relu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
126/3:

batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
126/4: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
126/5: loss = autoencoder_train.history['loss']
126/6: val_loss = autoencoder_train.history['val_loss']
126/7: a = np.zeros((50,2))
126/8: a[:,1] = val_loss
126/9: a[:,0]=loss
126/10: np.savetxt('loss5thTry.txt',a,fmt='%4.5f',header = 'loss,val_loss')
126/11: autoencoder.save('ELF2PROCAR-5thTry-81>729x160-Relu-sigmoid-Linear.hdf5')
127/1:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
127/2:

def autoencoder(input_img): # 6th Try
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='sigmoid', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
127/3:

batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
127/4: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
127/5: loss = autoencoder_train.history['loss']
127/6: val_loss = autoencoder_train.history['val_loss']
127/7: a = np.zeros((50,2))
127/8: a[:,0]=loss
127/9: a[:,1] = val_loss
127/10: np.savetxt('loss6thTry.txt',a,fmt='%4.5f',header = 'loss,val_loss')
127/11: autoencoder.save('ELF2PROCAR-5thTry-81>729x160.hdf5')
128/1:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
128/2:

def autoencoder(input_img): # 6th Try
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
128/3:

batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
128/4: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
128/5: loss = autoencoder_train.history['loss']
128/6: val_loss = autoencoder_train.history['val_loss']
128/7: a = np.zeros((50,2))
128/8: a[:,0]=loss
128/9: a[:,1] = val_loss
128/10: np.savetxt('loss7thTry.txt',a,fmt='%4.5f',header = 'loss,val_loss')
128/11: autoencoder.save('ELF2PROCAR-7thTry-81>729x160relu-elu-sigmoid-linear.hdf5')
128/12: pred = autoencoder.predict(test_data_elf)
128/13: pred[0]
128/14: test_data_procar[0]
129/1:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
129/2:
def autoencoder(input_img): #8th Try
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    encoded = Dense(87480, activation='relu')(conv3)
    encoded = Dense(43740, activation='relu')(encoded)
    encoded = Dense(21870, activation='relu')(encoded)
    
    decoded = Dense(43740, activation='relu')(encoded)
    decoded = Dense(87480, activation='relu')(decoded)

    reshape = Reshape((9,5,1944))(decoded) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
129/3:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
129/4: from keras.layer import Dense
129/5: from keras.layers import Dense
129/6:
def autoencoder(input_img): #8th Try
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    encoded = Dense(87480, activation='relu')(conv3)
    encoded = Dense(43740, activation='relu')(encoded)
    encoded = Dense(21870, activation='relu')(encoded)
    
    decoded = Dense(43740, activation='relu')(encoded)
    decoded = Dense(87480, activation='relu')(decoded)

    reshape = Reshape((9,5,1944))(decoded) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
129/7:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
129/8:
def autoencoder(input_img): #8th Try
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    encoded = Dense(87480, activation='relu')(conv3)
    encoded = Dense(43740, activation='relu')(encoded)
    encoded = Dense(21870, activation='relu')(encoded)
    
    decoded = Dense(43740, activation='relu')(encoded)
    decoded = Dense(87480, activation='sigmoid')(decoded)

    reshape = Reshape((9,5,1944))(decoded) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
129/9:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
129/10:
def autoencoder(input_img): #8th Try
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    encoded = Dense(87480, activation='relu')(flat)
    encoded = Dense(43740, activation='relu')(encoded)
    encoded = Dense(21870, activation='relu')(encoded)
    
    decoded = Dense(43740, activation='relu')(encoded)
    decoded = Dense(87480, activation='sigmoid')(decoded)

    reshape = Reshape((9,5,1944))(decoded) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
129/11:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
129/12: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
130/1:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D,Dense
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
130/2:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
130/3:
def autoencoder(input_img): #8th Try
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    encoded = Dense(87480, activation='relu')(flat)
    decoded = Dense(43740, activation='relu')(encoded)
    decoded = Dense(87480, activation='sigmoid')(decoded)

    reshape = Reshape((9,5,1944))(decoded) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
130/4:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
130/5:
def autoencoder(input_img): #8th Try with 100 epoch
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
130/6:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
130/7:
batch_size = 20
epochs = 100
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
130/8:
def autoencoder(input_img): #8th Try with 100 epoch
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
130/9:
batch_size = 20
epochs = 100
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
130/10: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
131/1:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D,Dense
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
131/2:
def autoencoder(input_img): #8th Try
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='valid')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='valid')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='valid')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='valid')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='valid')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='valid')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='valid')(up4) # 729x160x1
    return decoded
131/3:
batch_size = 20
epochs = 100
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
131/4:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
131/5:
def autoencoder(input_img): #8th Try
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='valid')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='valid')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='valid')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='valid')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='valid')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='valid')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='valid')(up4) # 729x160x1
    return decoded
131/6:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
131/7:
def autoencoder(input_img): #7th Try
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
131/8:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
131/9:
def autoencoder(input_img): #7th Try
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='valid')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='valid')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='valid')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='valid')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='valid')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='valid')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='valid')(up4) # 729x160x1
    return decoded
131/10:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
131/11:
def autoencoder(input_img): #7th Try
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='casual')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='casual')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='casual')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(486, (3, 3), activation='relu', padding='casual')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='casual')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='casual')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='casual')(up4) # 729x160x1
    return decoded
131/12:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
131/13:
def autoencoder(input_img): #7th Try
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(120, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)

    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,1944))(flat) # 9x5x1944
    conv5 = Conv2D(972, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(486, (3, 3), activation='elu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(243, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
131/14:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
131/15: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
131/16: a = np.zeros((50,2))
131/17: loss = autoencoder_train.history['loss']
131/18: val_loss = autoencoder_train.history['val_loss']
131/19: a[:,1] = val_loss
131/20: a[:,0]=loss
131/21: np.savetxt('loss8thTry.txt',a,fmt='%4.5f',header = 'loss,val_loss')
131/22:
autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data


a
)
131/23: autoencoder.save('ELF2PROCAR-8thTry-81>729x160relu-elu-sigmoid-linear.hdf5')
131/24: pred = autoencoder.predict(test_data_elf)
131/25: pred[0]
131/26: test_data_procar[0]
132/1:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D,Dense
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
132/2:
def autoencoder(input_img): #9th Try
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(240, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)
    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,3888))(flat) # 9x5x1944
    conv5 = Conv2D(972, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(486, (3, 3), activation='elu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(243, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
132/3:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
132/4: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
132/5: a = np.zeros((50,2))
132/6: loss = autoencoder_train.history['loss']
132/7: val_loss = autoencoder_train.history['val_loss']
132/8: a[:,0]=loss
132/9: a[:,1] = val_loss
132/10: np.savetxt('loss9thTry.txt',a,fmt='%4.5f',header = 'loss,val_loss')
132/11: autoencoder.save('ELF2PROCAR-9thTry-81>729x160relu-elu-sigmoid-linear.hdf5')
133/1:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D,Dense
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
133/2:
def autoencoder(input_img): #10th Try batch 10
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(240, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)
    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,3888))(flat) # 9x5x1944
    conv5 = Conv2D(972, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(486, (3, 3), activation='elu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(243, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    decoded = D
    return decoded
133/3:
batch_size = 10
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
133/4:
batch_size = 10
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
133/5:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D,Dense
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
133/6:
batch_size = 10
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
133/7:
batch_size = 40
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
133/8:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
133/9:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D,Dense
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
133/10:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
134/1:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D,Dense
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
134/2:
batch_size = 10
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
134/3:
def autoencoder(input_img): #10th Try batch 10
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(240, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)
    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,3888))(flat) # 9x5x1944
    conv5 = Conv2D(972, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(486, (3, 3), activation='elu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(243, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    
    return decoded
134/4:
batch_size = 10
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
134/5: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
134/6: loss = autoencoder_train.history['loss']
134/7: val_loss = autoencoder_train.history['val_loss']
134/8: a = np.zeros((50,2))
134/9: a[:,1] = val_loss
134/10: a[:,0]=loss
134/11: np.savetxt('loss10thTry.txt',a,fmt='%4.5f',header = 'loss,val_loss')
134/12: autoencoder.summary
134/13: autoencoder.summary()
134/14: autoencoder.save('ELF2PROCAR-10thTry-81>729x160relu-elu-sigmoid-linear.hdf5')
134/15: pred = autoencoder.predict(test_data_elf)
134/16: pred[0]
134/17: test_data_procar[0]
135/1:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D,Dense
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
135/2:
def autoencoder(input_img): #11th Try batch
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(240, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)
    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,3888))(flat) # 9x5x1944
    conv5 = Conv2D(972, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(486, (3, 3), activation='elu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(243, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243
    decoded = Conv2D(1, (3, 3), activation='tanh', padding='same')(up4) # 729x160x1
    return decoded
135/3:
batch_size = 10
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
135/4: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
136/1:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D,Dense
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
136/2:
def autoencoder(input_img): #11th Try batch
    #encoder
    #in put = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 32
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 32
    conv2 = Conv3D(60, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 64
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 64
    conv3 = Conv3D(240, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 120 (small and thick)
    #decoder
    flat = Flatten()(conv3)  # 87480 x 1
    reshape = Reshape((9,5,3888))(flat) # 9x5x1944
    conv5 = Conv2D(972, (3, 3), activation='relu', padding='same')(reshape) # 9x5x972 (small and thick)
    up1   = UpSampling2D((3,2))(conv5) # 27x10x972
    conv6 = Conv2D(486, (3, 3), activation='elu', padding='same')(up1) # 27x10x486
    up2 = UpSampling2D((3,4))(conv6) # 81x40x486
    conv7 = Conv2D(243, (3, 3), activation='tanh', padding='same')(up2) # 81x40x243
    up4 = UpSampling2D((9,4))(conv7) # 729x160x243
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 729x160x1
    return decoded
136/3:
batch_size = 10
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
136/4: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
136/5: pred = autoencoder.predict(test_data_elf)
136/6: pred[0]
136/7: test_data_procar[2]
136/8: loss = autoencoder_train.history['loss']
136/9: val_loss = autoencoder_train.history['val_loss']
136/10: a = np.zeros((50,2))
136/11: a[:,0]=loss
136/12: a[:,1] = val_loss
136/13: np.savetxt('loss11thTry.txt',a,fmt='%4.5f',header = 'loss,val_loss')
136/14: autoencoder.save('ELF2PROCAR-11thTry-81>729x160relu-elu-sigmoid-linear.hdf5')
136/15: pred-test_data_procar
136/16: (pred-test_data_procar).np.abs
136/17: abs(pred-test_data_procar)
136/18: abs(pred-test_data_procar).sum
136/19: abs(pred-test_data_procar).sum()
136/20: abs(pred[0]-test_data_procar[0]).sum()
136/21: abs(pred-test_data_procar).sum()/80
136/22: pred-test_data_procar
137/1: from pyprocar import ProcarSelect,ProcarParser,repair,UtilsProcar
137/2: ls
137/3: path = '..'
137/4: path = '../'
137/5: idir = 'mp-10036'
137/6: procarFile = ProcarParser()
137/7: procarFile.readFile(path+os.sep+idir+os.sep+'PROCAR-rep', False)
137/8: import os
137/9: procarFile.readFile(path+os.sep+idir+os.sep+'PROCAR-rep', False)
137/10: data = ProcarSelect(procarFile, deepCopy=True)
137/11: data.kpoints.shape
137/12: data.kpoints[:,2] = 0
137/13: data = ProcarSelect(procarFile, deepCopy=True)
137/14: data.kpoints[:,2] == 0
137/15: data.kpoints[data.kpoints[:,2] == 0]
137/16: cond1 = data.kpoints[:,2] == 0
137/17: cond2 = data.kpoints[:,1] == 0
137/18: cond3 = data.kpoints[:,0] >=0
137/19: cond1
137/20: cond1 +cond2
137/21: import numpy as np
137/22: np.bitwise_and?
137/23: np.bitwise_and([True,False],[True,True])
137/24: np.bitwise_and(cond1,cond2)
137/25: np.bitwise_and(cond1,cond2,cond3)
137/26: data.kpoints[np.bitwise_and(cond1,cond2,cond3)]
137/27: cond3 = data.kpoints[:,0] >= 0.1
137/28: data.kpoints[np.bitwise_and(cond1,cond2,cond3)]
137/29: data.kpoints[np.bitwise_and(cond1,cond2)]
137/30: cond12 = np.bitwise_and(cond1,cond2)
137/31: data.kpoints[np.bitwise_and(cond12,cond3)]
137/32: cond3
137/33: data.kpoints[cond3]
137/34: cond3 = data.kpoints[:,0] <0
137/35: data.kpoints[cond3]
137/36: cond3 = data.kpoints[:,0] <= 0
137/37: data.kpoints[cond3]
137/38: cond3 = data.kpoints[:,0] >= 0
137/39: data.kpoints[cond3]
137/40: data.kpoints[np.bitwise_and(cond12,cond3)]
137/41: data.bands
137/42: data.bands[np.bitwise_and(cond12,cond3)]
137/43: import matplotlib.pylab as plt
137/44:
for iband in data.bands[np.bitwise_and(cond12,cond3)]:
    plt.plot(iband)
137/45: iband.shape
137/46:
for iband in data.bands[np.bitwise_and(cond12,cond3)]:
    plt.plot(iband[::2])
137/47: iband
137/48: iband[::2]
137/49: iband[::1]
137/50: iband[::3]
137/51: iband[::2]
137/52: iband
137/53: iband[::2]
137/54: iband[:2]
137/55: iband[::1]
137/56: iband
137/57: iband[2::]
137/58: iband[0::2]
137/59: iband[0::2].shape
137/60: iband
137/61: iband[0::1].shape
137/62: iband[0::2].shape
137/63: np.arange(0,20,20)
137/64: np.arange(0,20,1)
137/65: np.arange(0,20,1)[::2]
137/66: iband[0::2]
137/67: iband
137/68: iband[1::2]
137/69: iband[1::2].shape
137/70:
for iband in data.bands[np.bitwise_and(cond12,cond3)]:
    plt.plot(iband[0::2],np.linspace(0,1,80))
    plt.plot(iband[1::2],np.linspace(0,1,80))
137/71:
for iband in data.bands[np.bitwise_and(cond12,cond3)]:
    plt.plot(np.linspace(0,1,80),iband[0::2])
    plt.plot(np.linspace(0,1,80),iband[1::2])
137/72: iband
137/73: plt.plot(iband)
137/74:
for iband in data.bands[np.bitwise_and(cond12,cond3)]:
    plt.plot(np.linspace(0,1,80),iband[0:79])
    plt.plot(np.linspace(0,1,80),iband[79:159])
137/75:
for iband in data.bands[np.bitwise_and(cond12,cond3)]:
    plt.plot(np.linspace(0,1,80),iband[0:79])
    plt.plot(np.linspace(0,1,80),iband[79:159])
137/76: iband
137/77: iband[0:79]
137/78: iband[0:79].shape
137/79: iband[0:80].shape
137/80: iband[0:80]
137/81: iband[80]
137/82: iband[80:160]
137/83:
for iband in data.bands[np.bitwise_and(cond12,cond3)]:
    plt.plot(np.linspace(0,1,80),iband[0:80])
    plt.plot(np.linspace(0,1,80),iband[80,160])
137/84:
for iband in data.bands[np.bitwise_and(cond12,cond3)]:
    plt.plot(np.linspace(0,1,80),iband[0:80])
    plt.plot(np.linspace(0,1,80),iband[80:160])
137/85: data.bands.shape
137/86: data.bands[np.bitwise_and(cond12,cond3)]
137/87:
for iband in data.bands[np.bitwise_and(cond12,cond3)]:
    plt.plot(np.linspace(0,1,80),iband[0:80])
    plt.plot(np.linspace(0,1,80),iband[80:160])
137/88: data.bands.shape
137/89: data.spd
137/90: data.spd.shape
137/91: data.bands
137/92:
for iband in data.bands[np.bitwise_and(cond12,cond3)]:
    plt.plot(np.linspace(0,1,80),iband[0:80])
    plt.plot(np.linspace(0,1,80),iband[80:160])
137/93: data.bands[np.bitwise_and(cond12,cond3)]
137/94: data.bands[np.bitwise_and(cond12,cond3)].shape
137/95: data.bands[np.bitwise_and(cond12,cond3)].reshape(160,-1)
137/96: data.bands[np.bitwise_and(cond12,cond3)].reshape(160,-1).shape
137/97: data.bands[np.bitwise_and(cond12,cond3)].reshape(160,-1)
137/98: data.bands[np.bitwise_and(cond12,cond3)].reshape(160,-1)[0]
137/99: data.bands[np.bitwise_and(cond12,cond3)].reshape(160,-1)[1]
137/100:
for iband in data.bands[np.bitwise_and(cond12,cond3)].reshape(160,-1):
    plt.plot(iband)
137/101:
for iband in data.bands[np.bitwise_and(cond12,cond3)].reshape(160,-1):
    plt.plot(np.linspace(0,1,5),iband,c='blue')
137/102: pwd
137/103:
                outcarparser = UtilsProcar()
                e_fermi = outcarparser.FermiOutcar(path+os.sep+idir+os.sep+'OUTCAR')
137/104: e_fermi
137/105: data.bands = data.bands - e_fermi
137/106:
for iband in data.bands[np.bitwise_and(cond12,cond3)].reshape(160,-1):
    plt.plot(np.linspace(0,1,5),iband,c='blue')
137/107:
for iband in data.bands[np.bitwise_and(cond12,cond3)].reshape(160,-1):
    plt.plot(np.linspace(0,1,5),iband,c='blue')
137/108: plt.xlim(-2,2)
137/109: plt.show()
137/110:
for iband in data.bands[np.bitwise_and(cond12,cond3)].reshape(160,-1):
    plt.plot(np.linspace(0,1,5),iband,c='blue')
137/111: plt.ylim(-2,2)
137/112:
for iband in data.bands[np.bitwise_and(cond12,cond3)].reshape(160,-1):
    plt.plot(np.linspace(0,1,5),iband,c='blue')
137/113: np.bitwise_and(cond12,cond3)
137/114: np.where(np.bitwise_and(cond12,cond3))
137/115: np.where(np.bitwise_and(cond12,cond3))[0]
137/116: np.where(np.bitwise_and(cond12,cond3))[0]
137/117: data.kpoints[np.where(np.bitwise_and(cond12,cond3))[0]]
138/1: plt.ylim(-2,2)
138/2: from keras.models import load_model
138/3: autoencoder = load_model('ELF2PROCAR-9thTry-81>729x160relu-elu-sigmoid-linear.hdf5')
138/4:
import h5py
rf = h5py.File('data_elfs_455_128_128_128.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_455_729_160.hdf5')
data_procar = rf['data']
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
138/5:
import h5py
rf = h5py.File('data_elfs_455_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_455_729_160.hdf5')
data_procar = rf['data']
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,729,160,1)
test_data_procar  = test_data_procar.reshape(-1,729,160,1)
138/6: pred = autoencoder.predict(test_data_elf)
138/7: test_data_procar.shape
138/8: test_data_procar[0]
138/9: test_data_procar[0].shape
138/10: test_data_procar[0][[0,1,2,3,4]]
138/11: test_data_procar[0][0]
138/12: test_data_procar[0][0].shape
138/13: test_data_procar[0][[0,1,2,3,4]]
138/14: test_data_procar[0][[0,1,2,3,4]].reshape(160,-1)
138/15: test_data_procar[0][[0,1,2,3,4]].reshape(160,-1).shape
138/16: test_data_procar[0][[0,1,2,3,4]].reshape(160,-1)
138/17: test_data_procar[0][[0,1,2,3,4]].reshape(160,-1)
138/18: import maplotlib.pylab as plt
138/19: import matplotlib.pylab as plt
138/20:
for iband in test_data_procar[0][[0,1,2,3,4]].reshape(160,-1):
    plt.plot(np.linspace(0,1,5),iband,c='blue')
138/21:
for iband in pred[0][[0,1,2,3,4]].reshape(160,-1):
    plt.plot(np.linspace(0,1,5),iband,c='red')
138/22: plt.ylim(-2,2)
138/23:
for iband in test_data_procar[0][[0,1,2,3,4]].reshape(160,-1):
    plt.plot(np.linspace(0,1,5),iband,c='blue')
138/24:
for iband in pred[0][[0,1,2,3,4]].reshape(160,-1):
    plt.plot(np.linspace(0,1,5),iband,c='red')
138/25:
for iband in test_data_procar[1][[0,1,2,3,4]].reshape(160,-1):
    plt.plot(np.linspace(0,1,5),iband,c='blue')
138/26:
for iband in pred[1][[0,1,2,3,4]].reshape(160,-1):
    plt.plot(np.linspace(0,1,5),iband,c='red')
138/27:
for iband in pred[1][[0,1,2,3,4]].reshape(160,-1):

    plt.scatter(np.linspace(0,1,5),iband,c='red')
138/28:
for iband in test_data_procar[1][[0,1,2,3,4]].reshape(160,-1):
    plt.scatter(np.linspace(0,1,5),iband,c='blue')
138/29:
for iband in test_data_procar[1][[0,1,2,3,4]].reshape(160,-1)[20:40]:
    plt.scatter(np.linspace(0,1,5),iband,c='blue')
138/30:
for iband in pred[1][[0,1,2,3,4]].reshape(160,-1)[20:40]:

    plt.scatter(np.linspace(0,1,5),iband,c='red')
137/118:
for iband in data.bands[np.bitwise_and(cond12,cond3)].reshape(160,-1):
    plt.plot(np.linspace(0,1,5),iband,c='blue')
138/31:
for iband in pred[1][[0,1,2,3,4]].reshape(160,-1)[20:40]:

    plt.scatter(np.linspace(0,1,5),iband,c='red')
138/32:
for iband in test_data_procar[1][[0,1,2,3,4]].reshape(160,-1)[20:40]:
    plt.scatter(np.linspace(0,1,5),iband,c='blue')
138/33: plt.
138/34:
for iband in test_data_procar[1][[0,1,2,3,4]].reshape(160,-1)[20:40]:
    plt.scatter(np.linspace(0,1,5),iband,c='blue','DFT')
138/35:
for iband in test_data_procar[1][[0,1,2,3,4]].reshape(160,-1)[20:40]:
    plt.scatter(np.linspace(0,1,5),iband,c='blue',label='DFT')
138/36:
for iband in pred[1][[0,1,2,3,4]].reshape(160,-1)[20:40]:

    plt.scatter(np.linspace(0,1,5),iband,c='red',label='Predicted')
138/37:
for iband in test_data_procar[1][[0,1,2,3,4]].reshape(160,-1)[20:40]:
    plt.scatter(np.linspace(0,1,5),iband,c='blue',label='DFT')
138/38:
for iband in pred[1][[0,1,2,3,4]].reshape(160,-1)[20:40]:

    plt.scatter(np.linspace(0,1,5),iband,c='red',label='Predicted',marker='x')
138/39: plt.legend()
138/40:
for iband in test_data_procar[1][[0,1,2,3,4]].reshape(160,-1)[20:40]:
    plt.scatter(np.linspace(0,1,5),iband,c='blue',label='DFT')
138/41:
for iband in test_data_procar[1][[0,1,2,3,4]].reshape(160,-1)[20:40]:
    plt.scatter(np.linspace(0,1,5),iband,c='blue')
138/42:
for iband in pred[1][[0,1,2,3,4]].reshape(160,-1)[20:40]:

    plt.scatter(np.linspace(0,1,5),iband,c='red',marker='x')
138/43: plt.ylim(-40,30)
138/44: plt.scatter(-100,100,c='red',marker='x',label='ML-predicted')
138/45: plt.scatter(-100,100,c='blue',label='DFT')
138/46: plt.ylim(-40,30)
138/47: plt.xlim(0,1)
138/48: plt.xlim(-0.5,1.5)
138/49: plt.xlim(-0.25,1.25)
138/50: plt.legend()
138/51: plt.xlabel('E-E$_F$(eV)')
138/52: plt.ylabel('E-E$_F$(eV)')
138/53: plt.ylabel('k$_x$')
138/54: plt.ylabel('E-E$_F$(eV)')
138/55: plt.xlabel('k$_x$')
138/56: plt.xlabel('k$_x$',fontsize=24)
138/57: plt.xlabel('k$_x$',fontsize=18)
138/58: plt.ylabel('E-E$_F$(eV)',fontsize=18)
139/1:
import h5py
rf = h5py.File('data_elfs_kpath_444_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_kpath_444_20_80.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,20,160,1)
test_data_procar  = test_data_procar.reshape(-1,20,160,1)
139/2:
def autoencoder(input_img): # 1ndTry                                                                                                                                                                        
    #encoder                                                                                                                                                                                                
    #input = 81 x 81 x 81 1 (wide and thin)                                                                                                                                                                 
    conv1 = Conv3D(25, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 20                                                                                                               
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 20                                                                                                                                          
    conv2 = Conv3D(50, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 40                                                                                                                   
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 40                                                                                                                                              
    conv3 = Conv3D(100, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 100 (small and thick)                                                                                                  

    #decoder                                                                                                                                                                                                
    flat = Flatten()(conv3) # 72900 x 1                                                                                                                                                                     
    reshape = Reshape((5,5,2916))(flat) # 9x5x1944                                                                                                                                                          
    conv5 = Conv2D(729, (3,3), activation='relu', padding='same')(reshape) # 9x5x729 (small and thick)                                                                                                      
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729                                                                                                                                                          
    conv6 = Conv2D(243, (3, 3), activation='linear', padding='same')(up1) # 27x10x243                                                                                                                       
    up2 = UpSampling2D((2,4))(conv6) # 20x40x486                                                                                                                                                            
    conv7 = Conv2D(128, (3, 3), activation='linear', padding='same')(up2) # 81x40x128                                                                                                                       
    up4 = UpSampling2D((1,2))(conv7) # 20x80x128                                                                                                                                                            

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1                                                                                                                         
    return decoded
139/3:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
139/4: train_data_elf.shape
139/5: train_data_procar
139/6: train_data_procar.shape
139/7:
rf = h5py.File('data_procars_efermi_kpath_444_20_80.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
139/8: data_procar.shape
139/9:
train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)
139/10:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
140/1:

import h5py
rf = h5py.File('data_elfs_kpath_444_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_kpath_444_20_80.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)
140/2:
def autoencoder(input_img): # 1ndTry                                                                                                                                                                        
    #encoder                                                                                                                                                                                                
    #input = 81 x 81 x 81 1 (wide and thin)                                                                                                                                                                 
    conv1 = Conv3D(25, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 20                                                                                                               
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 20                                                                                                                                          
    conv2 = Conv3D(50, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 40                                                                                                                   
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 40                                                                                                                                              
    conv3 = Conv3D(100, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 100 (small and thick)                                                                                                  

    #decoder                                                                                                                                                                                                
    flat = Flatten()(conv3) # 72900 x 1                                                                                                                                                                     
    reshape = Reshape((5,5,2916))(flat) # 9x5x1944                                                                                                                                                          
    conv5 = Conv2D(729, (3,3), activation='relu', padding='same')(reshape) # 9x5x729 (small and thick)                                                                                                      
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729                                                                                                                                                          
    conv6 = Conv2D(243, (3, 3), activation='linear', padding='same')(up1) # 27x10x243                                                                                                                       
    up2 = UpSampling2D((2,4))(conv6) # 20x40x486                                                                                                                                                            
    conv7 = Conv2D(128, (3, 3), activation='linear', padding='same')(up2) # 81x40x128                                                                                                                       
    up4 = UpSampling2D((1,2))(conv7) # 20x80x128                                                                                                                                                            

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1                                                                                                                         
    return decoded
140/3:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
140/4: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
141/1:
import h5py
rf = h5py.File('data_elfs_kpath_444_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_kpath_444_20_80.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)
141/2:
def autoencoder(input_img): # 1ndTry                                                                                                                                                                        
    #encoder                                                                                                                                                                                                
    #input = 81 x 81 x 81 1 (wide and thin)                                                                                                                                                                 
    conv1 = Conv3D(25, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 20                                                                                                               
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 20                                                                                                                                          
    conv2 = Conv3D(50, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 40                                                                                                                   
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 40                                                                                                                                              
    conv3 = Conv3D(100, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 100 (small and thick)                                                                                                  

    #decoder                                                                                                                                                                                                
    flat = Flatten()(conv3) # 72900 x 1                                                                                                                                                                     
    reshape = Reshape((5,5,2916))(flat) # 9x5x1944                                                                                                                                                          
    conv5 = Conv2D(729, (3,3), activation='relu', padding='same')(reshape) # 9x5x729 (small and thick)                                                                                                      
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729                                                                                                                                                          
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='same')(up1) # 27x10x243                                                                                                                          
    up2 = UpSampling2D((2,4))(conv6) # 20x40x486                                                                                                                                                            
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x128                                                                                                                      
    up4 = UpSampling2D((1,2))(conv7) # 20x80x128                                                                                                                                                            

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1                                                                                                                         
    return decoded
141/3:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
141/4: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
142/1:
import h5py
rf = h5py.File('data_elfs_kpath_444_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_kpath_444_20_80.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop



train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)


def autoencoder(input_img): # 1ndTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(25, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 20
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 20
    conv2 = Conv3D(50, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 40
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 40
    conv3 = Conv3D(100, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 100 (small and thick)

    #decoder
    flat = Flatten()(conv3) # 72900 x 1
    reshape = Reshape((5,5,2916))(flat) # 9x5x1944
    conv5 = Conv2D(729, (3,3), activation='relu', padding='same')(reshape) # 9x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='same')(up1) # 27x10x243
    up2 = UpSampling2D((2,4))(conv6) # 20x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x128
    up4 = UpSampling2D((1,2))(conv7) # 20x80x128

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
142/2:

batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
142/3: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
142/4: loss = autoencoder_train.history['loss']
142/5: val_loss = autoencoder_train.history['val_loss']
142/6: a = np.zeros((50,2))
142/7: np.savetxt('loss1thTry.txt',a,fmt='%4.5f',header = 'loss,val_loss')
142/8: pred = autoencoder.predict(test_data_elf)
142/9: import matplotlib.pylab as plt
142/10: pred[0]
142/11: pred[0].shape
142/12: pred[0].reshape(80,20)
142/13:
for iband in pred[0].reshape(80,20):
    plt.plot(np.linspace(0,1,20),iband)
142/14:
for iband in test_data_elf[0].reshape(80,20):
    plt.plot(np.linspace(0,1,20),iband)
142/15:
for iband in test_data_procar[0].reshape(80,20):
    plt.plot(np.linspace(0,1,20),iband)
142/16:
for iband in pred[0].reshape(80,20):
    plt.plot(np.linspace(0,1,20),iband,c='b')
142/17:
for iband in test_data_procar[0].reshape(80,20):
    plt.plot(np.linspace(0,1,20),iband,c='r')
142/18:
for iband in pred[0].reshape(80,20):
    plt.scatter(np.linspace(0,1,20),iband,c='b')
142/19:
for iband in test_data_procar[0].reshape(80,20):
    plt.scatter(np.linspace(0,1,20),iband,c='r')
142/20: plt.ylim(-10,10)
142/21: test_data_procar[0]
142/22: test_data_procar[0].shape
142/23: test_data_procar[0][0]
142/24: test_data_procar[0].reshape(80,20)
142/25: test_data_procar[0].reshape(80,20)[0]
142/26: test_data_procar[0].reshape(80,20)[1]
142/27: test_data_procar[0].reshape(80,20)[2]
142/28: test_data_procar[0].reshape(80,20)[3]
142/29: test_data_procar[0].reshape(80,20)[4]
142/30: test_data_procar[0].reshape(80,20)[5]
142/31: test_data_procar[0].reshape(80,20)[10]
142/32: test_data_procar[0]
142/33: test_data_procar[0].shape
142/34:
for iband in test_data_procar[1].reshape(80,20):
    plt.scatter(np.linspace(0,1,20),iband,c='r')
142/35:
for iband in test_data_procar[1].reshape(80,20):
    plt.plot(np.linspace(0,1,20),iband,c='r')
142/36:
for iband in test_data_procar[2].reshape(80,20):
    plt.plot(np.linspace(0,1,20),iband,c='r')
142/37:
for iband in data_procar[2].reshape(80,20):
    plt.plot(np.linspace(0,1,20),iband,c='r')
142/38: data_procar[0]
142/39: data_procar[0].shape
142/40:
for iband in data_procar[5].reshape(80,20):
    plt.plot(np.linspace(0,1,20),iband,c='r')
142/41:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),data_procar[0][:,iband],c='r')
142/42:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),test_data_procar[0][:,iband],iband,c='r')
142/43:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),pred[0][:,iband],iband,c='b')
142/44: plt.ylim(-2,2)
142/45: plt.ylim(-20,20)
142/46: plt.ylim(-25,25)
142/47: plt.ylim(-27,27)
142/48: plt.ylim(-30,30)
142/49:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),test_data_procar[1][:,iband],iband,c='r')
142/50:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),pred[1][:,iband],iband,c='r')
142/51:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),test_data_procar[1][:,iband],iband,c='r')
142/52:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),pred[1][:,iband],iband,c='b')
142/53:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),pred[2][:,iband],iband,c='b')
142/54:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),test_data_procar[2][:,iband],iband,c='r')
142/55:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),test_data_procar[40][:,iband],iband,c='r')
142/56:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),pred[40][:,iband],iband,c='b')
142/57:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),pred[45][:,iband],iband,c='b')
142/58:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),pred[43][:,iband],iband,c='b')
142/59:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),test_data_procar[43][:,iband],iband,c='r')
142/60: autoencoder.save('ELF2PROCAR-kpath_1stTry.hdf5')
143/1:
import h5py
rf = h5py.File('data_elfs_kpath_444_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_kpath_444_20_80.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
143/2:
train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
143/3:
def autoencoder(input_img): # 1ndTry                                                                                                                                                                        
    #encoder                                                                                                                                                                                                
    #input = 81 x 81 x 81 1 (wide and thin)                                                                                                                                                                 
    flat    = Flatten()(input_img) # 531441                                                                                                                                                                 
    enc1    = Dense(59049,activation='relu')(flat)
    enc2    = Dense(6561,activation='relu')(enc1)
    enc3    = Dense(729,activation='sigmoid')(enc2)
    decoded = Dense(1600,activation='linear')(enc3)
    reshape = Reshape((20,80))
    return decoded
143/4:

batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
143/5: from keras.layers import Dense
143/6:

batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
144/1:
import h5py
rf = h5py.File('data_elfs_kpath_444_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_kpath_444_20_80.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
144/2: from keras.layers import Dense
144/3:

train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)
144/4:
def autoencoder(input_img): # 2ndTry                                                                                                                                                                        
    #encoder                                                                                                                                                                                                
    #input = 81 x 81 x 81 1 (wide and thin)                                                                                                                                                                 
    conv1 = Conv3D(10, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 20                                                                                                               
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 20                                                                                                                                          
    conv2 = Conv3D(20, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 40                                                                                                                   
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 40                                                                                                                                              
    conv3 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 30 (small and thick)                                                                                                    
    pool3 = MaxPooling3D(pool_size=(3,3,3),padding='same')(conv3) #3x3x3 x 30                                                                                                                               
    #decoder                                                                                                                                                                                                
    flat = Flatten()(conv3) # 810 x 1                                                                                                                                                                       
    enc =  Dense(400,activation='relu')(flat)
    dec =  Dense(800,activation='sigmoid')(enc)
    reshape = Reshape((5,5,32))(flat) # 5x5x32                                                                                                                                                              
    conv5 = Conv2D(20, (3,3), activation='relu', padding='same')(reshape) # 5x5x 16 (small and thick)                                                                                                       
    up1   = UpSampling2D((2,2))(conv5) # 10x10x16                                                                                                                                                           
    conv6 = Conv2D(10, (3, 3), activation='elu', padding='same')(up1) # 20x40x10                                                                                                                            
    up2 = UpSampling2D((2,4))(conv6) # 20x40x10                                                                                                                                                             
    conv7 = Conv2D(5, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x5                                                                                                                          
    up4 = UpSampling2D((1,2))(conv7) # 20x80x5                                                                                                                                                              

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1                                                                                                                         
    return decoded
144/5:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
144/6:
def autoencoder(input_img): # 2ndTry                                                                                                                                                                        
    #encoder                                                                                                                                                                                                
    #input = 81 x 81 x 81 1 (wide and thin)                                                                                                                                                                 
    conv1 = Conv3D(10, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 20                                                                                                               
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 20                                                                                                                                          
    conv2 = Conv3D(20, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 40                                                                                                                   
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 40                                                                                                                                              
    conv3 = Conv3D(30, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 30 (small and thick)                                                                                                    
    pool3 = MaxPooling3D(pool_size=(3,3,3),padding='same')(conv3) #3x3x3 x 30                                                                                                                               
    #decoder                                                                                                                                                                                                
    flat = Flatten()(conv3) # 810 x 1                                                                                                                                                                       
    enc =  Dense(400,activation='relu')(flat)
    dec =  Dense(800,activation='sigmoid')(enc)
    reshape = Reshape((5,5,32))(dec) # 5x5x32                                                                                                                                                               
    conv5 = Conv2D(20, (3,3), activation='relu', padding='same')(reshape) # 5x5x 16 (small and thick)                                                                                                       
    up1   = UpSampling2D((2,2))(conv5) # 10x10x16                                                                                                                                                           
    conv6 = Conv2D(10, (3, 3), activation='elu', padding='same')(up1) # 20x40x10                                                                                                                            
    up2 = UpSampling2D((2,4))(conv6) # 20x40x10                                                                                                                                                             
    conv7 = Conv2D(5, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x5                                                                                                                          
    up4 = UpSampling2D((1,2))(conv7) # 20x80x5                                                                                                                                                              

    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1                                                                                                                         
    return decoded
144/7:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
144/8: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
145/1:
import h5py
rf = h5py.File('data_elfs_kpath_444_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_kpath_444_20_80.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
145/2:
def autoencoder(input_img): # 2ndTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(25, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 20
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 20
    conv2 = Conv3D(50, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 40
#    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 40
#    conv3 = Conv3D(100, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 100 (small and thick)

    #decoder
    flat = Flatten()(conv2) # 72900 x 1
    reshape = Reshape((5,5,39366))(flat) # 9x5x1944
    conv5 = Conv2D(6561, (3,3), activation='relu', padding='same')(reshape) # 9x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(1000, (3, 3), activation='elu', padding='same')(up1) # 27x10x243
    up2 = UpSampling2D((2,4))(conv6) # 20x40x486
    conv7 = Conv2D(500, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x128
    up4 = UpSampling2D((1,2))(conv7) # 20x80x128
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
145/3:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
145/4:

train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)
145/5:
def autoencoder(input_img): # 2ndTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(25, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 20
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 20
    conv2 = Conv3D(50, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 40
#    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 40
#    conv3 = Conv3D(100, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 100 (small and thick)

    #decoder
    flat = Flatten()(conv2) # 72900 x 1
    reshape = Reshape((5,5,39366))(flat) # 9x5x1944
    conv5 = Conv2D(1000, (3,3), activation='relu', padding='same')(reshape) # 9x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(500, (3, 3), activation='elu', padding='same')(up1) # 27x10x243
    up2 = UpSampling2D((2,4))(conv6) # 20x40x486
    conv7 = Conv2D(200, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x128
    up4 = UpSampling2D((1,2))(conv7) # 20x80x128
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
145/6:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
145/7:

def autoencoder(input_img): # 2ndTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(25, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 20
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 20
    conv2 = Conv3D(50, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 40
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 40
    conv3 = Conv3D(150, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 100 (small and thick)

    #decoder
    flat = Flatten()(conv2) # 72900 x 1
    reshape = Reshape((5,5,4374))(flat) # 9x5x1944
    conv5 = Conv2D(1000, (3,3), activation='relu', padding='same')(reshape) # 9x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(500, (3, 3), activation='elu', padding='same')(up1) # 27x10x243
    up2 = UpSampling2D((2,4))(conv6) # 20x40x486
    conv7 = Conv2D(200, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x128
    up4 = UpSampling2D((1,2))(conv7) # 20x80x128
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
145/8:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
145/9:
def autoencoder(input_img): # 2ndTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(25, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 20
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 20
    conv2 = Conv3D(50, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 40
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 40
    conv3 = Conv3D(150, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 100 (small and thick)

    #decoder
    flat = Flatten()(conv3) # 72900 x 1
    reshape = Reshape((5,5,4374))(flat) # 9x5x1944
    conv5 = Conv2D(1000, (3,3), activation='relu', padding='same')(reshape) # 9x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(500, (3, 3), activation='elu', padding='same')(up1) # 27x10x243
    up2 = UpSampling2D((2,4))(conv6) # 20x40x486
    conv7 = Conv2D(200, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x128
    up4 = UpSampling2D((1,2))(conv7) # 20x80x128
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
145/10:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))

autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
145/11: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
145/12: loss = autoencoder_train.history['loss']
145/13: val_loss = autoencoder_train.history['val_loss']
145/14: a = np.zeros((50,2))
145/15: a[:,1] = val_loss
145/16: a[:,0]=loss
145/17: np.savetxt('loss2ndTry.txt',a,fmt='%4.5f',header = 'loss,val_loss')
145/18: pred = autoencoder.predict(test_data_elf)
145/19:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),test_data_procar[43][:,iband],iband,c='r')
145/20: import matplotlib.pylab is plt
145/21: import matplotlib.pylab as plt
145/22:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),test_data_procar[43][:,iband],iband,c='r')
145/23:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),pred[43][:,iband],iband,c='b')
145/24:
for iband in range(80):
    plt.scatter(np.linspace(0,1,20),pred[43][:,iband],iband,c='b')
145/25:
for iband in range(80):
    plt.scatter(np.linspace(0,1,20),pred[43][:,iband],iband,c='b',s=1)
145/26:
for iband in range(80):
    plt.scatter(np.linspace(0,1,20),pred[43][:,iband],iband,c='b',size=1)
145/27:
for iband in range(80):
    plt.scatter(np.linspace(0,1,20),pred[43][:,iband],iband,c='b',marker_size=1)
145/28:
for iband in range(80):
    plt.scatter(np.linspace(0,1,20),pred[43][:,iband],iband,c='b',markersize=1)
145/29:
for iband in range(80):
    plt.scatter(np.linspace(0,1,20),pred[43][:,iband],iband,c='b',s=np.ones(20,))
145/30:
for iband in range(80):
    plt.scatter(np.linspace(0,1,20),pred[43][:,iband],s=1,c='b')
145/31:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),test_data_procar[43][:,iband],s=1,c='r')
145/32:
for iband in range(80):
    plt.scatter(np.linspace(0,1,20),test_data_procar[43][:,iband],s=1,c='r')
145/33:
for iband in range(80):
    plt.plot(np.linspace(0,1,20),test_data_procar[20][20:40,iband],s=1,c='r')
145/34:
for iband in range(20,40):
    plt.plot(np.linspace(0,1,20),test_data_procar[20][:,iband],s=1,c='r')
145/35:
for iband in range(20,40):
    plt.scatter(np.linspace(0,1,20),test_data_procar[20][:,iband],s=1,c='r')
145/36:
for iband in range(20,40):
    plt.scatter(np.linspace(0,1,20),pred[20][:,iband],s=1,c='b')
145/37:
for iband in range(20,40):
    plt.scatter(np.linspace(0,1,20),pred[20][:,iband],s=2,c='b')
    plt.plot(np.linspace(0,1,20),pred[20][:,iband],c='b')
145/38:
for iband in range(20,40):
    plt.scatter(np.linspace(0,1,20),test_data_procar[20][:,iband],s=2,c='r')
    plt.plot(np.linspace(0,1,20),test_data_procar[20][:,iband],c='r')
145/39:
for iband in range(25,25):
    plt.scatter(np.linspace(0,1,20),pred[20][:,iband],s=2,c='b')
    plt.plot(np.linspace(0,1,20),pred[20][:,iband],c='b')
145/40:
for iband in range(25,25):
    plt.scatter(np.linspace(0,1,20),test_data_procar[20][:,iband],s=2,c='r')
    plt.plot(np.linspace(0,1,20),test_data_procar[20][:,iband],c='r')
145/41:
for iband in range(25,35):
    plt.scatter(np.linspace(0,1,20),test_data_procar[20][:,iband],s=2,c='r')
    plt.plot(np.linspace(0,1,20),test_data_procar[20][:,iband],c='r')
145/42:
for iband in range(25,35):
    plt.scatter(np.linspace(0,1,20),pred[20][:,iband],s=2,c='b')
    plt.plot(np.linspace(0,1,20),pred[20][:,iband],c='b')
145/43: plt.xlim(0,1)
145/44:
for iband in range(20,35):
    plt.scatter(np.linspace(0,1,20),pred[20][:,iband],s=2,c='b')
    plt.plot(np.linspace(0,1,20),pred[20][:,iband],c='b')
145/45:
for iband in range(20,35):
    plt.scatter(np.linspace(0,1,20),pred[21][:,iband],s=2,c='b')
    plt.plot(np.linspace(0,1,20),pred[21][:,iband],c='b')
145/46:
for iband in range(20,35):
    plt.scatter(np.linspace(0,1,20),pred[21][:,iband],s=2,c='b')
    plt.plot(np.linspace(0,1,20),pred[21][:,iband],c='b')
145/47:
for iband in range(20,35):
    plt.scatter(np.linspace(0,1,20),pred[22][:,iband],s=2,c='g')
    plt.plot(np.linspace(0,1,20),pred[22][:,iband],c='g')
145/48:
for iband in range(25,35):
    plt.scatter(np.linspace(0,1,20),test_data_procar[22][:,iband],s=2,c='r')
    plt.plot(np.linspace(0,1,20),test_data_procar[22][:,iband],c='r')
145/49:
for j in range(len(pred)):
    plt.figure()
    plt.scatter(np.linspace(0,1,20),test_data_procar[j][:,iband],s=3,c='r')
    plt.plot(np.linspace(0,1,20),test_data_procar[j][:,iband],c='r')
    plt.scatter(np.linspace(0,1,20),pred[j][:,iband],s=3,c='b')
    plt.plot(np.linspace(0,1,20),pred[j][:,iband],c='b')
    plt.xlim(0,1)
    plt.xlabel("$\Gamma$>X",fontsize=18)
    plt.ylabel("E-E$_F$(eV)",fontsize=18)
    plt.clf()
145/50:
for j in range(len(pred)):
    plt.figure()
    plt.scatter(np.linspace(0,1,20),test_data_procar[j][:,iband],s=3,c='r')
    plt.plot(np.linspace(0,1,20),test_data_procar[j][:,iband],c='r')
    plt.scatter(np.linspace(0,1,20),pred[j][:,iband],s=3,c='b')
    plt.plot(np.linspace(0,1,20),pred[j][:,iband],c='b')
    plt.xlim(0,1)
    plt.xlabel("$\Gamma$>X",fontsize=18)
    plt.ylabel("E-E$_F$(eV)",fontsize=18)
    plt.savefig('bands_{}'.format(j))
    plt.clf()
145/51:
for j in range(len(pred)):
    for iband in range(25,35):
        plt.figure()
        plt.scatter(np.linspace(0,1,20),test_data_procar[j][:,iband],s=3,c='r')
        plt.plot(np.linspace(0,1,20),test_data_procar[j][:,iband],c='r')
        plt.scatter(np.linspace(0,1,20),pred[j][:,iband],s=3,c='b')
        plt.plot(np.linspace(0,1,20),pred[j][:,iband],c='b')
        plt.xlim(0,1)
        plt.xlabel("$\Gamma$>X",fontsize=18)
        plt.ylabel("E-E$_F$(eV)",fontsize=18)
        plt.savefig('bands_{}'.format(j))
        plt.clf()
145/52:
for j in range(len(pred)):
    plt.figure()
    for iband in range(25,35):
    
        plt.scatter(np.linspace(0,1,20),test_data_procar[j][:,iband],s=3,c='r')
        plt.plot(np.linspace(0,1,20),test_data_procar[j][:,iband],c='r')
        plt.scatter(np.linspace(0,1,20),pred[j][:,iband],s=3,c='b')
        plt.plot(np.linspace(0,1,20),pred[j][:,iband],c='b')
    plt.xlim(0,1)
    plt.xlabel("$\Gamma$>X",fontsize=18)
    plt.ylabel("E-E$_F$(eV)",fontsize=18)
    plt.savefig('bands_{}'.format(j))
    plt.clf()
145/53: autoencoder.save('ELF2PROCAR-kpath_2ndTry.hdf5')
146/1: import pychemia
146/2: pychemia.utils.mathematics.rotation_matrix_around_axis_angle([0,0,1],np.pi/2)
146/3: import numpy as np
146/4: pychemia.utils.mathematics.rotation_matrix_around_axis_angle([0,0,1],np.pi/2)
147/1:
import h5py
rf = h5py.File('data_elfs_kpath_444_81_81_81.hdf5','r')
data_elf = rf['data']
data_elf = data_elf[:,:,:]
rf.close()
rf = h5py.File('data_procars_efermi_kpath_444_20_80.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
147/2: from scipy.ndimage import affine_transform
147/3: affine_transform?
147/4: affine_transform?
147/5: affine_transform(data_elf[0],matrix=pychemia.utils.mathematics.rotation_matrix_around_axis_angle([0,0,1],np.pi/2),output_shape=(81,81,81),mode='wrap')
147/6: import pychemia
147/7: affine_transform(data_elf[0],matrix=pychemia.utils.mathematics.rotation_matrix_around_axis_angle([0,0,1],np.pi/2),output_shape=(81,81,81),mode='wrap')
147/8: affine_transform(data_elf,matrix=pychemia.utils.mathematics.rotation_matrix_around_axis_angle([0,0,1],np.pi/2),output_shape=(81,81,81),mode='wrap')
147/9:
data_elf2 = []
data_elf3 = []
data_procar2 = []
data_procar3 = []
147/10: from scipy.ndimage import affine_transform
147/11: np
147/12: np.random.rand()
147/13: np.random.rand()
147/14: np.random.rand()
147/15: np.random.rand()*np.pi
147/16: np.random.rand()*np.pi
147/17: np.random.rand()*np.pi
147/18: np.random.rand()*np.pi
147/19: np.random.rand()*np.pi
147/20: np.random.rand()*np.pi
147/21: np.random.rand()*np.pi
147/22: np.random.rand()*np.pi
147/23: np.random.rand()*np.pi
147/24:
for idata in range(len(data_elf)):
   i = np.random.rand()
   j = np.random.rand()
   k = np.random.rand()
   angle = np.random.rand()*np.pi
   data_elf_mod.append(data_elf[idata])
   data_procar_mod.append(data_procar[idata])
   data_elf_mod.append(afffine_transform(idata,matrix=rot([i,j,k],angle),
                       output_shape=(81,81,81),mode='wrap'))
   data_procar_mod.append(data_procar[idata])
   i = np.random.rand()
   j = np.random.rand()
   k = np.random.rand()
   angle = np.random.rand()*np.pi
   data_elf_mod.append(afffine_transform(idata,matrix=rot([i,j,k],angle),
                       output_shape=(81,81,81),mode='wrap'))
   data_procar_mod.append(data_procar[idata])
147/25:
data_elf_mod = []
data_procar_mod = []
147/26:
for idata in range(len(data_elf)):
   i = np.random.rand()
   j = np.random.rand()
   k = np.random.rand()
   angle = np.random.rand()*np.pi
   data_elf_mod.append(data_elf[idata])
   data_procar_mod.append(data_procar[idata])
   data_elf_mod.append(afffine_transform(idata,matrix=rot([i,j,k],angle),
                       output_shape=(81,81,81),mode='wrap'))
   data_procar_mod.append(data_procar[idata])
   i = np.random.rand()
   j = np.random.rand()
   k = np.random.rand()
   angle = np.random.rand()*np.pi
   data_elf_mod.append(afffine_transform(idata,matrix=rot([i,j,k],angle),
                       output_shape=(81,81,81),mode='wrap'))
   data_procar_mod.append(data_procar[idata])
147/27: from scipy.ndimage import affine_transform
147/28: from pycemia.utils.mathematics import rotation_matrix_around_axis_angle as rot
147/29: from pychemia.utils.mathematics import rotation_matrix_around_axis_angle as rot
147/30:
for idata in range(len(data_elf)):
   i = np.random.rand()
   j = np.random.rand()
   k = np.random.rand()
   angle = np.random.rand()*np.pi
   data_elf_mod.append(data_elf[idata])
   data_procar_mod.append(data_procar[idata])
   data_elf_mod.append(afffine_transform(idata,matrix=rot([i,j,k],angle),
                       output_shape=(81,81,81),mode='wrap'))
   data_procar_mod.append(data_procar[idata])
   i = np.random.rand()
   j = np.random.rand()
   k = np.random.rand()
   angle = np.random.rand()*np.pi
   data_elf_mod.append(afffine_transform(idata,matrix=rot([i,j,k],angle),
                       output_shape=(81,81,81),mode='wrap'))
   data_procar_mod.append(data_procar[idata])
147/31: from scipy.ndimage import affine_transform
147/32:
for idata in range(len(data_elf)):
   i = np.random.rand()
   j = np.random.rand()
   k = np.random.rand()
   angle = np.random.rand()*np.pi
   data_elf_mod.append(data_elf[idata])
   data_procar_mod.append(data_procar[idata])
   data_elf_mod.append(affine_transform(idata,matrix=rot([i,j,k],angle),
                       output_shape=(81,81,81),mode='wrap'))
   data_procar_mod.append(data_procar[idata])
   i = np.random.rand()
   j = np.random.rand()
   k = np.random.rand()
   angle = np.random.rand()*np.pi
   data_elf_mod.append(affine_transform(idata,matrix=rot([i,j,k],angle),
                       output_shape=(81,81,81),mode='wrap'))
   data_procar_mod.append(data_procar[idata])
147/33:
for idata in range(len(data_elf)):
   
   i = np.random.rand()
   j = np.random.rand()
   k = np.random.rand()
   angle = np.random.rand()*np.pi
   data_elf_mod.append(data_elf[idata])
   data_procar_mod.append(data_procar[idata])
   data_elf_mod.append(affine_transform(idata,matrix=rot([i,j,k],angle),
                       output_shape=(81,81,81),mode='wrap'))
   data_procar_mod.append(data_procar[idata])
   i = np.random.rand()
   j = np.random.rand()
   k = np.random.rand()
   angle = np.random.rand()*np.pi
   data_elf_mod.append(affine_transform(idata,matrix=rot([i,j,k],angle),
                       output_shape=(81,81,81),mode='wrap'))
   data_procar_mod.append(data_procar[idata])
147/34:
for idata in range(len(data_elf)):
   i = np.random.rand()
   j = np.random.rand()
   k = np.random.rand()
   angle = np.random.rand()*np.pi
   data_elf_mod.append(data_elf[idata])
   data_procar_mod.append(data_procar[idata])
   data_elf_mod.append(affine_transform(data_elf[idata],matrix=rot([i,j,k],angle),
                       output_shape=(81,81,81),mode='wrap'))
   data_procar_mod.append(data_procar[idata])
   i = np.random.rand()
   j = np.random.rand()
   k = np.random.rand()
   angle = np.random.rand()*np.pi
   data_elf_mod.append(affine_transform(data_elf[idata],matrix=rot([i,j,k],angle),
                       output_shape=(81,81,81),mode='wrap'))
   data_procar_mod.append(data_procar[idata])
147/35: np.array(data_elf_mod).shape
147/36: data_elf = np.array(data_elf_mod)
147/37: data_procar = np.array(data_procar_mod)
147/38: del data_elf_mod
147/39: del data_procar_mod
147/40:
train_data_elf = data_elf[:1000,:,:,:]
test_data_elf = data_elf[1000:,:,:,:]
train_data_procar = data_procar[:1000,:,:]
test_data_procar = data_procar[1000:,:,:]
train_data_elf = train_data_elf.reshape(-1, 81,81,81, 1)
test_data_elf  = test_data_elf.reshape(-1,81,81,81,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)
147/41:
def autoencoder(input_img): # 1ndTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(25, (3, 3,3), activation='relu', padding='same')(input_img) #81x81x81 x 20
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 27x27x27 x 20
    conv2 = Conv3D(50, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 40
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #9x9x9 x 40
    conv3 = Conv3D(100, (3, 3,3), activation='relu', padding='same')(pool2) #9x9x9 x 100 (small and thick)

    #decoder
    flat = Flatten()(conv3) # 72900 x 1
    reshape = Reshape((5,5,2916))(flat) # 9x5x1944
    conv5 = Conv2D(729, (3,3), activation='relu', padding='same')(reshape) # 9x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(243, (3, 3), activation='elu', padding='same')(up1) # 27x10x243
    up2 = UpSampling2D((2,4))(conv6) # 20x40x486
    conv7 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up2) # 81x40x128
    up4 = UpSampling2D((1,2))(conv7) # 20x80x128
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
147/42:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))
147/43:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
147/44: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
147/45: a = np.zeros((50,2))
147/46: loss = autoencoder_train.history['loss']
147/47: val_loss = autoencoder_train.history['val_loss']
147/48: a[:,0]=loss
147/49: a[:,1] = val_loss
147/50: np.savetxt('loss3rdTryDataX3.txt',a,fmt='%4.5f',header = 'loss,val_loss')
147/51: autoencoder.save('ELF2PROCAR-kpath_3rdTryDataX3.hdf5')
147/52: pred = autoencoder.predict(test_data_elf)
147/53:
for j in range(len(pred)):
    plt.figure()
    for iband in range(25,35):
    
        plt.scatter(np.linspace(0,1,20),test_data_procar[j][:,iband],s=3,c='r')
        plt.plot(np.linspace(0,1,20),test_data_procar[j][:,iband],c='r')
        plt.scatter(np.linspace(0,1,20),pred[j][:,iband],s=3,c='b')
        plt.plot(np.linspace(0,1,20),pred[j][:,iband],c='b')
    plt.xlim(0,1)
    plt.xlabel("$\Gamma$>X",fontsize=18)
    plt.ylabel("E-E$_F$(eV)",fontsize=18)
    plt.savefig('bands_{}_3rd'.format(j))
    plt.clf()
147/54: import matplotlib.pylab as plt
147/55:
for j in range(len(pred)):
    plt.figure()
    for iband in range(25,35):
    
        plt.scatter(np.linspace(0,1,20),test_data_procar[j][:,iband],s=3,c='r')
        plt.plot(np.linspace(0,1,20),test_data_procar[j][:,iband],c='r')
        plt.scatter(np.linspace(0,1,20),pred[j][:,iband],s=3,c='b')
        plt.plot(np.linspace(0,1,20),pred[j][:,iband],c='b')
    plt.xlim(0,1)
    plt.xlabel("$\Gamma$>X",fontsize=18)
    plt.ylabel("E-E$_F$(eV)",fontsize=18)
    plt.savefig('bands_{}_3rd'.format(j))
    plt.clf()
147/56: test_data_procar[0].shape
147/57: test_data_elf[-].shape
147/58: test_data_elf[0].shape
147/59: test_data_elf[0].reshape(81,81,81)
147/60: test_data_elf[0].reshape(81,81,81).shape
147/61: plt.imshow(test_data_elf[0].reshape(81,81,81)[0,:,:])
147/62: plt.imshow(test_data_elf[1].reshape(81,81,81)[0,:,:])
147/63: plt.imshow(test_data_elf[2].reshape(81,81,81)[0,:,:])
147/64: plt.imshow(test_data_elf[2].reshape(81,81,81)[20,:,:])
147/65: plt.imshow(test_data_elf[2].reshape(81,81,81)[21,:,:])
147/66: plt.imshow(test_data_elf[2].reshape(81,81,81)[0,:,:])
147/67: plt.imshow(test_data_elf[10].reshape(81,81,81)[0,:,:])
147/68: plt.imshow(test_data_elf[11].reshape(81,81,81)[0,:,:])
147/69: plt.imshow(test_data_elf[21].reshape(81,81,81)[0,:,:])
147/70: plt.imshow(test_data_elf[22].reshape(81,81,81)[0,:,:])
147/71: plt.imshow(test_data_elf[22].reshape(81,81,81)[0,:,:])
147/72: plt.imshow(train_data_elf[0].reshape(81,81,81)[0,:,:])
147/73: plt.imshow(train_data_elf[1].reshape(81,81,81)[0,:,:])
147/74: plt.imshow(train_data_elf[2].reshape(81,81,81)[0,:,:])
147/75: plt.imshow(train_data_elf[20].reshape(81,81,81)[0,:,:])
147/76: plt.imshow(train_data_elf[20].reshape(81,81,81)[:,:,20])
147/77: plt.imshow(train_data_elf[20].reshape(81,81,81)[:,:,0])
147/78: plt.imshow(train_data_elf[0].reshape(81,81,81)[0,:,:])
148/1:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 1
data_before = data[j]
148/2:
import os
import pymatgen.io.vasp as vasp
import keras
from matplotlib import pyplot as plt
import numpy as np
import gzip
%matplotlib inline
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.models import Model
from keras.optimizers import RMSprop
148/3:
import scipy.ndimage as ndimage
#import pychemia
148/4:
def get_data(path):
    data = []
    ls = os.listdir(path)
    
    for idir in ls :
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            elfcar = vasp.Elfcar.from_file(path + os.sep + idir+os.sep+'ELFCAR')
            data.append(elfcar.data['total'])
    return data
148/5: data = get_data('isym-1_nbands80/')
148/6:
def get_label(path):
    label = []
    ls = os.listdir(path)
    
    for idir in ls :
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            label.append(idir)
    return label
148/7:
def get_label(path):
    label = []
    ls = os.listdir(path)
    
    for idir in ls :
        if 'mp-' in idir and os.path.exists(path + os.sep + idir+os.sep+'ELFCAR'):
            label.append(idir)
    return label
148/8: labels = get_label('isym-1_nbands80/')
148/9: labels
148/10:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 1
data_before = data[j]
148/11:
for idata in data:
    print(idata.shape)
148/12: data[j].shape
148/13: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
148/14: a = st.lattice.reciprocal_lattice
148/15:
lattice = st.lattice.matrix
lattice
148/16: data_before.shape
148/17: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
148/18:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/19:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 2
data_before = data[j]
148/20:
for idata in data:
    print(idata.shape)
148/21: data[j].shape
148/22:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 3
data_before = data[j]
148/23:
for idata in data:
    print(idata.shape)
148/24: data[j].shape
148/25:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 4
data_before = data[j]
148/26:
for idata in data:
    print(idata.shape)
148/27: data[j].shape
148/28:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 5
data_before = data[j]
148/29:
for idata in data:
    print(idata.shape)
148/30: data[j].shape
148/31:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 6
data_before = data[j]
148/32:
for idata in data:
    print(idata.shape)
148/33: data[j].shape
148/34:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 7
data_before = data[j]
148/35:
for idata in data:
    print(idata.shape)
148/36: data[j].shape
148/37:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 8
data_before = data[j]
148/38:
for idata in data:
    print(idata.shape)
148/39: data[j].shape
148/40:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 9
data_before = data[j]
148/41:
for idata in data:
    print(idata.shape)
148/42: data[j].shape
148/43:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 10
data_before = data[j]
148/44:
for idata in data:
    print(idata.shape)
148/45: data[j].shape
148/46:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 11
data_before = data[j]
148/47:
for idata in data:
    print(idata.shape)
148/48: data[j].shape
148/49:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 12
data_before = data[j]
148/50:
for idata in data:
    print(idata.shape)
148/51: data[j].shape
148/52:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 13
data_before = data[j]
148/53:
for idata in data:
    print(idata.shape)
148/54: data[j].shape
148/55:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 14
data_before = data[j]
148/56:
for idata in data:
    print(idata.shape)
148/57: data[j].shape
148/58:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 15
data_before = data[j]
148/59:
for idata in data:
    print(idata.shape)
148/60: data[j].shape
148/61:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 16
data_before = data[j]
148/62:
for idata in data:
    print(idata.shape)
148/63: data[j].shape
148/64:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 17
data_before = data[j]
148/65:
for idata in data:
    print(idata.shape)
148/66: data[j].shape
148/67: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
148/68: a = st.lattice.reciprocal_lattice
148/69:
lattice = st.lattice.matrix
lattice
148/70: data_before.shape
148/71: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
148/72:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/73:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 18
data_before = data[j]
148/74:
for idata in data:
    print(idata.shape)
148/75: data[j].shape
148/76: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
148/77: a = st.lattice.reciprocal_lattice
148/78:
lattice = st.lattice.matrix
lattice
148/79: data_before.shape
148/80: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
148/81:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/82:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 19
data_before = data[j]
148/83:
for idata in data:
    print(idata.shape)
148/84: data[j].shape
148/85: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
148/86: a = st.lattice.reciprocal_lattice
148/87:
lattice = st.lattice.matrix
lattice
148/88: data_before.shape
148/89: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
148/90:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/91:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 20
data_before = data[j]
148/92:
for idata in data:
    print(idata.shape)
148/93: data[j].shape
148/94: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
148/95: a = st.lattice.reciprocal_lattice
148/96:
lattice = st.lattice.matrix
lattice
148/97: data_before.shape
148/98: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
148/99:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/100:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 21
data_before = data[j]
148/101:
for idata in data:
    print(idata.shape)
148/102: data[j].shape
148/103: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
148/104: a = st.lattice.reciprocal_lattice
148/105:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 22
data_before = data[j]
148/106:
for idata in data:
    print(idata.shape)
148/107: data[j].shape
148/108:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 23
data_before = data[j]
148/109:
for idata in data:
    print(idata.shape)
148/110: data[j].shape
148/111:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 24
data_before = data[j]
148/112:
for idata in data:
    print(idata.shape)
148/113: data[j].shape
148/114: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
148/115: a = st.lattice.reciprocal_lattice
148/116:
lattice = st.lattice.matrix
lattice
148/117: data_before.shape
148/118: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
148/119:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/120:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 25
data_before = data[j]
148/121:
for idata in data:
    print(idata.shape)
148/122: data[j].shape
148/123: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
148/124: a = st.lattice.reciprocal_lattice
148/125:
lattice = st.lattice.matrix
lattice
148/126: data_before.shape
148/127: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
148/128:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/129:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 26
data_before = data[j]
148/130:
for idata in data:
    print(idata.shape)
148/131: data[j].shape
148/132: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
148/133: a = st.lattice.reciprocal_lattice
148/134:
lattice = st.lattice.matrix
lattice
148/135: data_before.shape
148/136: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
148/137:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/138:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 27
data_before = data[j]
148/139:
for idata in data:
    print(idata.shape)
148/140: data[j].shape
148/141: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
148/142: a = st.lattice.reciprocal_lattice
148/143:
lattice = st.lattice.matrix
lattice
148/144: data_before.shape
148/145: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
148/146:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/147:
#data_before = np.pad(data[j],(128,128),'wrap')
j= 28
data_before = data[j]
148/148:
for idata in data:
    print(idata.shape)
148/149: data[j].shape
148/150: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
148/151: a = st.lattice.reciprocal_lattice
148/152:
lattice = st.lattice.matrix
lattice
148/153: data_before.shape
148/154: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(70,70,70),mode='wrap')
148/155:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/156: labels[j]
148/157: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(81,81,81),mode='wrap')
148/158:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/159: 128/2/2/2/2/2
148/160: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(120,120,120),mode='wrap')
148/161:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/162: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(140,140,140),mode='wrap')
148/163:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/164: 128/2/2/2/2/2
148/165:
j= 28
data_before = np.pad(data[j],(140,140,140),'wrap')

#data_before = data[j]
148/166:
for idata in data:
    print(idata.shape)
148/167: data[j].shape
148/168: labels[j]
148/169: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
148/170: a = st.lattice.reciprocal_lattice
148/171:
lattice = st.lattice.matrix
lattice
148/172: data_before.shape
148/173: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(140,140,140),mode='wrap')
148/174:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/175:
j= 28
#data_before = np.pad(data[j],(140,140,140),'wrap')

data_before = data[j]
148/176:
for idata in data:
    print(idata.shape)
148/177: data[j].shape
148/178: labels[j]
148/179: st = vasp.Poscar.from_file('isym-1_nbands80/'+labels[j]+'/POSCAR').structure
148/180: a = st.lattice.reciprocal_lattice
148/181:
lattice = st.lattice.matrix
lattice
148/182: data_before.shape
148/183: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(140,140,140),mode='wrap')
148/184:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/185:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[20,:,:]

plt.imshow(curr_img, cmap='jet')
148/186:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,20,:]

plt.imshow(curr_img, cmap='jet')
148/187:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,20]

plt.imshow(curr_img, cmap='jet')
148/188:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/189: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(60,60,54),mode='wrap')
148/190:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/191: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(60,60,54),mode='constant')
148/192:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/193: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(60,60,54),mode='wrap')
148/194:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
148/195: data_after = ndimage.affine_transform(data_before,matrix=a.matrix,output_shape=(81,81,81),mode='wrap')
148/196:
plt.figure(figsize=[15,15])

# Display the first image in training data
plt.subplot(121)
curr_img = data_before[:,:,0]

plt.imshow(curr_img, cmap='jet')

# Display the first image in testing data
plt.subplot(122)
curr_img = data_after[:,:,0]

plt.imshow(curr_img, cmap='jet')
147/79: plt.imshow(train_data_elf[1].reshape(81,81,81)[0,:,:])
147/80: plt.imshow(train_data_elf[2].reshape(81,81,81)[0,:,:])
147/81: plt.imshow(test_data_elf[2].reshape(81,81,81)[0,:,:])
147/82: plt.imshow(test_data_elf[2].reshape(81,81,81)[20,:,:])
147/83: %history
149/1: import h5py
149/2: import matplotlib.pylab as plt
149/3:
rf = h5py.File('data_elfs_kpath_test_interpolate.hdf5')
data_procar = rf['data']
data_procar = data_procar[:,:,:]
rf.close()
149/4: del data_procar
149/5:
rf = h5py.File('data_elfs_kpath_test_interpolate.hdf5')
data_elfs = rf['data']
data_elfs = data_elfs[:,:,:,:]
rf.close()
149/6: data_elfs.shape
149/7: plt.imshow(data_elfs[0][:,:,0])
149/8: plt.imshow(data_elfs[1][:,:,0])
149/9: plt.imshow(data_elfs[1][:,:,20])
149/10: plt.imshow(data_elfs[1][:,:,30])
149/11: plt.imshow(data_elfs[2][:,:,0])
149/12: plt.imshow(data_elfs[2][:,:,20])
149/13: plt.imshow(data_elfs[2][0,:,:])
149/14: plt.imshow(data_elfs[2][0,:,:])
149/15: from scipy.ndimage import affine_transform
149/16: plt.imshow(affine_transform(data_elfs[2][0,:,:],matrix=[[],[],[]]))
149/17: import pychemia
149/18: pychemia.utils.mathematics.rotation_matrix_around_axis_angle
149/19: import numpy as np
149/20: i = np.random()
149/21: i = np.random.rand()
149/22: i
149/23: j = np.random.rand()
149/24: k = np.random.rand()
149/25: angle = np.random.rand()*np.pi
149/26: pychemia.utils.mathematics.rotation_matrix_around_axis_angle?
149/27: m = pychemia.utils.mathematics.rotation_matrix_around_axis_angle([i,j,k],theta=angle)
149/28: m
149/29: plt.imshow(affine_transform(data_elfs[2][0,:,:],matrix=m))
149/30: plt.imshow(affine_transform(data_elfs[2],matrix=m)[0,:,:])
149/31: plt.imshow(affine_transform(data_elfs[2],matrix=m)[0,:,:],mode='wrap')
149/32: plt.imshow(affine_transform(data_elfs[2],matrix=m,mode='wrap')[0,:,:])
149/33: plt.imshow(affine_transform(data_elfs[2],matrix=m)[0,:,:])
149/34: plt.imshow(affine_transform(np.pad(data_elfs[2],(200,200),mode='wrap'),matrix=m)[0,:,:])
149/35: plt.imshow(data_elfs[2][0,:,:])
149/36:
rf = h5py.File('data_elfs_kpath_test_interpolate.hdf5')
data_elfs = rf['data']
data_elfs = data_elfs[:,:,:,:]
rf.close()
149/37: plt.imshow(data_elfs[2][0,:,:])
149/38: plt.imshow(data_elfs[2][20,:,:])
149/39: plt.imshow(data_elfs[2][:,:,20])
149/40: plt.imshow(data_elfs[2][:,:,50])
149/41: plt.imshow(data_elfs[2][:,:,90])
149/42: plt.imshow(data_elfs[2][:,:,80])
149/43: plt.imshow(data_elfs[2][:,:,0])
149/44: plt.imshow(data_elfs[2][:,:,0])
149/45: plt.imshow(data_elfs[2][0,:,:])
149/46: plt.imshow(data_elfs[2][0,:,:])
149/47: plt.imshow(data_elfs[2][0,:,:])
149/48: plt.imshow(data_elfs[2][0,:,:])
150/1: import matplotlib.pyplot as plt
150/2: import pymatgen.io.vasp as vasp
150/3: elf  = vasp.Elfcar.from_file('ELFCAR')
150/4: elf.data
150/5: elf.data.shape
150/6: elf.data['total']
150/7: elf = elf.data['total']
150/8: elf.shape
150/9: plt.imshow(elf[0,:,:])
150/10: plt.show()
151/1: from "get_ELF-PROCAR" import *
151/2: from "get_ELF-PROCAR.py" import *
151/3: cat get_ELF-PROCAR.py
151/4:
def get_data_kpath(path):
        ls = os.listdir(path)
            i = 0
151/5:     elfs    = []
151/6:     procars = []
151/7:     i = 1
151/8:     tot = len(ls)
151/9:
    for idir in ls :
            print(idir,i,tot)
                if 'mp-' in idir :
                            try :
                                            elfcar = vasp.Elfcar.from_file(path+os.sep+idir+os.sep+'ELFCAR').data['total']
151/10:                 st = vasp.Poscar.from_file(path+os.sep+idir+os.sep+'POSCAR').structure
151/11:                 recLat = st.lattice.reciprocal_lattice.matrix
151/12:                 elfcar = ndimage.affine_transform(elfcar,matrix=recLat,output_shape=(81,81,81),mode='wrap')
151/13:                 repair(path+os.sep+idir+os.sep+'BANDS'+os.sep+'PROCAR',path+os.sep+idir+os.sep+'BANDS'+os.sep+'PROCAR-rep')
151/14:                 procarFile = ProcarParser()
151/15:                 procarFile.readFile(path+os.sep+idir+os.sep+'BANDS'+os.sep+'PROCAR-rep', False)
151/16:                 data = ProcarSelect(procarFile, deepCopy=True)
151/17:                 outcarparser = UtilsProcar()
151/18:                 e_fermi = outcarparser.FermiOutcar(path+os.sep+idir+os.sep+'BANDS'+os.sep+'OUTCAR')
151/19:                 elfs.append(elfcar)
151/20:                 procars.append(data.bands-e_fermi)
151/21:
            except :
    
                    continue
151/22:         i+=1
151/23:     return
151/24:
def get_data_kpath(path):
        ls = os.listdir(path)
            i = 0
151/25:     elfs    = []
151/26:     procars = []
151/27:     i = 1
151/28:     tot = len(ls)
151/29:
    for idir in ls :
            print(idir,i,tot)
                if 'mp-' in idir :
                            try :
                                            elfcar = vasp.Elfcar.from_file(path+os.sep+idir+os.sep+'ELFCAR').data['total']
151/30:                 st = vasp.Poscar.from_file(path+os.sep+idir+os.sep+'POSCAR').structure
151/31:                 recLat = st.lattice.reciprocal_lattice.matrix
151/32:                 elfcar = ndimage.affine_transform(elfcar,matrix=recLat,output_shape=(81,81,81),mode='wrap')
151/33:                 repair(path+os.sep+idir+os.sep+'BANDS'+os.sep+'PROCAR',path+os.sep+idir+os.sep+'BANDS'+os.sep+'PROCAR-rep')
151/34:                 procarFile = ProcarParser()
151/35:                 procarFile.readFile(path+os.sep+idir+os.sep+'BANDS'+os.sep+'PROCAR-rep', False)
151/36:                 data = ProcarSelect(procarFile, deepCopy=True)
151/37:                 outcarparser = UtilsProcar()
151/38:                 e_fermi = outcarparser.FermiOutcar(path+os.sep+idir+os.sep+'BANDS'+os.sep+'OUTCAR')
151/39:                 elfs.append(elfcar)
151/40:                 procars.append(data.bands-e_fermi)
151/41:
            except :
    
                    continue
151/42:         i+=1
151/43:     return
152/1: import h5py
152/2:
from pychemia.utils.mathematics import rotation_matrix_around_axis_angle as rot
from scipy.ndimage import affine_transform
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
152/3: rf = h5py.File('data_kpath_NoAffine.hdf5)
152/4: rf = h5py.File('data_kpath_NoAffine.hdf5')
152/5: rf.keys()
152/6: rf['elfcar']
152/7: data_elf = rf['elfcar'][:,:,:]
152/8: data_elf.shape
152/9: import matplotlib.pyplot as plt
152/10: plt.imshow(data_elf[0,0,:,:])
152/11: plt.imshow(data_elf[1,0,:,:])
152/12: plt.imshow(data_elf[2,0,:,:])
152/13: plt.imshow(data_elf[2,10,:,:])
152/14: data_procar = rf['procar'][:,:,:]
152/15: data_labels = rf['labels'][:]
152/16: data_labels
152/17: rf.close()
152/18:
train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 140,140,140, 1)
test_data_elf  = test_data_elf.reshape(-1,140,140,140,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)
152/19:
def autoencoder(input_img): # 3rdTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(20, (3, 3,3), activation='relu', padding='same')(input_img) #140,140,140 x 20
    pool1 = MaxPooling3D(pool_size=(3,3,3))(conv1) # 70,70,70 x 20
    conv2 = Conv3D(40, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 40
    pool2 = MaxPooling3D(pool_size=(3,3,3))(conv2) #35,35,35 x 40
    conv3 = Conv3D(80, (3, 3,3), activation='relu', padding='same')(pool2) #35,35,35 x 80 (small and thick)

    #decoder
    flat = Flatten()(conv3) # 72900 x 1
    reshape = Reshape((5,5,137200))(flat) # 5,5,137200
    conv5 = Conv2D(729, (3,3), activation='relu', padding='same')(reshape) # 5x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(500, (3, 3), activation='elu', padding='same')(up1) # 10x10x500
    up2 = UpSampling2D((2,4))(conv6) # 20x40x500
    conv7 = Conv2D(200, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x200
    up4 = UpSampling2D((1,2))(conv7) # 20x80x200
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
152/20:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 140,140,140
input_img = Input(shape = (x, y,z, inChannel))
152/21:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
152/22:
def autoencoder(input_img): # 3rdTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(20, (3, 3,3), activation='relu', padding='same')(input_img) #140,140,140 x 20
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 70,70,70 x 20
    conv2 = Conv3D(40, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 40
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #35,35,35 x 40
    conv3 = Conv3D(80, (3, 3,3), activation='relu', padding='same')(pool2) #35,35,35 x 80 (small and thick)

    #decoder
    flat = Flatten()(conv3) # 72900 x 1
    reshape = Reshape((5,5,137200))(flat) # 5,5,137200
    conv5 = Conv2D(729, (3,3), activation='relu', padding='same')(reshape) # 5x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(500, (3, 3), activation='elu', padding='same')(up1) # 10x10x500
    up2 = UpSampling2D((2,4))(conv6) # 20x40x500
    conv7 = Conv2D(200, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x200
    up4 = UpSampling2D((1,2))(conv7) # 20x80x200
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
152/23:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 81,81,81
input_img = Input(shape = (x, y,z, inChannel))
152/24:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
152/25: autoencoder??
152/26: autoencoder??
152/27:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
152/28:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
152/29: train_data_elf.shape
152/30: test_data_elf.shape
152/31:
def autoencoder(input_img): # 3rdTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) #140,140,140 x 20
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 70,70,70 x 20
    conv2 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool1) #27x27x27 x 40
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #35,35,35 x 40
    conv3 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool2) #35,35,35 x 64 (small and thick)

    #decoder
    flat = Flatten()(conv3) # 72900 x 1
    reshape = Reshape((5,5,109760))(flat) # 
    conv5 = Conv2D(729, (3,3), activation='relu', padding='same')(reshape) # 5x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(500, (3, 3), activation='elu', padding='same')(up1) # 10x10x500
    up2 = UpSampling2D((2,4))(conv6) # 20x40x500
    conv7 = Conv2D(200, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x200
    up4 = UpSampling2D((1,2))(conv7) # 20x80x200
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
152/32:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
152/33:
def autoencoder(input_img): # 3rdTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) #140,140,140 x 20
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 70,70,70 x 20
    conv2 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool1) #70x70x70 x 32
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #35,35,35 x 40
    conv3 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool2) #35,35,35 x 64 (small and thick)

    #decoder
    flat = Flatten()(conv3) # 72900 x 1
    reshape = Reshape((5,5,109760))(flat) # 
    conv5 = Conv2D(729, (3,3), activation='relu', padding='same')(reshape) # 5x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(500, (3, 3), activation='elu', padding='same')(up1) # 10x10x500
    up2 = UpSampling2D((2,4))(conv6) # 20x40x500
    conv7 = Conv2D(200, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x200
    up4 = UpSampling2D((1,2))(conv7) # 20x80x200
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
152/34:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
152/35:
def autoencoder(input_img): # 3rdTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) #140,140,140 x 20
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 70,70,70 x 20
    conv2 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool1) #70x70x70 x 32
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #35,35,35 x 40
    conv3 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool2) #35,35,35 x 64 (small and thick)

    #decoder
    flat = Flatten()(conv3) # 72900 x 1
    reshape = Reshape((5,5,109760))(flat) # 
    conv5 = Conv2D(729, (3,3), activation='relu', padding='same')(reshape) # 5x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(500, (3, 3), activation='elu', padding='same')(up1) # 10x10x500
    up2 = UpSampling2D((2,4))(conv6) # 20x40x500
    conv7 = Conv2D(200, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x200
    up4 = UpSampling2D((1,2))(conv7) # 20x80x200
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
152/36: x
152/37:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 140,140,140
input_img = Input(shape = (x, y,z, inChannel))
152/38:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
152/39:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
152/40: autoencoder.summary()
152/41:
def autoencoder(input_img): # 3rdTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 80,80,80 x 8
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #80,80,80 x 16
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #40,40,40 x 16
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #40x40x40x32 (small and thick)
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20,20,20 x 64
    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20 x 64 (small and thick)

    #decoder
    flat = Flatten()(conv3) # 72900 x 1
    reshape = Reshape((5,5,20480))(flat) # 
    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(reshape) # 5x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(32, (3, 3), activation='elu', padding='same')(up1) # 10x10x500
    up2 = UpSampling2D((2,4))(conv6) # 20x40x500
    conv7 = Conv2D(16, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x200
    up4 = UpSampling2D((1,2))(conv7) # 20x80x200
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
152/42:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 160,160,160
input_img = Input(shape = (x, y,z, inChannel))
152/43:
def autoencoder(input_img): # 3rdTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 80,80,80 x 8
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #80,80,80 x 16
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #40,40,40 x 16
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #40x40x40x32 (small and thick)
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20,20,20 x 64
    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20 x 64 (small and thick)

    #decoder
    flat = Flatten()(conv3) # 72900 x 1
    reshape = Reshape((5,5,20480))(flat) # 
    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(reshape) # 5x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(32, (3, 3), activation='elu', padding='same')(up1) # 10x10x500
    up2 = UpSampling2D((2,4))(conv6) # 20x40x500
    conv7 = Conv2D(16, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x200
    up4 = UpSampling2D((1,2))(conv7) # 20x80x200
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
152/44:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
152/45:
def autoencoder(input_img): # 3rdTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 80,80,80 x 8
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #80,80,80 x 16
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #40,40,40 x 16
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #40x40x40x32 (small and thick)
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20,20,20 x 64
    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20 x 64 (small and thick)

    #decoder
    flat = Flatten()(conv3) # 72900 x 1
    reshape = Reshape((5,5,20480))(flat) # 
    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(reshape) # 5x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(32, (3, 3), activation='elu', padding='same')(up1) # 10x10x500
    up2 = UpSampling2D((2,4))(conv6) # 20x40x500
    conv7 = Conv2D(16, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x200
    up4 = UpSampling2D((1,2))(conv7) # 20x80x200
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
152/46:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 160,160,160
input_img = Input(shape = (x, y,z, inChannel))
152/47:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
152/48:
def autoencoder(input_img): # 3rdTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 80,80,80 x 8
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #80,80,80 x 16
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #40,40,40 x 16
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #40x40x40x32 (small and thick)
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20,20,20 x 64
    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20 x 64 (small and thick)

    #decoder
    flat = Flatten()(conv3) # 72900 x 1
    reshape = Reshape((5,5,20480))(flat) # 
    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(reshape) # 5x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(32, (3, 3), activation='elu', padding='same')(up1) # 10x10x500
    up2 = UpSampling2D((2,4))(conv6) # 20x40x500
    conv7 = Conv2D(16, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x200
    up4 = UpSampling2D((1,2))(conv7) # 20x80x200
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
152/49: x
152/50: y
152/51: z
152/52:
def autoencoder(input_img): # 3rdTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 80,80,80 x 8
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #80,80,80 x 16
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #40,40,40 x 16
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #40x40x40x32 (small and thick)
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20,20,20 x 64
    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20 x 64 (small and thick)

    #decoder
    flat = Flatten()(conv4) # 72900 x 1
    reshape = Reshape((5,5,20480))(flat) # 
    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(reshape) # 5x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(32, (3, 3), activation='elu', padding='same')(up1) # 10x10x500
    up2 = UpSampling2D((2,4))(conv6) # 20x40x500
    conv7 = Conv2D(16, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x200
    up4 = UpSampling2D((1,2))(conv7) # 20x80x200
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
152/53:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
152/54:
def autoencoder(input_img): # 3rdTry
    #encoder
    #input = 81 x 81 x 81 1 (wide and thin)
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 80,80,80 x 8
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #80,80,80 x 16
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #40,40,40 x 16
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #40x40x40x32 (small and thick)
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #20,20,20 x 64
    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool3) #20x20x20 x 64 (small and thick)

    #decoder
    flat = Flatten()(conv4) # 72900 x 1
    reshape = Reshape((5,5,20480))(flat) # 
    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(reshape) # 5x5x729 (small and thick)
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729
    conv6 = Conv2D(32, (3, 3), activation='elu', padding='same')(up1) # 10x10x500
    up2 = UpSampling2D((2,4))(conv6) # 20x40x500
    conv7 = Conv2D(16, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x200
    up4 = UpSampling2D((1,2))(conv7) # 20x80x200
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1
    return decoded
152/55:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
152/56:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
152/57: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
153/1:
import h5py
from pychemia.utils.mathematics import rotation_matrix_around_axis_angle as rot
from scipy.ndimage import affine_transform
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
153/2: rf = h5py.File('data_kpath_NoAffine.hdf5')
153/3: data_labels = rf['labels'][:]
153/4: data_procar = rf['procar'][:,:,:]
153/5: data_elf = rf['elfcar'][:,:,:]
153/6: rf.close()
153/7:
train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 160,160,160, 1)
test_data_elf  = test_data_elf.reshape(-1,160,160,160,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)
153/8:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8 
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 80,80,80 x 8 
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #80,80,80 x 16 
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #40,40,40 x 16 
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #40x40x40x32 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #20,20,20 x 64 
    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool3) #20x20x20 x 64 (small and thick) 
    
    #decoder 
    flat = Flatten()(conv4) # 72900 x 1 
    reshape = Reshape((5,5,20480))(flat) #  
    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(reshape) # 5x5x729 (small and thick) 
    up1   = UpSampling2D((2,2))(conv5) # 10x10x729 
    conv6 = Conv2D(32, (3, 3), activation='elu', padding='same')(up1) # 10x10x500 
    up2 = UpSampling2D((2,4))(conv6) # 20x40x500 
    conv7 = Conv2D(16, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x200 
    up4 = UpSampling2D((1,2))(conv7) # 20x80x200 
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1 
    return decoded
153/9:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 160,160,160
input_img = Input(shape = (x, y,z, inChannel))
153/10:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary().
153/11:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
153/12:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
153/13: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
154/1:
import h5py
from pychemia.utils.mathematics import rotation_matrix_around_axis_angle as rot
from scipy.ndimage import affine_transform
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
154/2: rf = h5py.File('data_kpath_NoAffine.hdf5')
154/3: data_elf = rf['elfcar'][:,:,:]
154/4: data_procar = rf['procar'][:,:,:]
154/5: data_labels = rf['labels'][:]
154/6: rf.close()
154/7:
train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 160,160,160, 1)
test_data_elf  = test_data_elf.reshape(-1,160,160,160,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)
154/8:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8 
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 80,80,80 x 8 
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #80,80,80 x 16 
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #40,40,40 x 16 
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #40x40x40x32 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #20,20,20 x 64 
    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool3) #20x20x20 x 64 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10,10,10 x 64 
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x128 (small and thick) 
    #decoder 
    flat = Flatten()(conv4) # 128000 x 1 
    reshape = Reshape((5,5,5120))(flat) #  
    conv5 = Conv2D(2048, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
    up1   = UpSampling2D((2,2))(conv5) # 10x10x2048
    conv6 = Conv2D(1024, (3, 3), activation='elu', padding='same')(up1) # 10x10x1024
    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
    conv7 = Conv2D(512, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x512 
    up4 = UpSampling2D((1,2))(conv7) # 20x80x512
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1 
    return decoded
154/9:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 160,160,160
input_img = Input(shape = (x, y,z, inChannel))
154/10:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
154/11:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8 
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 80,80,80 x 8 
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #80,80,80 x 16 
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #40,40,40 x 16 
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #40x40x40x32 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #20,20,20 x 64 
    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool3) #20x20x20 x 64 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #10,10,10 x 64 
    conv5 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool4) #10x10x10x128 (small and thick) 
    #decoder 
    flat = Flatten()(conv5) # 128000 x 1 
    reshape = Reshape((5,5,5120))(flat) #  
    conv5 = Conv2D(2048, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
    up1   = UpSampling2D((2,2))(conv5) # 10x10x2048
    conv6 = Conv2D(1024, (3, 3), activation='elu', padding='same')(up1) # 10x10x1024
    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
    conv7 = Conv2D(512, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x512 
    up4 = UpSampling2D((1,2))(conv7) # 20x80x512
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1 
    return decoded
154/12:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
154/13:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8 
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 80,80,80 x 8 
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #80,80,80 x 16 
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #40,40,40 x 16 
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #40x40x40x32 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #20,20,20 x 64 
    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool3) #20x20x20 x 64 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #10,10,10 x 64 
    conv5 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool4) #10x10x10x128 (small and thick) 
    #decoder 
    flat = Flatten()(conv5) # 128000 x 1 
    reshape = Reshape((5,5,5120))(flat) #  
    conv5 = Conv2D(512, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
    up1   = UpSampling2D((2,2))(conv5) # 10x10x2048
    conv6 = Conv2D(128, (3, 3), activation='elu', padding='same')(up1) # 10x10x1024
    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
    conv7 = Conv2D(64, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x512 
    up4 = UpSampling2D((1,2))(conv7) # 20x80x512
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1 
    return decoded
154/14:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
154/15:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8 
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 80,80,80 x 8 
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #80,80,80 x 16 
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #40,40,40 x 16 
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #40x40x40x32 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #20,20,20 x 64 
    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool3) #20x20x20 x 64 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #10,10,10 x 64 
    conv5 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool4) #10x10x10x128 (small and thick) 
    #decoder 
    flat = Flatten()(conv5) # 128000 x 1 
    reshape = Reshape((5,5,5120))(flat) #  
    conv5 = Conv2D(128, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
    up1   = UpSampling2D((2,2))(conv5) # 10x10x2048
    conv6 = Conv2D(64, (3, 3), activation='elu', padding='same')(up1) # 10x10x1024
    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
    conv7 = Conv2D(32, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x512 
    up4 = UpSampling2D((1,2))(conv7) # 20x80x512
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1 
    return decoded
154/16:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
154/17:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
154/18: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
155/1:
import h5py
from pychemia.utils.mathematics import rotation_matrix_around_axis_angle as rot
from scipy.ndimage import affine_transform
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
155/2: rf = h5py.File('data_kpath_NoAffine.hdf5')
155/3: data_elf = rf['elfcar'][:,:,:]
155/4: data_labels = rf['labels'][:]
155/5: data_procar = rf['procar'][:,:,:]
155/6: rf.close()
155/7:
train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 160,160,160, 1)
test_data_elf  = test_data_elf.reshape(-1,160,160,160,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)
155/8:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8 
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 80,80,80 x 8 
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #80,80,80 x 16 
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #40,40,40 x 16 
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #40x40x40x32 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #20,20,20 x 64 
    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool3) #20x20x20 x 64 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10,10,10 x 64 
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x128 (small and thick) 
    #decoder 
    reshape = Reshape((20,80,80))(conv4) #  
    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
#    up1   = UpSampling2D((2,2))(conv5) # 10x10x2048
    conv6 = Conv2D(32, (3, 3), activation='elu', padding='same')(conv5) # 10x10x1024
#    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
    conv7 = Conv2D(16, (3, 3), activation='sigmoid', padding='same')(conv6) # 20x40x512 
#    up4 = UpSampling2D((1,2))(conv7) # 20x80x512
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(conv7) # 20x80x1 
    return decoded
155/9:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 160,160,160
input_img = Input(shape = (x, y,z, inChannel))
155/10:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
155/11:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8 
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 80,80,80 x 8 
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #80,80,80 x 16 
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #40,40,40 x 16 
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #40x40x40x32 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #20,20,20 x 64 
    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool3) #20x20x20 x 64 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10,10,10 x 64 
    conv5 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x128 (small and thick) 
    #decoder 
    reshape = Reshape((20,80,80))(conv5) #  
    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
#    up1   = UpSampling2D((2,2))(conv5) # 10x10x2048
    conv6 = Conv2D(32, (3, 3), activation='elu', padding='same')(conv5) # 10x10x1024
#    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
    conv7 = Conv2D(16, (3, 3), activation='sigmoid', padding='same')(conv6) # 20x40x512 
#    up4 = UpSampling2D((1,2))(conv7) # 20x80x512
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(conv7) # 20x80x1 
    return decoded
155/12:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
155/13: x
155/14: y
155/15: z
155/16: input_img
155/17:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8 
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 80,80,80 x 8 
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #80,80,80 x 16 
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #40,40,40 x 16 
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #40x40x40x32 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #20,20,20 x 64 
    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool3) #20x20x20 x 64 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv4) #10,10,10 x 64 
    conv5 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x128 (small and thick) 
    #decoder 
    reshape = Reshape((20,80,80))(conv5) #  
    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
#    up1   = UpSampling2D((2,2))(conv5) # 10x10x2048
    conv6 = Conv2D(32, (3, 3), activation='elu', padding='same')(conv5) # 10x10x1024
#    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
    conv7 = Conv2D(16, (3, 3), activation='sigmoid', padding='same')(conv6) # 20x40x512 
#    up4 = UpSampling2D((1,2))(conv7) # 20x80x512
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(conv7) # 20x80x1 
    return decoded
155/18:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
155/19:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
155/20:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
155/21: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
156/1:
import h5py
from pychemia.utils.mathematics import rotation_matrix_around_axis_angle as rot
from scipy.ndimage import affine_transform
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
156/2: rf = h5py.File('data_kpath_NoAffine.hdf5')
156/3: data_procar = rf['procar'][:,:,:]
156/4: data_labels = rf['labels'][:]
156/5: data_labels = rf['labels'][:]
156/6: data_elf = rf['elfcar'][:,:,:]
158/1:
import h5py
from pychemia.utils.mathematics import rotation_matrix_around_axis_angle as rot
from scipy.ndimage import affine_transform
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
158/2: rf = h5py.File('data_kpath_NoAffine.hdf5')
158/3: data_elf = rf['elfcar'][:,:,:]
158/4: data_labels = rf['labels'][:]
158/5: data_procar = rf['procar'][:,:,:]
158/6: rf.close()
158/7:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8 
    pool1 = MaxPooling3D(pool_size=(4,4,4))(conv1) # 40,40,40 x 8 
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #40,40,40 x 16 
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20,20,20 x 16 
    conv3 = Conv3D(64,(3, 3,3), activation='relu', padding='same')(pool2) #20,20,20x32 (small and thick) 
#    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #20,20,20 x 64 
#    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10 x 64 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10,10,10 x 64 
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x128 (small and thick) 
    #decoder 
    flat = Flatten()(conv4) # 128000 x 1 
    reshape = Reshape((5,5,5120))(flat) #  
    conv5 = Conv2D(2048, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
    up1   = UpSampling2D((2,2))(conv5) # 10x10x2048
    conv6 = Conv2D(1024, (3, 3), activation='elu', padding='same')(up1) # 10x10x1024
    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
    conv7 = Conv2D(512, (3, 3), activation='sigmoid', padding='same')(up2) # 20x40x512 
    up4 = UpSampling2D((1,2))(conv7) # 20x80x512
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1 
    return decoded
158/8:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 160,160,160
input_img = Input(shape = (x, y,z, inChannel))
158/9:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
158/10:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8 
    pool1 = MaxPooling3D(pool_size=(4,4,4))(conv1) # 40,40,40 x 8 
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #40,40,40 x 16 
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20,20,20 x 16 
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #20,20,20x32 (small and thick) 
#    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #20,20,20 x 64 
#    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool3) #20x20x20 x 64 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10,10,10 x 32
    conv5 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x128 (small and thick) 
    #decoder 
    reshape = Reshape((20,80,80))(conv5) #  
    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
#    up1   = UpSampling2D((2,2))(conv5) # 10x10x2048
    conv6 = Conv2D(32, (3, 3), activation='elu', padding='same')(conv5) # 10x10x1024
#    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
    conv7 = Conv2D(16, (3, 3), activation='sigmoid', padding='same')(conv6) # 20x40x512 
#    up4 = UpSampling2D((1,2))(conv7) # 20x80x512
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(conv7) # 20x80x1 
    return decoded
158/11:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
158/12: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
158/13:
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
158/14:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
158/15:
train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 160,160,160, 1)
test_data_elf  = test_data_elf.reshape(-1,160,160,160,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)
158/16:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
158/17: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
159/1:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #160,160,160 x 8 
    pool1 = MaxPooling3D(pool_size=(4,4,4))(conv1) # 40,40,40 x 8 
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #40,40,40 x 16 
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20,20,20 x 16 
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #20,20,20x32 (small and thick) 
#    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #20,20,20 x 64 
#    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool3) #20x20x20 x 64 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10,10,10 x 32
    conv5 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x128 (small and thick) 
    #decoder 
    reshape = Reshape((20,80,80))(conv5) #  
    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
#    up1   = UpSampling2D((2,2))(conv5) # 10x10x2048
    conv6 = Conv2D(32, (3, 3), activation='sigmoid', padding='same')(conv5) # 10x10x1024
#    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
    conv7 = Conv2D(16, (3, 3), activation='linear', padding='same')(conv6) # 20x40x512 
#    up4 = UpSampling2D((1,2))(conv7) # 20x80x512
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(conv7) # 20x80x1 
    return decoded
159/2:
import h5py
from pychemia.utils.mathematics import rotation_matrix_around_axis_angle as rot
from scipy.ndimage import affine_transform
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
159/3: rf = h5py.File('data_kpath_NoAffine.hdf5')
159/4: data_procar = rf['procar'][:,:,:]
159/5: data_elf = rf['elfcar'][:,:,:]
159/6: data_labels = rf['labels'][:]
159/7:
train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 160,160,160, 1)
test_data_elf  = test_data_elf.reshape(-1,160,160,160,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)
159/8:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 160,160,160
input_img = Input(shape = (x, y,z, inChannel))
159/9:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
159/10:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
159/11: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
160/1: ll
160/2: cd ..
160/3: ll
160/4: cd ML-Antiperovskite/
160/5: ll
160/6: cd mp-8368_194
160/7: ll
161/1: import pymatgen.io.vasp as vasp
161/2: elf  = vasp.Elfcar.from_file('ELFCAR')
161/3: elf = elf.data['total']
161/4: elf
161/5: elf.shape
161/6: import matplotlib.pyplot as plt
161/7: plt.imshow(elf[0,:,:])
161/8: plt.imshow(elf[:,:,0])
161/9: vasprun = vasp.Vasprun('vasprun.xml')
161/10: vasprun.structures
161/11: st = vasprun.structures
161/12: st
161/13: st[0]
161/14: st[0].replace_species()
161/15: lt = st[0].lattice
161/16: lt.reciprocal_lattice.matrix
161/17: import numpy as np
161/18: from scipy.ndimage import affine_transform
161/19: plt.imshow(affine_transform(elf,matrix=lt.reciprocal_lattice.matrix,(81,81,81),mode='wrap'))
161/20: plt.imshow(affine_transform(elf,matrix=lt.reciprocal_lattice.matrix,output_shape=(81,81,81),mode='wrap'))
161/21: plt.imshow(affine_transform(elf,matrix=lt.reciprocal_lattice.matrix,output_shape=(81,81,81),mode='wrap')[0,::])
161/22: plt.imshow(affine_transform(elf,matrix=lt.reciprocal_lattice.matrix,output_shape=(81,81,81),mode='wrap')[0,:,:])
161/23: plt.imshow(affine_transform(elf,matrix=lt.reciprocal_lattice.matrix,output_shape=(81,81,81),mode='wrap')[:,:,0])
161/24: cd ..
161/25: ls
161/26: cd isym-1_nbands80
162/1: import matplotlib.pyplot as plt
162/2: import pymatgen.io.vasp as vasp
162/3: import numpy as np
162/4: from scipy.ndimage import affine_transform
162/5: vasprun = vasp.Vasprun('vasprun.xml')
162/6: vasp.Elfcar?
162/7: vasp.Elfcar()
162/8: elf  = vasp.Elfcar.from_file('ELFCAR')
162/9: elf = elf.data['total']
162/10: elf.shape
162/11: st = vasprun.structures
162/12: lt = st[0].lattice
162/13: lt
162/14: mt = lt.reciprocal_lattice.matrix
162/15: mt
162/16: plt.imshow(affine_transform(elf,matrix=lt.reciprocal_lattice.matrix,output_shape=(81,81,81),mode='wrap')[:,:,0])
162/17: plt.imshow(affine_transform(elf,matrix=lt.reciprocal_lattice.matrix,output_shape=(81,81,81),mode='wrap')[0,:,:])
162/18: plt.imshow(affine_transform(np.pad(elf,(100,100)),matrix=lt.reciprocal_lattice.matrix,output_shape=(81,81,81),mode='wrap')[0,:,:])
162/19: plt.imshow(affine_transform(np.pad(elf,(100,100),mode='wrap'),matrix=lt.reciprocal_lattice.matrix,output_shape=(81,81,81),mode='wrap')[0,:,:])
162/20: plt.imshow(elf[:,00])
162/21: plt.imshow(elf[:,0,0])
162/22: plt.imshow(elf[0,:,:])
162/23: plt.imshow(np.pad(elf[0,:,:].(128,128,128)))
162/24: plt.imshow(np.pad(elf[0,:,:],(128,128,128)))
162/25: plt.imshow(np.pad(elf[0,:,:],(128,128,128),mode='wrap'))
162/26: plt.imshow(np.pad(elf[0,:,:],(128,128,128),mode='wrap')[0,::])
162/27: plt.imshow(np.pad(elf[0,:,:],(128,128,128),mode='wrap')[0,:,:])
162/28: plt.imshow(np.pad(elf,(128,128,128),mode='wrap')[0,:,:])
162/29: plt.imshow(np.pad(elf,(128,128),mode='wrap')[0,:,:])
162/30: plt.imshow(np.pad(elf,(128,128),mode='wrap')[0,:,:])
162/31: plt.imshow(affine_transform(np.pad(elf,(100,100),mode='wrap'),matrix=lt.reciprocal_lattice.matrix,output_shape=(81,81,81),mode='wrap',order=5)[0,:,:])
162/32: plt.imshow(affine_transform(np.pad(elf,(100,100),mode='wrap'),matrix=lt.reciprocal_lattice.matrix,output_shape=(200,200,200),mode='wrap',order=5)[0,:,:])
162/33: plt.imshow(affine_transform(np.pad(elf,(100,100),mode='wrap'),matrix=lt.reciprocal_lattice.matrix,output_shape=(200,200,200),mode='constant',order=5)[0,:,:])
162/34: plt.imshow(affine_transform(np.pad(elf,(100,100),mode='wrap'),matrix=lt.reciprocal_lattice.matrix,mode='constant',order=5)[0,:,:])
162/35: a = affine_transform(np.pad(elf,(100,100),mode='wrap'),matrix=lt.reciprocal_lattice.matrix,mode='constant',order=5)
162/36: a
162/37: plt.imshow(affine_transform(np.pad(elf,(100,100),mode='wrap'),matrix=lt.reciprocal_lattice.matrix,mode='wrap',order=5)[0,:,:])
162/38: pwd
162/39: lt
162/40: plt.imshow(affine_transform(np.pad(elf,(100,100),mode='wrap'),matrix=mt,mode='wrap',order=5)[0,:,:])
162/41: import numpy as np
162/42: plt.imshow(np.dot(elf,mt)[:,:,0])
162/43: plt.imshow(np.dot(mt,elf)[:,:,0])
162/44: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',order=5)[0,:,:])
162/45: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',order=5)[0,:,:])
162/46: elf.shape
162/47: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(40,80,56),order=5)[0,:,:])
162/48: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(20,20,20),order=5)[0,:,:])
162/49: plt.imshow(affine_transform(np.pad(elf,(100,100),mode='wrap'),matrix=mt,mode='wrap',order=5)[0,:,:])
164/1: import pymatgen.io.vasp as vasp
164/2: import numpy as np
164/3: import matplotlib.pyplot as plt
164/4: elf  = vasp.Elfcar.from_file('ELFCAR')
164/5: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(20,20,20),order=5)[0,:,:])
164/6: from scipy.ndimage import affine_transform
164/7: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(20,20,20),order=5)[0,:,:])
164/8: st = vasprun.structures
164/9: vasprun = vasp.Vasprun('vasprun.xml')
164/10: st = vasprun.structures
164/11: mt = lt.reciprocal_lattice.matrix
164/12: lt = st[0].lattice
164/13: mt = lt.reciprocal_lattice.matrix
164/14: mt
165/1: import opencv
165/2: import cv2
165/3: import cv2
164/15: mt.round(5)
164/16: mt.round(6)
164/17: mt.round(4)
164/18: mt.round(3)
164/19: mt.round(4)
164/20: mt.round(3)
164/21: st = vasprun.structures
164/22: import skimage.transform.ProjectiveTransform as pt
164/23: import skimage.transform.ProjectiveTransform as pt
164/24: import skimage.transform.ProjectiveTransform as pt
164/25: import skimage.transform as tr
164/26: pr = tr.ProjectiveTransform(matrix=mt)
164/27: pr
164/28: pr?
164/29: pr(elf)
164/30: pr
164/31: pr.params
164/32: pr.estimate(elf)
164/33: pr.estimate()(elf)
164/34: pr.estimate(np.zeros_like(elf),elf)
164/35: pr.estimate(elf,np.zeros_like(elf))
164/36: pr.estimate?
164/37: elf
164/38: elf = elf.data['total']
164/39: elf
164/40: plt
164/41: plt.imshow(elf[0,:,:])
164/42: plt.imshow(np.pad(elf[0,:,:],(140,140,140)))
164/43: plt.imshow(np.pad(elf[0,:,:],(140,140,140),mode='wrap'))
164/44: plt.imshow(np.pad(elf[0,:,:],(140,140),mode='wrap'))
164/45: plt.imshow(np.pad(elf[0,:,:],(50,50),mode='wrap'))
164/46: plt.imshow(np.pad(elf[0,:,:],(50,50),mode='wrap'))
164/47: plt.imshow(np.pad(elf[0,:,:],mode='wrap'))
164/48: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(20,20,20),order=5)[0,:,:])
164/49: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(400,400,400),order=5)[0,:,:])
164/50: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(100,100,100),order=2)[0,:,:])
164/51: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(100,100,100),order=3,cval=0.5)[0,:,:])
164/52: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(100,100,100),order=3,cval=1)[0,:,:])
164/53: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(100,100,100),order=3,cval=1)[20,:,:])
164/54: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(100,100,100),order=3,cval=1)[22,:,:])
164/55: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(100,100,100),order=3,cval=1)[18,:,:])
164/56: plt.imshow(elf[18,:,:])
164/57: plt.imshow(np.pad(elf[18,:,:],(50,50),mode='wrap'))
164/58: plt.imshow(elf[18,:,:])
164/59: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(100,100,100),order=3,cval=1)[18,:,:])
164/60: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(150,150,150),order=3,cval=1)[18,:,:])
164/61: np.linalg.inv(mt)
164/62: mtp = np.linalg.inv(mt)
164/63: plt.imshow(affine_transform(elf,matrix=mtp,mode='wrap',output_shape=(150,150,150),order=3,cval=1)[18,:,:])
164/64: plt.imshow(affine_transform(elf,matrix=lt.matrix,mode='wrap',output_shape=(150,150,150),order=3,cval=1)[18,:,:])
164/65: plt.imshow(affine_transform(elf,matrix=np.linalg.inv(lt.matrix),mode='wrap',output_shape=(150,150,150),order=3,cval=1)[18,:,:])
164/66: np.linalg.inv(lt.matrix)
164/67: plt.imshow(affine_transform(elf,matrix=np.linalg.inv(lt.matrix)*10,mode='wrap',output_shape=(150,150,150),order=3,cval=1)[18,:,:])
164/68: plt.imshow(affine_transform(elf,matrix=np.linalg.inv(lt.matrix)*100,mode='wrap',output_shape=(150,150,150),order=3,cval=1)[18,:,:])
164/69: plt.imshow(affine_transform(elf,matrix=np.linalg.inv(lt.matrix),mode='wrap',order=3,cval=1)[18,:,:])
164/70: plt.imshow(affine_transform(elf,matrix=np.linalg.inv(lt.matrix),mode='wrap',(180,180,180)order=3,cval=1)[18,:,:])
164/71: plt.imshow(affine_transform(elf,matrix=np.linalg.inv(lt.matrix),mode='wrap',output_shape=(180,180,180),order=3,cval=1)[18,:,:])
164/72: plt.imshow(affine_transform(elf,matrix=np.linalg.inv(lt.matrix),mode='wrap',output_shape=(1000,1000,1000),order=3,cval=1)[18,:,:])
164/73: lt.reciprocal_lattice.matrix
164/74: np.linalg.inv(lt.matrix)
164/75: np.linalg.inv(lt.matrix)/np.linalg.inv(lt.matrix)
164/76: 1.19098655e+00/1.89551396e-01
164/77: 2*np.pi
164/78: plt.imshow(affine_transform(elf,matrix=np.linalg.inv(lt.matrix),mode='wrap',output_shape=(500,500,500),order=2)[18,:,:])
164/79: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(500,500,500),order=2)[18,:,:])
164/80: plt.imshow(affine_transform(elf,matrix=mt,mode='constant',output_shape=(100,100),order=2)[18,:,:])
164/81: plt.imshow(affine_transform(elf,matrix=mt,mode='constant',output_shape=(100,100))[18,:,:])
164/82: plt.imshow(affine_transform(elf,matrix=mt,mode='constant',output_shape=(140,140))[18,:,:])
164/83: plt.imshow(affine_transform(elf,matrix=mt,mode='constant',output_shape=(140,140,140))[18,:,:])
164/84: plt.imshow(affine_transform(elf,matrix=mt,mode='ferlect',output_shape=(140,140,140))[18,:,:])
164/85: plt.imshow(affine_transform(elf,matrix=mt,mode='reflect',output_shape=(140,140,140))[18,:,:])
164/86: plt.imshow(affine_transform(elf,matrix=mt,mode='nearest',output_shape=(140,140,140))[18,:,:])
164/87: plt.imshow(affine_transform(elf,matrix=mt,mode='mirror',output_shape=(140,140,140))[18,:,:])
164/88: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(140,140,140))[18,:,:])
164/89: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap')[18,:,:])
164/90: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap')[0,:,:])
164/91: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap')[:,:,0])
164/92: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap')[:,:,2])
164/93: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(140,140,140))[:,:,2])
164/94: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(160,160,160))[:,:,2])
164/95: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(160,160,240))[:,:,2])
164/96: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(210,210,140))[:,:,2])
164/97: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(1000,1000,140))[:,:,2])
164/98: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(3000,3000,140))[:,:,2])
164/99: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(140,140,140))[18,:,:])
164/100: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(3000,3000,140))[:,:,2])
166/1: import matplotlib.pyplot as plt
166/2: import pymatgen.io.vasp as vasp
166/3: elf  = vasp.Elfcar.from_file('ELFCAR')
166/4: ls
166/5: cd ..
166/6: ls
166/7: elf  = vasp.Elfcar.from_file('ELFCAR')
166/8: elf = elf.data['total']
166/9: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(140,140,140))[18,:,:])
166/10: from scipy.ndimage import affine_transform
166/11: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(140,140,140))[18,:,:])
166/12: vasprun = vasp.Vasprun('vasprun.xml')
166/13: st = vasprun.structures
166/14: mt = lt.reciprocal_lattice.matrix
166/15: lt = st[0].lattice
166/16: mt = lt.reciprocal_lattice.matrix
166/17: plt.imshow(affine_transform(elf,matrix=mt,mode='wrap',output_shape=(140,140,140))[18,:,:])
166/18: test = np.pad(1,elf,(1,1),mode='constant')
166/19: import numpy as np
166/20: test = np.pad(1,elf,(1,1),mode='constant')
166/21: test = np.pad(elf,(1,1),1,mode='constant')
166/22: test = np.pad(elf,((1,1)),1,mode='constant')
166/23: test = np.pad(elf,((1,1)),mode='constant')
166/24: test
166/25: test.shape
166/26: test = np.pad(elf,((1,)),mode='constant')
166/27: test.shape
166/28: test
166/29: test = np.pad(elf,(1,0),mode='constant')
166/30: test
166/31: test.shape
166/32: elf.shape
166/33: plt.imshow(affine_transform(test,matrix=mt,mode='wrap',output_shape=(140,140,140))[18,:,:])
166/34: test = np.pad(elf,(1,0),mode='mean')
166/35: plt.imshow(affine_transform(test,matrix=mt,mode='wrap',output_shape=(140,140,140))[18,:,:])
166/36: plt.imshow(affine_transform(test,matrix=mt,mode='wrap',output_shape=(400,400,400))[18,:,:])
166/37: plt.imshow(affine_transform(test,matrix=mt,mode='wrap',output_shape=(140,140,140))[18,:,:])
166/38: plt.imshow([18,:,:])
166/39: a = affine_transform(test,matrix=mt,mode='wrap',output_shape=(140,140,140))
166/40: rot_x = np.array([[1,0,0],[0,np.cos(np.pi/3),-1*np.sin(np.pi/3)],[0,np.sin(np.pi/3),np.cos(np.pi/3)]])
166/41: rot
166/42: rot_x
166/43: b = affine_transform(a,matrix=rot_x,mode='wrap',output=(140,140,140))
166/44: b = affine_transform(a,matrix=rot_x,mode='wrap',output_shape=(140,140,140))
166/45: plt.imshow(a[18,:,:])
166/46: plt.imshow(b[18,:,:])
166/47: a = np.pad(a,(1,0),mode='mean')
166/48: b = affine_transform(a,matrix=rot_x,mode='wrap',output_shape=(140,140,140))
166/49: plt.imshow(b[18,:,:])
166/50: plt.imshow(b[18,:,:])
166/51: mt
166/52: np.dot(mt,rot_x)
166/53: plt.imshow(affine_transform(test,matrix=np.dot(mt,rot_x),mode='wrap',output_shape=(140,140,140))[18,:,:])
166/54: plt.imshow(affine_transform(elf,matrix=np.dot(mt,rot_x),mode='wrap',output_shape=(140,140,140))[18,:,:])
166/55: plt.imshow(affine_transform(elf,matrix=np.dot(rot_x,mt),mode='wrap',output_shape=(140,140,140))[18,:,:])
166/56: plt.imshow(affine_transform(test,matrix=np.dot(mt,rot_x),mode='wrap',output_shape=(140,140,140))[18,:,:])
166/57: plt.imshow(affine_transform(test,matrix=rot_x,mode='wrap',output_shape=(140,140,140))[18,:,:])
166/58: plt.imshow(affine_transform(elf,matrix=rot_x,mode='wrap',output_shape=(140,140,140))[18,:,:])
166/59: plt.imshow(elf[18,:,:])
166/60: plt.imshow(affine_transform(elf,matrix=rot_x,mode='wrap')[18,:,:])
166/61: plt.imshow(affine_transform(elf,matrix=rot_x)[18,:,:])
166/62: plt.imshow(affine_transform(elf,matrix=mt)[18,:,:])
166/63: plt.imshow(affine_transform(elf,matrix=mt,output_shape=(200,200,200))[18,:,:])
166/64: plt.imshow(affine_transform(elf,matrix=mt,output_shape=(200,200,200))[18,:,:])
166/65: a = plt.imshow(affine_transform(elf,matrix=mt,output_shape=(200,200,200)))
166/66: a
166/67: a = affine_transform(elf,matrix=mt,output_shape=(200,200,200))
166/68: a
166/69: a = plt.imshow(affine_transform(elf,matrix=mt,output_shape=(200,200,200)))
166/70: plt.imshow(affine_transform(elf,matrix=mt,output_shape=(200,200,200))[18,:,:])
166/71: plt.imshow(affine_transform(elf,matrix=mt,output_shape=(200,200,200))[18,:,:])
166/72: plt.imshow(affine_transform(np.pad(elf,(200,200,200),mode='wrap'),matrix=mt,output_shape=(200,200,200))[18,:,:])
166/73: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=mt,output_shape=(200,200,200))[18,:,:])
166/74: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=mt,output_shape=(400,400,400))[18,:,:])
166/75: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=mt,output_shape=(400,400,400),offset=200)[18,:,:])
166/76: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=mt,output_shape=(80,80,80),offset=200)[18,:,:])
166/77: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=np.dot(mt,rot_x),output_shape=(80,80,80),offset=200)[18,:,:])
166/78: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=np.dot(mt,rot_x),offset=200)[18,:,:])
166/79: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=np.dot(mt,rot_x),output_shape=(22,22,22),offset=200)[18,:,:])
166/80: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=np.dot(mt*2,rot_x),output_shape=(22,22,22),offset=200)[18,:,:])
166/81: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=np.dot(mt*4,rot_x),output_shape=(22,22,22),offset=200)[18,:,:])
166/82: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=np.dot(mt*2,rot_x),output_shape=(40,40,40),offset=200)[18,:,:])
166/83: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=np.dot(mt*2,rot_x),output_shape=(80,80,80),offset=200)[18,:,:])
166/84: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=np.dot(mt*2,rot_x),output_shape=(80,80,80),offset=200)[18,:,:])
166/85: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=np.dot(mt,rot_x),output_shape=(80,80,80),offset=200)[18,:,:])
166/86: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=np.dot(mt*1.5,rot_x),output_shape=(80,80,80),offset=200)[18,:,:])
166/87: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=mt*1.5,output_shape=(80,80,80),offset=200)[18,:,:])
166/88: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=mt*2,output_shape=(80,80,80),offset=200)[18,:,:])
166/89: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=np.dot(mt,rot_x),output_shape=(80,80,80),offset=200)[18,:,:])
166/90: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=np.dot(mt,rot_x),output_shape=(80,80,80),offset=200)[:,:,0])
166/91: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=np.dot(mt,rot_x),output_shape=(80,80,80),offset=200)[:,:,0])
166/92: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=np.dot(mt,rot_x),output_shape=(80,80,80),offset=200)[0,:,:])
166/93: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=np.dot(mt,rot_x),output_shape=(160,160,160),offset=200)[0,:,:])
166/94: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=mt,output_shape=(160,160,160),offset=200)[0,:,:])
166/95: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=mt,output_shape=(140),offset=200)[0,:,:])
166/96: plt.imshow(affine_transform(np.pad(elf,(200,200),mode='wrap'),matrix=mt,output_shape=(140,140,140),offset=200)[0,:,:])
167/1:
import h5py
from pychemia.utils.mathematics import rotation_matrix_around_axis_angle as rot
from scipy.ndimage import affine_transform
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
167/2: rf = h5py.File('data_kpath_Affine.hdf5')
167/3: data_labels = rf['labels'][:]
167/4: data_elf = rf['elfcar'][:,:,:]
167/5: data_procar = rf['procar'][:,:,:]
167/6: rf.close()
167/7: import matplotlib.pyplot as plt
167/8:
plt.imshow(affine_transform(np.pad(data_elf[0],(200,200),mode='wrap'),matrix=,output_shape=(140,140,140),offset=200)[0,:,:]
)
167/9: plt.imshow(data_elf[0][:,:,0])
167/10: plt.imshow(data_elf[1][:,:,0])
167/11: data_labels[1]
167/12: plt.imshow(data_elf[1][:,:,0])
167/13: plt.imshow(np.pad(data_elf[1],(120,120),mode='wrap'))
167/14: plt.imshow(np.pad(data_elf[1],(120,120),mode='wrap')[:,:,0])
167/15:
train_data_elf = data_elf[:400,:,:,:]
test_data_elf = data_elf[400:,:,:,:]
train_data_procar = data_procar[:400,:,:]
test_data_procar = data_procar[400:,:,:]
train_data_elf = train_data_elf.reshape(-1, 80,80,80, 1)
test_data_elf  = test_data_elf.reshape(-1,80,80,80,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)
167/16:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(input_img) #80,80,80 x 8 
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40,40,40 x 8 
    conv2 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(pool1) #40,40,40 x 16 
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20,20,20 x 16 
    conv3 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool2) #20,20,20x32 (small and thick) 
#    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #20,20,20 x 64 
#    conv4 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool3) #20x20x20 x 64 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10,10,10 x 32
    conv5 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x128 (small and thick) 
    #decoder 
    reshape = Reshape((20,80,80))(conv5) #  
    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
#    up1   = UpSampling2D((2,2))(conv5) # 10x10x2048
    conv6 = Conv2D(32, (3, 3), activation='sigmoid', padding='same')(conv5) # 10x10x1024
#    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
    conv7 = Conv2D(16, (3, 3), activation='linear', padding='same')(conv6) # 20x40x512 
#    up4 = UpSampling2D((1,2))(conv7) # 20x80x512
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(conv7) # 20x80x1 
    return decoded
167/17:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 80,80,80
input_img = Input(shape = (x, y,z, inChannel))
167/18:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
167/19:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
167/20: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
167/21:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) #80,80,80 x 8 
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40,40,40 x 8 
    conv2 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool1) #40,40,40 x 16 
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20,20,20 x 16 
    conv3 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool2) #20,20,20x32 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10,10,10 x 64 
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10 x 128 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #5,5,5,128
    conv5 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(pool3) #5,5,5*256 (small and thick) 
    #decoder 
    reshape = Reshape((20,80,20))(conv5) #  
#    conv5 = Conv2D(64, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
#    up1   = UpSampling2D((2,2))(conv5) # 10x10x2048
#    conv6 = Conv2D(32, (3, 3), activation='sigmoid', padding='same')(conv5) # 10x10x1024
#    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
#    conv7 = Conv2D(16, (3, 3), activation='linear', padding='same')(conv6) # 20x40x512 
#    up4 = UpSampling2D((1,2))(conv7) # 20x80x512
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(reshape) # 20x80x1 
    return decoded
167/22:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
167/23:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) #80,80,80 x 16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40,40,40 x 16
    conv2 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool1) #40,40,40 x 32
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20,20,20 x 32
    conv3 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool2) #20,20,20x64 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10,10,10 x 64 
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10 x 128 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #5,5,5,128
    conv5 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(pool3) #5,5,5*256 (small and thick) 
    #decoder 
    reshape = Reshape((20,80,20))(conv5) #  
    conv5 = Conv2D(10, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
#    up1   = UpSampling2D((2,2))(conv5) # 10x10x2048
#    conv6 = Conv2D(32, (3, 3), activation='sigmoid', padding='same')(conv5) # 10x10x1024
#    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
#    conv7 = Conv2D(16, (3, 3), activation='linear', padding='same')(conv6) # 20x40x512 
#    up4 = UpSampling2D((1,2))(conv7) # 20x80x512
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(conv5) # 20x80x1 
    return decoded
167/24:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
167/25:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) #80,80,80 x 16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40,40,40 x 16
    conv2 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool1) #40,40,40 x 32
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20,20,20 x 32
    conv3 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool2) #20,20,20x64 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10,10,10 x 64 
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10 x 128 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5,5,5,128
    conv5 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(pool3) #5,5,5*256 (small and thick) 
    #decoder 
    reshape = Reshape((20,80,20))(conv5) #  
    conv5 = Conv2D(10, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
#    up1   = UpSampling2D((2,2))(conv5) # 10x10x2048
#    conv6 = Conv2D(32, (3, 3), activation='sigmoid', padding='same')(conv5) # 10x10x1024
#    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
#    conv7 = Conv2D(16, (3, 3), activation='linear', padding='same')(conv6) # 20x40x512 
#    up4 = UpSampling2D((1,2))(conv7) # 20x80x512
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(conv5) # 20x80x1 
    return decoded
167/26:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
167/27:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
167/28: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
168/1:
import h5py
from pychemia.utils.mathematics import rotation_matrix_around_axis_angle as rot
from scipy.ndimage import affine_transform
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
168/2: rf = h5py.File('data_kpath_Affine_RepData.hdf5.hdf5')
168/3: data_procar = rf['procar'][:,:,:]
168/4: rf.close()
168/5: rf = h5py.File('data_kpath_Affine_RepData.hdf5')
168/6: rm data_kpath_Affine_RepData.hdf5.hdf5
168/7: data_procar = rf['procar'][:,:,:]
168/8: data_elf = rf['elfcar'][:,:,:]
168/9: data_labels = rf['labels'][:]
168/10: rf.close()
168/11:
train_data_elf = data_elf[:1000,:,:,:]
test_data_elf = data_elf[1000:,:,:,:]
train_data_procar = data_procar[:1000,:,:]
test_data_procar = data_procar[1000:,:,:]
train_data_elf = train_data_elf.reshape(-1, 80,80,80, 1)
test_data_elf  = test_data_elf.reshape(-1,80,80,80,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)
168/12:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) #80,80,80 x 16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40,40,40 x 16
    conv2 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool1) #40,40,40 x 32
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20,20,20 x 32
    conv3 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool2) #20,20,20x64 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10,10,10 x 64 
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10 x 128 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5,5,5,128
    conv5 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(pool3) #5,5,5*256 (small and thick) 
    #decoder 
    reshape = Reshape((20,80,20))(conv5) #  
    conv5 = Conv2D(10, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
#    up1   = UpSampling2D((2,2))(conv5) # 10x10x2048
#    conv6 = Conv2D(32, (3, 3), activation='sigmoid', padding='same')(conv5) # 10x10x1024
#    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
#    conv7 = Conv2D(16, (3, 3), activation='linear', padding='same')(conv6) # 20x40x512 
#    up4 = UpSampling2D((1,2))(conv7) # 20x80x512
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(conv5) # 20x80x1 
    return decoded
168/13:
batch_size = 20
epochs = 100
inChannel = 1
x,y,z = 80,80,80
input_img = Input(shape = (x, y,z, inChannel))
168/14:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
168/15:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
168/16: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
169/1:
import h5py
from pychemia.utils.mathematics import rotation_matrix_around_axis_angle as rot
from scipy.ndimage import affine_transform
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
169/2: rf = h5py.File('data_kpath_Affine_RepData.hdf5')
169/3: data_procar = rf['procar'][:,:,:]
169/4: data_labels = rf['labels'][:]
169/5: data_elf = rf['elfcar'][:,:,:]
169/6:
train_data_elf = data_elf[:1000,:,:,:]
test_data_elf = data_elf[1000:,:,:,:]
train_data_procar = data_procar[:1000,:,:]
test_data_procar = data_procar[1000:,:,:]
train_data_elf = train_data_elf.reshape(-1, 80,80,80, 1)
test_data_elf  = test_data_elf.reshape(-1,80,80,80,1)
train_data_procar = train_data_procar.reshape(-1,20,80,1)
test_data_procar  = test_data_procar.reshape(-1,20,80,1)
169/7:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) #80,80,80 x 16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40,40,40 x 16
    conv2 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool1) #40,40,40 x 32
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20,20,20 x 32
    conv3 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool2) #20,20,20x64 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10,10,10 x 64 
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10 x 128 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5,5,5,128
    conv5 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(pool3) #5,5,5*256 (small and thick) 
    #decoder 
    flat = Flatten()(conv5) # 32000x1
    reshape = Reshape((5,5,1280))(flat) #  
    conv5 = Conv2D(256, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
    up1   = UpSampling2D((2,2))(conv5) # 10x10x256
    conv6 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up1) # 10x10x128
    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
    conv7 = Conv2D(64, (3, 3), activation='linear', padding='same')(conv6) # 20x40x128
    up4 = UpSampling2D((1,2))(conv7) # 20x80x64
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(conv5) # 20x80x1 
    return decoded
169/8:
batch_size = 20
epochs = 75
inChannel = 1
x,y,z = 80,80,80
input_img = Input(shape = (x, y,z, inChannel))
169/9:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
169/10:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input = 81 x 81 x 81 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) #80,80,80 x 16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40,40,40 x 16
    conv2 = Conv3D(32, (3, 3,3), activation='relu', padding='same')(pool1) #40,40,40 x 32
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20,20,20 x 32
    conv3 = Conv3D(64, (3, 3,3), activation='relu', padding='same')(pool2) #20,20,20x64 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10,10,10 x 64 
    conv4 = Conv3D(128, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10 x 128 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5,5,5,128
    conv5 = Conv3D(256, (3, 3,3), activation='relu', padding='same')(pool3) #5,5,5*256 (small and thick) 
    #decoder 
    flat = Flatten()(conv5) # 32000x1
    reshape = Reshape((5,5,1280))(flat) #  
    conv5 = Conv2D(256, (3,3), activation='relu', padding='same')(reshape) # 5x5x2048 (small and thick) 
    up1   = UpSampling2D((2,2))(conv5) # 10x10x256
    conv6 = Conv2D(128, (3, 3), activation='sigmoid', padding='same')(up1) # 10x10x128
    up2 = UpSampling2D((2,4))(conv6) # 20x40x1024 
    conv7 = Conv2D(64, (3, 3), activation='linear', padding='same')(up2) # 20x40x128
    up4 = UpSampling2D((1,2))(conv7) # 20x80x64
    
    decoded = Conv2D(1, (3, 3), activation='linear', padding='same')(up4) # 20x80x1 
    return decoded
169/11:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
169/12: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
169/13:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
169/14: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_procar, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_procar))
169/15: import matplotlib.pyplot as plt
169/16: pred = autoencoder.predict(test_data_elf)
169/17: plt.imshow(test_data_elf[2].reshape(81,81,81)[20,:,:])
169/18: plt.imshow(test_data_elf[2].reshape(80,80,80)[20,:,:])
169/19:
for j in range(len(pred)):
    plt.figure()
    for iband in range(25,35):
    
        plt.scatter(np.linspace(0,1,20),test_data_procar[j][:,iband],s=3,c='r')
        plt.plot(np.linspace(0,1,20),test_data_procar[j][:,iband],c='r')
        plt.scatter(np.linspace(0,1,20),pred[j][:,iband],s=3,c='b')
        plt.plot(np.linspace(0,1,20),pred[j][:,iband],c='b')
    plt.xlim(0,1)
    plt.xlabel("$\Gamma$>X",fontsize=18)
    plt.ylabel("E-E$_F$(eV)",fontsize=18)
    plt.savefig('bands_{}_3rd'.format(j))
    plt.clf() 
   zx.
169/21: j= 0
169/22:
for iband in range(0,80):
    plt.scatter(np.linspace(0,1,20),test_data_procar[j][:,iband],s=3,c='r')
    plt.plot(np.linspace(0,1,20),test_data_procar[j][:,iband],c='r')
    plt.scatter(np.linspace(0,1,20),pred[j][:,iband],s=3,c='b')
    plt.plot(np.linspace(0,1,20),pred[j][:,iband],c='b')
169/23:
for iband in range(25,35):
    plt.scatter(np.linspace(0,1,20),test_data_procar[j][:,iband],s=3,c='r')
    plt.plot(np.linspace(0,1,20),test_data_procar[j][:,iband],c='r')
    plt.scatter(np.linspace(0,1,20),pred[j][:,iband],s=3,c='b')
    plt.plot(np.linspace(0,1,20),pred[j][:,iband],c='b')
171/1:
import h5py
from pychemia.utils.mathematics import rotation_matrix_around_axis_angle as rot
from scipy.ndimage import affine_transform
import keras
import numpy as np
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D
from keras.layers import Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
171/2: rf = h5py.File('data_dos_elf_1260_80x80x80.hdf5','r')
171/3: data_elf = rf['elfcar'][:,:,:]
171/4: data_elf.shape
171/5: data_dos = rf['dos'][:,:,:]
171/6: data_dos.shpae
171/7: data_dos.shape
171/8: data_labels = rf['labels'][:]
171/9: rf.cose()
171/10: rf.close()
171/11: data_dos
171/12: data_dos.shape
171/13: data_dos[:,:,0:2]
171/14: data_dos[:,:,0:2].shape
171/15: data_dos= data_dos[:,:,0:2]
171/16:
train_data_elf = data_elf[:1000,:,:,:]
test_data_elf = data_elf[1000:,:,:,:]
train_data_dos = data_dos[:1000,:,:]
test_data_dos = data_dos[1000:,:,:]
train_data_elf = train_data_elf.reshape(-1, 80,80,80, 1)
test_data_elf  = test_data_elf.reshape(-1,80,80,80,1)
train_data_dos = train_data_dos.reshape(-1,301,2,1)
test_data_dos  = test_data_dos.reshape(-1,301,2,1)
171/17:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #5x5x5x8

    #decoder 
    flat = Flatten()(conv4) # 1000x 1
    return decoded
171/18:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='sigmoid')(flat)
    d2 = Dense(602,activation='linear')(d1)
    decode = Reshape((301,2,1))(d2)
    return decoded
171/19: from keras.layers import Dense
171/20:

batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 80,80,80
input_img = Input(shape = (x, y,z, inChannel))
171/21:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/22:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='sigmoid')(flat)
    d2 = Dense(602,activation='linear')(d1)
    decoded = Reshape((301,2,1))(d2)
    return decoded
171/23:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/24:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                             train_data_procar,
                                                             test_size=0.2,
                                                             random_state=13)
171/25:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_dos,valid_ground_dos = train_test_split(train_data_elf,
                                                             train_data_dos,
                                                             test_size=0.2,
                                                             random_state=13)
171/26: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_dos, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_dos))
171/27:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='sigmoid')(flat)
    d2 = Dense(602,activation='sigmoid')(d1)
    d3 = Dense(602,activation='linear')(d2)
    decoded = Reshape((301,2,1))(d3)
    return decoded
171/28:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/29:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(602,activation='sigmoid')(d1)
    d3 = Dense(602,activation='sigmoid')(d2)
    d4 = Dense(602,activation='linear')(d3)
    decoded = Reshape((301,2,1))(d4)
    return decoded
171/30:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/31: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_dos, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_dos))
171/32:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(602,activation='sigmoid')(d1)
    d3 = Dense(602,activation='sigmoid')(d2)
    d4 = Dense(602,activation='relu')(d3)
    decoded = Reshape((301,2,1))(d4)
    return decoded
171/33:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/34: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_dos, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_dos))
171/35:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(602,activation='sigmoid')(d1)
    d3 = Dense(602,activation='sigmoid')(d2)
    d4 = Dense(602,activation='linear')(d3)
    decoded = Reshape((301,2,1))(d4)
    return decoded
171/36: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_dos, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_dos))
171/37:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/38: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_dos, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_dos))
171/39:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(500,activation='linear')(d3)
    d5 = Dense(602,activation='linear')(d4)
    decoded = Reshape((301,2,1))(d5)
    return decoded
171/40:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/41: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_dos, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_dos))
171/42:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d3 = Dense(400,activation='sigmoid')(d3)
    d3 = Dense(400,activation='sigmoid')(d3)
    d4 = Dense(500,activation='linear')(d3)
    d5 = Dense(602,activation='linear')(d4)
    decoded = Reshape((301,2,1))(d5)
    return decoded
171/43:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/44:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/45:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d3 = Dense(400,activation='sigmoid')(d3)
    d3 = Dense(400,activation='sigmoid')(d3)
    d4 = Dense(500,activation='linear')(d3)
    d5 = Dense(602,activation='linear')(d4)
    decoded = Reshape((301,2,1))(d5)
    return decoded
171/46:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/47: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_dos, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_dos))
171/48:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(301,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    out = concatenate([d6,d7])
    decoded = Reshape((301,2,1))(d8)
    return decoded
171/49:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/50:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(301,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    out = concatenate([d6,d7])
    decoded = Reshape((301,2,1))(d8)
    return decoded
171/51: from keras.layers import concatenate
171/52:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(301,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    out = concatenate([d6,d7])
    decoded = Reshape((301,2,1))(d8)
    return decoded
171/53:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/54:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(301,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    out = concatenate([d6,d7])
    decoded = Reshape((301,2,1))(out)
    return decoded
171/55:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/56: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_dos, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_dos))
171/57: a = np.random.random((20,2))
171/58: b = np.random.random((20,2))
171/59: a = np.random.random((20,))
171/60: b = np.random.random((20,))
171/61: a
171/62: b
171/63: np.concatenate([a,b])
171/64: np.concatenate([a,b],axis=1)
171/65: np.concatenate([a,b],axis=0)
171/66: np.concatenate([a,b],axis=-1)
171/67: np.concatenate([a,b],axis=2)
171/68: np.concatenate([a,b],axis=1)
171/69: a = np.random.random((20,1))
171/70: b = np.random.random((20,1))
171/71: np.concatenate([a,b],axis=2)
171/72: np.concatenate([a,b],axis=1)
171/73:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(301,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=1)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/74:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/75:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(301,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=0)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/76:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/77:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(301,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=1)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/78:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/79:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(301,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=0)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/80:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/81:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(301,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=2)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/82:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/83: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_dos, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_dos))
171/84:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(1,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=2)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/85: lambda x:np.arange(x,301)
171/86: add = lambda x:np.arange(x,301)
171/87: add(2)
171/88: add = lambda x:np.arange(x,y,301)
171/89: add(2,3)
171/90: add(2)
171/91: add = lambda x,y:np.arange(x,y,301)
171/92: add(2,3)
171/93: add = lambda x,y:np.linspace(x,y,301)
171/94: add(2,3)
171/95: add(2,3).shape()
171/96: add(2,3).shape
171/97: from keras.layers import Lambda
171/98:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(2,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    d6 = Lambda(add(d6[0],d6[1]))
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=2)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/99:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/100:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(2,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    d6 = Lambda(lambda x,y:np.linspace(x,y,301))(d6)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=2)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/101:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/102:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(2,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    d6 = Lambda(lambda x,y:np.linspace(x,y,301))(d6[0],d6[1])
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=2)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/103: from keras.layers import Lambda
171/104:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/105: dos
171/106: data_dos
171/107: data_dos[0]
171/108: data_dos.shape
171/109: data_dos[0][:,0]
171/110: np.diff(data_dos[0][:,0])
171/111: np.diff(data_dos[1][:,0])
171/112: np.diff(data_dos[2][:,0])
171/113: for i in 100 :np.diff(data_dos[2][:,0])
171/114: for i in 100 : np.diff(data_dos[2][:,0])
171/115: for i in 100 : np.diff(data_dos[i][:,0])
171/116: for i in rang(100) : np.diff(data_dos[i][:,0])
171/117: for i in range(100) : np.diff(data_dos[i][:,0])
171/118: for i in range(100) :  np.diff(data_dos[i][:,0])
171/119:
for i in range(100) : 
    print(np.diff(data_dos[i][:,0]))
171/120:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(2,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    d6 = Lambda(lambda x:np.linspace(x[0],x[1],301))(d6)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=2)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/121:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/122:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(2,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    d6 = (d6)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=2)
    decoded = Reshape((301,2,1))(out)
    return decoded 
    
    
    
    
    
    .
    
    dsf
    .sdv
171/123: import tensorflow as tf
171/124: tf.linspace(20,100,20)
171/125:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(2,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    d6 = tf.linspace(d6[0],d6[1],301)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=2)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/126:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/127:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(2,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    d6 = tf.linspace(d6[0],d6[1],301)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=2)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/128: tf.linspace(10,12,2)
171/129: tf.linspace(10.0,12.0,2)
171/130:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(1,activation='linear')(d5)
    d6_end = Dense(1,activation='linear')(d5)
    d7 = Dense(301,activation='relu')(d5)
    d6 = tf.linspace(d6,d6_end,301)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=2)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/131:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/132:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(2,activation='linear')(d5)
#    d6_end = Dense(1,activation='linear')(d5)
    d6 = Reshape((2,))(d6)
    d7 = Dense(301,activation='relu')(d5)
    d6 = tf.linspace(d6[0],d6[0],301)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=2)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/133:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/134:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(2,activation='linear')(d5)
#    d6_end = Dense(1,activation='linear')(d5)
    d6 = Reshape((2,))(d6)
    d7 = Dense(301,activation='relu')(d5)
    d6 = tf.linspace(d6[0][0],d6[1][0],301)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=2)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/135:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/136:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(2,activation='linear')(d5)
#    d6_end = Dense(1,activation='linear')(d5)
    d6 = Reshape((2,))(d6)
    d7 = Dense(301,activation='relu')(d5)
    d6 = tf.linspace(d6[0][0],d6[0][1],301)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=2)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/137:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
171/138:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(2,activation='linear')(d5)
#    d6_end = Dense(1,activation='linear')(d5)
    d6 = Reshape((2,))(d6)
    d7 = Dense(301,activation='relu')(d5)
    d6 = tf.linspace(d6[0][0],d6[0][1],301)
    d6 = Reshape((301,1))(d6)
    d7 = Reshape((301,1))(d7)
    out = concatenate([d6,d7],axis=2)
    decoded = Reshape((301,2,1))(out)
    return decoded
171/139: data_dos
171/140: data_dos[0]
171/141: data_dos[0][:,0]
171/142: data_dos[0][:,0] > -10
171/143: data_dos[0][:,0] < 10
171/144: c2 = data_dos[0][:,0] < 10
171/145: c1 = data_dos[0][:,0] > -10
171/146: np.bitwise_and(c1,c2)
171/147: data_dos[0][np.bitwise_and(c1,c2)]
171/148: plt.plot(data_dos[0][np.bitwise_and(c1,c2)])
171/149: import matplotlib.pylab as plt
171/150: plt.plot(data_dos[0][np.bitwise_and(c1,c2)])
171/151: plt.plot(data_dos[0][np.bitwise_and(c1,c2)][:,0],data_dos[0][np.bitwise_and(c1,c2)][:,1])
171/152: import scipy.interpolate as interpolate
171/153: test = data_dos[0]
171/154: interpolate.interp1d?
171/155: interpolate.CubicSpline?
171/156: f = interpolate.CubicSpline(test[:,0],test[:,1])
171/157: f
171/158: f?
171/159: f?
171/160: plt.plot(test[:,0],test[:,1])
171/161: x = np.linspace(-10,10,100)
171/162: x
171/163: plt.plot(x,f(x))
171/164: f = interpolate.interp2d?
171/165: f = interpolate.interp1d?
171/166: f = interpolate.interp1d(test[:,0],test[:,1],kind='linear')
171/167: plt.plot(test[:,0],test[:,1])
171/168: plt.plot(x,f(x))
171/169: x = np.linspace(-10,10,200)
171/170: plt.plot(test[:,0],test[:,1])
171/171: plt.plot(x,f(x))
171/172: data_dos.shape
171/173:
data_dos_window = np.zeros((len(data_dos),100))
x = np.linspace(-10,10,100)
for idata in range(len(data_dos)):
    f = interpolate.interp1d(data_dos[idata,:,0],data_dos[idata,:,1])
    data_dos_window[idata] = f(x)
171/174: idata
171/175: data_dos[186]
171/176:
data_dos_window = np.zeros((len(data_dos),100))
x = np.linspace(-10,5,100)
for idata in range(len(data_dos)):
    f = interpolate.interp1d(data_dos[idata,:,0],data_dos[idata,:,1])
    data_dos_window[idata] = f(x)
171/177: idata
171/178: data_dos[222]
171/179:
data_dos_window = np.zeros((len(data_dos),100))
x = np.linspace(-5,5,100)
for idata in range(len(data_dos)):
    f = interpolate.interp1d(data_dos[idata,:,0],data_dos[idata,:,1])
    data_dos_window[idata] = f(x)
171/180: idata
171/181: data_dos[339]
171/182:
data_dos_window = np.zeros((len(data_dos),100))
x = np.linspace(-3,3,100)
for idata in range(len(data_dos)):
    f = interpolate.interp1d(data_dos[idata,:,0],data_dos[idata,:,1])
    data_dos_window[idata] = f(x)
171/183: plt.plot(data_dos_window[0])
171/184: plt.plot(data_dos_window[1])
171/185: plt.plot(data_dos_window[2])
171/186: plt.plot(data_dos_window[3])
171/187: plt.plot(data_dos_window[5])
171/188: plt.plot(data_dos_window[10])
171/189: plt.plot(z,data_dos_window[10])
171/190: plt.plot(x,data_dos_window[10])
171/191:
data_dos_window = np.zeros((len(data_dos),100))
x = np.linspace(-3,3,100)
for idata in range(len(data_dos)):
    f = interpolate.interp1d(data_dos[idata,:,0],data_dos[idata,:,1])
    data_dos_window[idata] = f(x)
171/192: plt.plot(x,data_dos_window[200])
172/1:
import h5py 
from pychemia.utils.mathematics import rotation_matrix_around_axis_angle as rot 
from scipy.ndimage import affine_transform 
from scipy import interpolate
import keras 
import numpy as np 
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D 
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D 
from keras.layers import Flatten,Reshape,Dense
from keras.models import Model 
from keras.optimizers import RMSprop
172/2:
rf = h5py.File('data_dos_elf_1260_80x80x80.hdf5','r')
data_labels = rf['labels'][:]
data_dos = rf['dos'][:,:,:] 
data_dos = data_dos[:,:,0:2]
data_elf = rf['elfcar'][:,:,:,:]

data_dos_window = np.zeros((len(data_dos),100))
x = np.linspace(-3,3,100)
for idata in range(len(data_dos)):
    f = interpolate.interp1d(data_dos[idata,:,0],data_dos[idata,:,1])
    data_dos_window[idata] = f(x)
data_dos = data_dos_window
172/3:
train_data_elf = data_elf[:1000,:,:,:]
test_data_elf = data_elf[1000:,:,:,:]
train_data_dos = data_dos[:1000,:,:]
test_data_dos = data_dos[1000:,:,:]
train_data_elf = train_data_elf.reshape(-1, 80,80,80, 1)
test_data_elf  = test_data_elf.reshape(-1,80,80,80,1)
train_data_dos = train_data_dos.reshape(-1,100,2,1)
test_data_dos  = test_data_dos.reshape(-1,100,2,1)
172/4:
train_data_elf = data_elf[:1000,:,:,:]
test_data_elf = data_elf[1000:,:,:,:]
train_data_dos = data_dos[:1000,:]
test_data_dos = data_dos[1000:,:]
train_data_elf = train_data_elf.reshape(-1, 80,80,80, 1)
test_data_elf  = test_data_elf.reshape(-1,80,80,80,1)
train_data_dos = train_data_dos.reshape(-1,100,2,1)
test_data_dos  = test_data_dos.reshape(-1,100,2,1)
172/5:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(100,activation='relu')(d5)
    return d6
172/6:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 80,80,80
input_img = Input(shape = (x, y,z, inChannel))
172/7:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
172/8:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_dos,valid_ground_dos = train_test_split(train_data_elf, 
                                                              train_data_dos, 
                                                              test_size=0.2, 
                                                              random_state=13)
172/9:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(100,activation='relu')(d5)
    return d6
172/10:
train_data_elf = data_elf[:1000,:,:,:]
test_data_elf = data_elf[1000:,:,:,:]
train_data_dos = data_dos[:1000,:]
test_data_dos = data_dos[1000:,:]
train_data_elf = train_data_elf.reshape(-1, 80,80,80, 1)
test_data_elf  = test_data_elf.reshape(-1,80,80,80,1)
train_data_dos = train_data_dos.reshape(-1,100,1)
test_data_dos  = test_data_dos.reshape(-1,100,1)
172/11:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(100,activation='relu')(d5)
    return d6
172/12:

batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 80,80,80
input_img = Input(shape = (x, y,z, inChannel))
172/13:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
172/14:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_dos,valid_ground_dos = train_test_split(train_data_elf, 
                                                              train_data_dos, 
                                                              test_size=0.2, 
                                                              random_state=13)
172/15: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_dos, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_dos))
172/16:
train_data_elf = data_elf[:1000,:,:,:]
test_data_elf = data_elf[1000:,:,:,:]
train_data_dos = data_dos[:1000,:]
test_data_dos = data_dos[1000:,:]
train_data_elf = train_data_elf.reshape(-1, 80,80,80, 1)
test_data_elf  = test_data_elf.reshape(-1,80,80,80,1)
train_data_dos = train_data_dos.reshape(-1,100)
test_data_dos  = test_data_dos.reshape(-1,100)
172/17: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_dos, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_dos))
172/18: test_data_dos.shape
172/19:
train_data_elf = data_elf[:1000,:,:,:]
test_data_elf = data_elf[1000:,:,:,:]
train_data_dos = data_dos[:1000,:]
test_data_dos = data_dos[1000:,:]
train_data_elf = train_data_elf.reshape(-1, 80,80,80, 1)
test_data_elf  = test_data_elf.reshape(-1,80,80,80,1)
train_data_dos = train_data_dos.reshape(-1,100,1)
test_data_dos  = test_data_dos.reshape(-1,100,1)
172/20:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8

    #decoder 
    flat = Flatten()(pool4) # 1000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(100,activation='relu')(d5)
    decoded = Reshape((100,1))(d6)
    return decoded
172/21:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
172/22: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_dos, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_dos))
173/1:
import h5py 
from pychemia.utils.mathematics import rotation_matrix_around_axis_angle as rot 
from scipy.ndimage import affine_transform 
from scipy import interpolate
import keras 
import numpy as np 
from keras.layers import Input,Conv3D,MaxPooling3D,UpSampling3D 
from keras.layers import Conv2D,MaxPooling2D,UpSampling2D 
from keras.layers import Flatten,Reshape,Dense
from keras.models import Model 
from keras.optimizers import RMSprop
173/2:
rf = h5py.File('data_dos_elf_1260_80x80x80.hdf5','r')
data_labels = rf['labels'][:]
data_dos = rf['dos'][:,:,:] 
data_dos = data_dos[:,:,0:2]
data_elf = rf['elfcar'][:,:,:,:]
173/3:
data_dos_window = np.zeros((len(data_dos),100))
x = np.linspace(-10,10,100)
for idata in range(len(data_dos)):
    f = interpolate.interp1d(data_dos[idata,:,0],data_dos[idata,:,1],fill_value=0.0,bounds_error=False)
    data_dos_window[idata] = f(x)
data_dos = data_dos_window
173/4:
train_data_elf = data_elf[:1000,:,:,:]
test_data_elf = data_elf[1000:,:,:,:]
train_data_dos = data_dos[:1000,:]
test_data_dos = data_dos[1000:,:]
train_data_elf = train_data_elf.reshape(-1, 80,80,80, 1)
test_data_elf  = test_data_elf.reshape(-1,80,80,80,1)
train_data_dos = train_data_dos.reshape(-1,100,1)
test_data_dos  = test_data_dos.reshape(-1,100,1)
173/5:
def autoencoder(input_img): # 3rdTry 
    #encoder 
    #input =80x80x80 1 (wide and thin) 
    conv1 = Conv3D(16, (3, 3,3), activation='relu', padding='same')(input_img) # 80x80x80x16
    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1) # 40x40x40 x 8 
    conv2 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool1) #40x40x40x 8
    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2) #20x20x20x8
    conv3 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool2) #20x20x20x8 (small and thick) 
    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3) #10x10x10x8
    conv4 = Conv3D(8, (3, 3,3), activation='relu', padding='same')(pool3) #10x10x10x8 (small and thick) 
#    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4) #5x5x5x8
    pool4 = conv4
    #decoder 
    flat = Flatten()(pool4) # 8000x 1
    d1 = Dense(800,activation='relu')(flat)
    d2 = Dense(400,activation='sigmoid')(d1)
    d3 = Dense(400,activation='sigmoid')(d2)
    d4 = Dense(400,activation='sigmoid')(d3)
    d5 = Dense(400,activation='sigmoid')(d4)
    d6 = Dense(100,activation='relu')(d5)
    decoded = Reshape((100,1))(d6)
    return decoded
173/6:
batch_size = 20
epochs = 50
inChannel = 1
x,y,z = 80,80,80
input_img = Input(shape = (x, y,z, inChannel))
173/7:
autoencoder = Model(input_img, autoencoder(input_img))
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
173/8:
from sklearn.model_selection import train_test_split
train_X_elf,valid_X_elf,train_ground_dos,valid_ground_dos = train_test_split(train_data_elf, 
                                                              train_data_dos, 
                                                              test_size=0.2, 
                                                              random_state=13)
173/9: autoencoder_train = autoencoder.fit(train_X_elf, train_ground_dos, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_elf, valid_ground_dos))
173/10: pred = autoencoder.predict(test_data_elf)
173/11: pred[0]
173/12: test_data_dos[0]
173/13: plt.plot(x,pred[0],label='ML')
173/14: import matplotlib.pylab as plt
173/15: plt.plot(x,pred[0],label='ML')
173/16: pred[0].shape
173/17: plt.plot(x,pred[0][:,0],label='ML')
173/18: pre[0][:,0]
173/19: pred[0][:,0]
173/20: pred[0][:,1]
173/21: pred[0]
173/22: pred[0][1]
173/23: pred[0][:]
173/24: pred[0][:,0].shape
173/25: x.shape
173/26: x
173/27: x = np.linspace(-10,10,200)
173/28: x = np.linspace(-10,10,100)
173/29: test_data_dos[0].shape
173/30: plt.plot(x,pred[0],label='ML')
173/31: plt.plot(x,test_data_dos[0],label='DFT')
173/32: plt.plot(x,test_data_dos[1],label='DFT')
173/33: plt.plot(x,pred[1],label='ML')
173/34: plt.plot(x,test_data_dos[100],label='DFT')
173/35: plt.plot(x,pred[100],label='ML')
173/36: plt.plot(x,pred[200],label='ML')
173/37: plt.plot(x,test_data_dos[200],label='DFT')
173/38: plt.legend()
173/39: plt.plot(x,pred[0],label='ML')
173/40: plt.plot(x,test_data_dos[0],label='DFT')
173/41: plt.legend()
174/1: import cv2
175/1: import cv2
176/1: import matplotlib.pylab as plt
176/2: import matplotlib.image as mpimg
176/3: img = mpimg.imread('MQSC_264.tif')
176/4: img
176/5: plt.imshow(img)
176/6: img.shape
176/7: img[:,6288:]
176/8: img[:,(6288/2):]
176/9: img[:,(6288//2):]
176/10: plt.imshow(img[:,(6288//2):])
176/11: plt.imshow(img[:,:(6288//2)])
176/12: import PIL
176/13: from PIL import Image
176/14: img1 = Image.open('MQSC_264.tif')
176/15: img1
176/16: img1.height
176/17: img1.show()
176/18: img1.resize?
176/19: img2 = img1.resize(200,200)
176/20: img2 = img1.resize((200,200))
176/21: img2.show()
176/22: img2 = img1.resize((1000,1000))
176/23: img2.show()
176/24: img1.crop?
176/25: img1.size
176/26: left = 0
176/27: right = 6288//2
176/28: upper = 0
176/29: lower = 2471
176/30: img3 = img1.crop((left,upper,right,lower))
176/31: img3.show()
176/32: img3.size
176/33: img4 = img3.resize((2000,2000))
176/34: img4.show()
176/35: img1.shape
176/36: img1.size
176/37: w,h=img1.size
176/38: w
176/39: img1.split?
176/40: img1.getdata()
176/41: img1.getdata?
176/42: a = img1.getdata
176/43: a
176/44: a()
176/45: a = img1.getdata()
176/46: a.getpixel()
176/47: img.rotate?
176/48: img1.rotate(45).show()
176/49: img1.rotate?
177/1: import cv2
176/50: img1.rotate(20)
176/51: img1.rotate(20).show()
176/52: img1.save?
178/1: import pandas
178/2: import pandas as pd
178/3: df = pd.read_excel('Automated_Algorithm_Scans.xlsx')
178/4: df
178/5: df = pd.read_excel('Automated_Algorithm_Scans.xlsx',sheet_name='')
178/6: df = pd.read_excel('Automated_Algorithm_Scans.xlsx',sheet_name='MQHT')
178/7: df
178/8: df = pd.read_excel('Automated_Algorithm_Scans.xlsx',sheet_name='MQSC')
178/9: df
178/10: from keras.layers import Conv2D,MaxPool2D,Dense
178/11:
def conv_deep_net(input_img): # 2000x2000 >>>> 1
    #Convolution
    #input = 2000x2000   1 (wide and thin)
    conv1 = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img) #2000x2000 x 16
    pool1 = MaxPool2D(pool_size=(2,2))(conv1) # 1000x1000x16
    conv2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1) #1000x1000x 8
    pool2 = MaxPool3D(pool_size=(2,2))(conv2) # 500x500x 8
    conv3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool2) # 500x500x8 (small and thick)
    pool3 = MaxPool2D(pool_size=(2,2))(conv3) #250x250x8
    conv4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool3) # 250x250x8 (small and thick)
    pool4 = MaxPool2D(pool_size=(2,2))(conv4) # 125x125x1
    
    # Deep Learning
    flat = Flatten()(pool4) # 15625 x 1
    d1 = Dense(800,activation='relu')(flat) # 800 x1
    d2 = Dense(400,activation='relu')(d1)   # 400 x1
    d3 = Dense(200,activation='relu')(d2)   # 200 x1
    d4 = Dense(200,activation='relu')(d3)   # 200 x1
    d5 = Dense(1,activation='sigmoid')(d4)  # final node
    return d5
178/12: conv_deep_net?
178/13: conv_deep_net??
178/14: conv_deep_net??
179/1: from PIL import Image
179/2: img = Image.open('MQSC_264.tif')
179/3:
        w,h = img.size
        m = w//2
        img_left = img.resize(size=(2000,2000),box=(0,0,m,h))
        img_right = img.resize(size=(2000,2000),box=(m,0,w,h))
179/4: img_right
179/5: img_right.histogram()
179/6: img_right.getpixel()
179/7: img_right.getpixel?
179/8: img_right.getdata?
179/9: img_right.getdata()
179/10: data = img_right.getdata()
179/11: data
179/12: list(data)
179/13: np.array(list(data)).reshape(2000,20000)
179/14: import numpy as np
179/15: np.array(list(data)).reshape(2000,20000)
179/16: np.array(list(data)).reshape(2000,2000)
179/17: test = np.array(list(data)).reshape(2000,2000)
179/18: import mastplotlib.pylab as plt
179/19: import matplotlib.pylab as plt
179/20: plt.pl
179/21: plt.imshow(test)
179/22: ls
179/23: plt.imshow(np.array(list(img.getdata())).reshape(2000,2000))
179/24: plt.imshow(np.array(list(img_left.getdata())).reshape(2000,2000))
180/1: import h5py
180/2: import matplotlib.pylab as plt
180/3: rf = h5py.File('test.hdf5','r')
180/4: data = rf['data'][:]
180/5: data
180/6: data.shape
180/7: data[0].shape
180/8: plt.imshow(data[0])
180/9: plt.imshow(data[1])
180/10: plt.imshow(data[2])
180/11: plt.imshow(data[3])
181/1: import h5py
181/2: rf = h5py.File('scaned_data.hdf5')
181/3: data = rf['data'][:]
181/4: data = rf['data']
181/5: data
181/6: a = data[:,:,:]
181/7: data.value
181/8: data.value()
181/9: data.size
181/10: data[:,0]
182/1: import h5py
182/2: rf = h5py.File('scaned_data.hdf5')
182/3: rf.close()
182/4: rf = h5py.File('scaned_data_2000x2000.hdf5')
182/5: data = rf['data']
182/6: data[:,:,0]
182/7: import matplotlib.pylab as plt
182/8: plt.imshow(data[:,:,0])
182/9: plt.imshow(data[0,:,:])
182/10: plt.imshow(data[1,:,:])
182/11: data[1,:,:].shape
182/12: plt.imshow(data[1,:,:])
182/13: plt.imshow(data[12,:,:])
182/14: rf.close()
182/15: rf = h5py.File('test.hdf5')
182/16: data = rf['data']
182/17: data.shape
182/18: plt.imshow(data[1,:,:])
182/19: plt.imshow(data[1,:,:],cmap='gray')
182/20: rf.close()
182/21: rf = h5py.File('500x500.hdf5')
182/22: plt.imshow(data[1,:,:],cmap='gray')
182/23: data = rf['data']
182/24: plt.imshow(data[1,:,:],cmap='gray')
182/25: plt.imshow(data[1,:,:],cmap='gray')
182/26: rf.close()
182/27: rf = h5py.File('1000x1000.hdf5')
182/28: data = rf['data']
182/29: plt.imshow(data[1,:,:],cmap='gray')
182/30: rf.close()
182/31: rf = h5py.File('1000x1000.hdf5')
182/32: data = rf['data']
182/33: plt.imshow(data[1,:,:],cmap='gray')
183/1: import PIL
183/2: from PIL import Image
183/3: img = Image.open('LQ_401.tif')
183/4: img_box = img.getbbox()
183/5: img_box
183/6: img.size
184/1: import PIL
184/2: import matplotlib.pylab as plt
184/3: from PIL import Image
184/4: rf = h5py.File('500x500.hdf5')
184/5: import h5py
184/6: rf = h5py.File('500x500.hdf5')
184/7: data = rf['data']
184/8: plt.imshow(data[1,:,:],cmap='gray')
184/9: plt.imshow(data[1,:,:],cmap='gray')
184/10: data[1,:,:]
184/11: data[1,:,:].max()
184/12: data[1,:,:].min()
184/13: data[1,:,:]/255
184/14: plt.imshow(data[1,:,:]/255,cmap='gray')
184/15: plt.hist(data[1,:,:]/255)
184/16: plt.hist(list(data[1,:,:]/255))
184/17: list(data[1,:,:])
184/18: import numpy as np
184/19: a = data[1,:,:]
184/20: a.flatten()
184/21: plt.hist(a.flatten())
184/22: a< 25
184/23: a[a< 25] = 0
184/24: plt.hist(a.flatten())
184/25: plt.imshow(a,cmap='gray')
184/26: a[a<50] = 0
184/27: plt.imshow(a,cmap='gray')
184/28: a[a<100] = 0
184/29: plt.imshow(a,cmap='gray')
184/30: a[a<200] = 0
184/31: plt.imshow(a,cmap='gray')
184/32: a = data[1,:,:]
184/33: plt.imshow(a,cmap='gray')
184/34: plt.imshow(a,cmap='gray')
184/35: plt.imshow(a,cmap='gray')
184/36: import skimage.feature
184/37: edges = skimage.feature.canny(a)
184/38: import skimage.viewer
184/39: vi = skimage.viewer.ImageViewer(a)
184/40: vi.show()
184/41: vi = skimage.viewer.ImageViewer(edges)
184/42: vi.show()
184/43: vi
184/44: vi.x
184/45: vi.style
184/46:
for i in vi :
    print(i)
184/47: vi.canvas
184/48: vi.cursor()
184/49: vi.cursor
184/50:
for i in vi.cursor:
    print(i)
184/51: vi.y
184/52: edges.all()
184/53: edges
184/54: edges = skimage.feature.canny(a,low_threshold=0.5)
184/55: vi = skimage.viewer.ImageViewer(edges)
184/56: vi.show()
184/57: edges = skimage.feature.canny(a,sigma=1)
184/58: vi = skimage.viewer.ImageViewer(edges)
184/59: vi.show()
184/60: edges = skimage.feature.canny(a,sigma=3)
184/61: vi = skimage.viewer.ImageViewer(edges)
184/62: vi.show()
184/63: edges = skimage.feature.canny(a,sigma=10)
184/64: vi.show()
184/65: vi = skimage.viewer.ImageViewer(edges)
184/66: vi.show()
184/67: edges.sum()
184/68: edges.sum(axis=2)
184/69: edges.sum(axis=1)
184/70: np.argmax(edges.sum(axis=1))
184/71: edges[477]
184/72: vi = skimage.viewer.ImageViewer(edges[477])
184/73: vi.show()
184/74: vi = skimage.viewer.ImageViewer(edges[477])
184/75: np.argmax(edges.sum(axis=0))
184/76: edges.sum(axis=0)
184/77: vi = skimage.viewer.ImageViewer(edges[1])
184/78: vi = skimage.viewer.ImageViewer(edges[:,1])
184/79: edges[1].shape
184/80: edges.shape
184/81: plt.imshow(edges)
184/82: edges = skimage.feature.canny(a,sigma=20)
184/83: plt.imshow(edges)
184/84: edges = skimage.feature.canny(a,sigma=10,low_threshold=0.5)
184/85: plt.imshow(edges)
184/86: edges = skimage.feature.canny(a,sigma=10,low_threshold=0.1)
184/87: plt.imshow(edges)
184/88: edges = skimage.feature.canny(a,sigma=10,high_threshold=0.5)
184/89: plt.imshow(edges)
184/90: edges = skimage.feature.canny(a,sigma=10,high_threshold=1)
184/91: plt.imshow(edges)
184/92: plt.imshow(edges)
184/93: skimage.feature.canny?
184/94: skimage.feature.canny?
184/95: skimage.feature.canny?
184/96: edges = skimage.feature.canny(a,sigma=10,high_threshold=1,low_threshold=0)
184/97: plt.imshow(edges)
185/1: from PIL import image
185/2: from PIL import Image
185/3: import h5py
185/4: rf = h5py.File('1000x1000.hdf5')
185/5: data = rf['data']
185/6: data[1,:,:]
185/7: plt.imshow(data[1,:,:])
185/8: import matplotlib.pylab as plt
185/9: import numpy as np
185/10: plt.imshow(data[1,:,:])
185/11: np.gradient(data[1,:,:])
185/12: np.gradient(data[1,:,:])[0]
185/13: plt.imshow(np.gradient(data[1,:,:])[0])
185/14: plt.imshow(np.gradient(data[1,:,:])[1])
185/15: plt.imshow(np.gradient(data[1,:,:])[1],cmap='gray')
185/16: plt.imshow(np.gradient(data[1,:,:])[0],cmap='gray')
185/17: plt.imshow(np.gradient(data[1,:,:])[1],cmap='gray')
185/18: plt.imshow(np.gradient(data[1,:,:])[1],cmap='gray')
185/19: np.gradient(data[1,:,:])[1].sum()
185/20: np.gradient(data[1,:,:])[1].sum(axis=0)
185/21: plt.plot(np.gradient(data[1,:,:])[1].sum(axis=0))
185/22: plt.plot(np.gradient(data[1,:,:])[1].sum(axis=1))
185/23: plt.plot(np.gradient(data[1,:,:])[1].sum(axis=0))
185/24: plt.plot(np.gradient(data[1,:,:])[1].sum(axis=0))
185/25: plt.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
185/26: plt.imshow(data[10,:,:],cmap='gray')
185/27: plt.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
185/28: plt.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
185/29: plt.imshow(data[10,:,:],cmap='gray')
185/30: plt.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
185/31: plt.subplot(2,1)
185/32:
fig,ax=plt.subplots(2,1)
ax[0].imshow(data[10,:,:],cmap='gray')
ax[1].plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.show()
185/33:
fig,ax=plt.subplots(2,1,sharex=True)
ax[0].imshow(data[10,:,:],cmap='gray')
ax[1].plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.show()
185/34:
fig,ax=plt.subplots(2,1,sharex=True)
ax[0].imshow(data[10,:,:],cmap='gray')
ax[1].plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.show()
185/35:
fig,ax=plt.subplots(2,1,sharex=True)
ax[0].imshow(data[10,:,:],cmap='gray',aspect='equal')
ax[1].plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.show()
185/36:
fig,ax=plt.subplots(2,1,sharex=True,length_ratio=[3,1])
ax[0].imshow(data[10,:,:],cmap='gray')
ax[1].plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.show()
185/37:
fig,ax=plt.subplots(2,1,sharex=True,length_ratio=[3,1])
ax[0].imshow(data[10,:,:],cmap='gray')
ax[1].plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.show()
185/38: from matplotlib import gridspec
185/39:
fig,ax=plt.subplots(2,1,sharex=True)
#gs = gridspec.GridSpec(1, 2, length_ratios=[3, 1]) 
#ax[0]
ax[0].imshow(data[10,:,:],cmap='gray')
ax[1].plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/40:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2, 1, length_ratios=[3, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/41:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/42:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2, 1, height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/43:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2, 1, width_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/44:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(1, 2, width_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/45:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, width_ratios=[10, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/46:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[10, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/47:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[20, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/48:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, ,width_rations=[1],height_ratios=[20, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/49:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, width_rations=[1],height_ratios=[20, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/50:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, width_ratios=[1],height_ratios=[20, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/51:
fig = plt.figure(figsize=(13,9),constained_layout=True)
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, width_ratios=[1],height_ratios=[20, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/52:
fig = plt.figure(figsize=(13,9),constrained_layout=False)
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, width_ratios=[1],height_ratios=[20, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/53:
fig = plt.figure(figsize=(13,9),constrained_layout=True)
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, width_ratios=[1],height_ratios=[20, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/54:
fig = plt.figure(figsize=(13,9),constrained_layout=True)
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, width_ratios=[1],height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
plt.tight_layout()
plt.show()
185/55:
fig = plt.figure(figsize=(13,9),constrained_layout=True)
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, width_ratios=[1],height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
#plt.tight_layout()
plt.show()
185/56:
fig = plt.figure(figsize=(13,9),constrained_layout=True)
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, width_ratios=[1],height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1],figsize=(10,2))
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
#plt.tight_layout()
plt.show()
185/57:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, width_ratios=[1],height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1],figsize=(10,2))
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
#plt.tight_layout()
plt.show()
185/58: ax1.set_adjustable?
185/59:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, width_ratios=[1],height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1],figsize=(10,2))
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_adjustable(share=True)
#plt.tight_layout()
plt.show()
185/60:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, width_ratios=[1],height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_adjustable(share=True)
#plt.tight_layout()
plt.show()
185/61:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, width_ratios=[1],height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_adjustable('box',share=True)
#plt.tight_layout()
plt.show()
185/62: ax1.set_adjustable?
185/63:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, width_ratios=[1],height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_adjustable('box',share=True)
#plt.tight_layout()
plt.show()
185/64:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
#ax1.set_adjustable('box',share=True)
ax1.set_figwigth(1)
#plt.tight_layout()
plt.show()
185/65:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
#ax1.set_adjustable('box',share=True)
ax1.set_figwidth(1)
#plt.tight_layout()
plt.show()
185/66:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
#ax1.set_adjustable('box',share=True)
ax1.set_figwidth(1)
#plt.tight_layout()
plt.show()
185/67:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
#ax1.set_adjustable('box',share=True)
#ax1.set_figwidth(1)
#plt.tight_layout()
plt.show()
185/68: ax1.set_aspect?
185/69:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect('equal')
#ax1.set_figwidth(1)
#plt.tight_layout()
plt.show()
185/70:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect('equal',share=True)
#ax1.set_figwidth(1)
#plt.tight_layout()
plt.show()
185/71:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(num=1,share=True)
#ax1.set_figwidth(1)
#plt.tight_layout()
plt.show()
185/72:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(1,share=True)
#ax1.set_figwidth(1)
#plt.tight_layout()
plt.show()
185/73:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(2,share=True)
#ax1.set_figwidth(1)
#plt.tight_layout()
plt.show()
185/74:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.5,share=True)
#ax1.set_figwidth(1)
#plt.tight_layout()
plt.show()
185/75:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.25,share=True)
#ax1.set_figwidth(1)
#plt.tight_layout()
plt.show()
185/76:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[5, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.025,share=True)
#ax1.set_figwidth(1)
#plt.tight_layout()
plt.show()
185/77:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.025,share=True)
#ax1.set_figwidth(1)
#plt.tight_layout()
plt.show()
185/78:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(1,share=True)
#ax1.set_figwidth(1)
#plt.tight_layout()
plt.show()
185/79:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.25,share=True)
#ax1.set_figwidth(1)
#plt.tight_layout()
plt.show()
185/80:
fig = plt.figure(figsize=(13,9))
#fig,ax=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.1,share=True)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/81:
fig = plt.figure(figsize=(13,9))
fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
#gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
#ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
#ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.1,share=True)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/82:
#fig = plt.figure(figsize=(13,9))
fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
#gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
#ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
#ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.5,share=True)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/83:
#fig = plt.figure(figsize=(13,9))
fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
#gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
#ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
#ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(1,share=True)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/84:
#fig = plt.figure(figsize=(13,9))
fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
#gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
#ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
#ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.5,share=True)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/85:
#fig = plt.figure(figsize=(13,9))
fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
#gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
#ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
#ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.15,share=True)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/86:
fig = plt.figure(figsize=(13,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.15,share=True)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/87:
fig = plt.figure(figsize=(13,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.09,share=True)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/88:
fig = plt.figure(figsize=(13,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.08)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/89:
fig = plt.figure(figsize=(13,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.08,share=True)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/90:
#fig = plt.figure(figsize=(13,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.08,share=True)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/91:
#fig = plt.figure(figsize=(13,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.08,share=True)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/92:
fig = plt.figure(figsize=(13,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.085,share=True)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/93:
fig = plt.figure(figsize=(9,13))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.085,share=True)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/94:
fig = plt.figure(figsize=(9,14))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.085,share=True)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/95:
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.085,share=True)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/96:
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.085,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/97:
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.1,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/98:
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.9,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/99:
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.09,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/100:
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.75,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/101:
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.075,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/102:
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.08,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/103:
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[10,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[10,:,:])[1].sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/104:
i=10
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[i,:,:])[1].sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/105:
i=11
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[i,:,:])[1].sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/106:
i=12
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[i,:,:])[1].sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/107:
i=13
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[i,:,:])[1].sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/108:
i=14
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[i,:,:])[1].sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/109:
i=15
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[i,:,:])[1].sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/110:
i=16
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[i,:,:])[1].sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/111:
i=17
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[i,:,:])[1].sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/112:
i=17
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(np.gradient(data[i,:,:])[1].abs().sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/113: a
185/114: data[i,:,:]
185/115: np.gradient(data[i,:,:])[1]
185/116: a=np.gradient(data[i,:,:])[1]
185/117: a
185/118: a.shape
185/119: abs(a)
185/120:
i=17
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:])[1]).abs().sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/121:
i=17
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:])[1]).sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/122:
i=18
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:])[1]).sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/123:
i=10
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:])[1]).sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/124:
i=15
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:])[1]).sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/125:
i=100
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:])[1]).sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/126:
i=99
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:])[1]).sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/127:
i=80
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:])[1]).sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/128: np.gradient(abs(np.gradient(data[i,:,:])[1]).sum(axis=0))
185/129: plt.plot(np.gradient(abs(np.gradient(data[i,:,:])[1]).sum(axis=0)))
185/130:
i=75
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:])[1]).sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/131:
i=74
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:])[1]).sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/132:
i=73
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:])[1]).sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/133:
i=72
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:])[1]).sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/134: abs(np.gradient(data[i,:,:])[1]).sum(axis=0)
185/135: abs(np.gradient(data[i,:,:])[1]).sum(axis=0) > 2000
185/136: np.argmax(abs(np.gradient(data[i,:,:])[1]).sum(axis=0) > 2000)
185/137: np.argmax(abs(np.gradient(data[i,:,:])[1]).sum(axis=0)[50:] > 2000)
185/138: np.argmax(abs(np.gradient(data[i,:,:])[1]).sum(axis=0)[:1000] > 2000)
185/139: np.argmax(abs(np.gradient(data[i,:,:])[1]).sum(axis=0)[950:1000] > 2000)
185/140: np.argmax(abs(np.gradient(data[i,:,:])[1]).sum(axis=0)[950::1000] > 2000)
185/141: np.argmax(abs(np.gradient(data[i,:,:])[1]).sum(axis=0) > 2000)
185/142: abs(np.gradient(data[i,:,:])[1]).sum(axis=0)
185/143:
i=72
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:])[1]).sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/144:
i=200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:])[1]).sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/145:
i=56
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:])[1]).sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/146:
i=56
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:].sum(axis=0))[1]).sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/147:
i=56
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(abs(np.gradient(data[i,:,:].sum(axis=0))[1]))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/148: data[i,:,:].sum(axis=0)
185/149: plt.plot(data[i,:,:].sum(axis=0))
185/150: np.gradient(data[i,:,:].sum(axis=0))
185/151: plt.plot(np.gradient(data[i,:,:].sum(axis=0)))
185/152: np.gradient(data[i,:,:].sum(axis=0))
185/153: plt.plot(np.gradient(data[i,:,:].sum(axis=0)))
185/154: plt.plot(np.gradient(data[i,:,:].sum(axis=0)))
185/155: plt.plot(data[i,:,:].sum(axis=0))
185/156: plt.plot(data[i,:,:].sum(axis=0)*100)
185/157: plt.plot(data[i,:,:].sum(axis=0)*100)
185/158: plt.plot(data[i,:,:].sum(axis=0))
185/159:
i=60
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plt.plot(data[i,:,:].sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/160:
i=60
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0))
ax1.set_aspect(0.079,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/161:
i=60
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0))
ax1.set_aspect(1,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/162:
i=60
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0))
ax1.set_aspect(0.001,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/163:
i=60
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0))
ax1.set_aspect(0.001,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/164:
i=61
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0))
ax1.set_aspect(0.001,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/165:
i=62
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0))
ax1.set_aspect(0.001,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/166:
i=60
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,:],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0))
ax1.set_aspect(0.001,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/167: data[i,:,:].sum(axis=0)
185/168: data[i,:,:].sum(axis=0)>2000
185/169: plt.plot(data[i,:,:].sum(axis=0))
185/170: data[i,:,:].sum(axis=0)>20000
185/171: argmax(data[i,:,:].sum(axis=0)>20000)
185/172: np.argmax(data[i,:,:].sum(axis=0)>20000)
185/173: plt.imshow(data[i,100:200,:])
185/174: plt.imshow(data[i,:,100:200],cmap='gray')
185/175: plt.imshow(data[i,:,50:250],cmap='gray')
185/176:
i=60
w = 100
fig = plt.figure(figsize=(6,9))
arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,(arg-w):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/177:
i=60
w = 100
fig = plt.figure(figsize=(6,9))
arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,(arg-w):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/178:
i=61
w = 100
fig = plt.figure(figsize=(6,9))
arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,(arg-w):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/179: np.argmax(data[i,:,:].sum(axis=0)>20000)
185/180: data[i,:,:].sum(axis=0)
185/181:
i=61
w = 100
fig = plt.figure(figsize=(6,9))
arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,(arg-w):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/182: labels = rf['labels']
185/183: labels
185/184: labels[i]
185/185:
i=61
w = 100
fig = plt.figure(figsize=(6,9))
if '_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
elif '_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,(arg-w):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/186:
i=61
w = 100
fig = plt.figure(figsize=(6,9))
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,(arg-w):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/187:
i=60
w = 100
fig = plt.figure(figsize=(6,9))
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,(arg-w):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/188:
i=60
w = 100
fig = plt.figure(figsize=(6,9))
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,(arg-w):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/189:
i=10
w = 100
fig = plt.figure(figsize=(6,9))
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,(arg-w):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/190:
i=10
w = 150
fig = plt.figure(figsize=(6,9))
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,(arg-w):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/191:
i=10
w = 200
fig = plt.figure(figsize=(6,9))
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
ax0.imshow(data[i,:,(arg-w):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/192:
i=10
w = 160
fig = plt.figure(figsize=(6,9))

#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//2)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//2):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/193:
i=10
w = 200
fig = plt.figure(figsize=(6,9))

#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//2)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//2):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/194:
i=10
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//3)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//3):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/195:
i=9
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//3)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//3):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/196:
i=8
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//3)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//3):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/197:
i=7
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//3)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//3):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/198:
i=6
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//3)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//3):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/199:
i=5
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//3)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//3):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/200:
i=5
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/201:
i=10
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/202:
i=20
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/203:
i=21
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/204:
i=22
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/205:
i=60
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/206:
i=65
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/207:
i=66
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/208:
i=26
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/209:
i=30
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/210:
i=31
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
185/211:
i=32
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<20000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>20000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/1: import matplotlib.pylab as plt
186/2: import h5py
186/3: rf = h5py.File('1000x1000.hdf5')
186/4: data[i,:,:].sum(axis=0)
186/5: data = rf['data']
186/6: labels = rf['labels']
186/7:
i=32
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/8: from matplotlib import gridspec
186/9:
i=32
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/10: import numpy as np
186/11:
i=32
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/12:
i=10
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/13:
i=9
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/14:
i=8
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/15:
i=7
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/16:
i=6
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/17:
i=4
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/18:
i=32
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/19:
i=34
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/20:
i=40
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/21:
i=60
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/22:
i=62
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/23:
i=64
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/24:
i=66
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/25:
i=68
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/26:
i=70
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<40000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>40000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/27:
i=70
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<100000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>100000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/28:
i=10
w = 200
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<100000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>100000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/29:
i=10
w = 300
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<60000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>60000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
186/30:
i=10
w = 300
fig = plt.figure(figsize=(6,9))
#fig,(ax0,ax1)=plt.subplots(2,1,sharex=True)
gs = gridspec.GridSpec(2,1, height_ratios=[1, 1]) 
ax0 = plt.subplot(gs[0])
if b'_R' in labels[i] :
    arg = np.argmax(data[i,:,:].sum(axis=0)<60000)
    ax0.imshow(data[i,:,(arg-w):(arg+w//4)],cmap='gray')    
elif b'_L' in labels[i]:
    arg = np.argmax(data[i,:,:].sum(axis=0)>60000)
    ax0.imshow(data[i,:,(arg-w//4):(arg+w)],cmap='gray')
#ax0.set_adjustable('box',share=True)
ax1 = plt.subplot(gs[1])
ax1.plot(data[i,:,:].sum(axis=0)[(arg-w):(arg+w)])
ax1.set_aspect(0.001,share=True)
#ax1.set_xlim(0,1000)
#ax1.set_figwidth(1)
plt.tight_layout()
plt.show()
187/1: import matplotlib.pylab as plt
187/2: import h5py
187/3: import numpy as np
187/4: rf = h5py.File('2000x375.hdf5','r')
187/5: data = rf['data']
187/6: labels = rf['labels']
187/7: labels.shape
187/8: data.shape
187/9: plt.imshow(data[0,:,:],cmap='gray')
187/10: plt.imshow(data[2000,:,:],cmap='gray')
187/11: plt.imshow(data[101,:,:],cmap='gray')
187/12: plt.imshow(data[3000,:,:],cmap='gray')
187/13: plt.imshow(data[3001,:,:],cmap='gray')
187/14: plt.imshow(data[3002,:,:],cmap='gray')
187/15: plt.imshow(data[3003,:,:],cmap='gray')
187/16: plt.imshow(data[2999,:,:],cmap='gray')
187/17: plt.imshow(data[2998,:,:],cmap='gray')
187/18: plt.imshow(data[2996,:,:],cmap='gray')
187/19: plt.imshow(data[2994,:,:],cmap='gray')
187/20: plt.imshow(data[2992,:,:],cmap='gray')
187/21: plt.imshow(data[2990,:,:],cmap='gray')
187/22: plt.imshow(data[2988,:,:],cmap='gray')
187/23: plt.imshow(data[2980,:,:],cmap='gray')
188/1: import numpy as np
188/2: import matplotlib.pylab as plt
188/3: import h5py
189/1: import h5py
189/2: import matplotlib.pylab as plt
189/3: rf = h5py.File('2000x400.hdf5','r')
189/4: data = rf['data']
189/5: labels = rf['labels']
189/6: data.shape
189/7: plt.ims
189/8: plt.imshow(data[2980,:,:],cmap='gray')
189/9: plt.imshow(data[3000,:,:],cmap='gray')
190/1: import h5py
190/2: rf = h5py.File('2000x400.hdf5')
190/3: data = rf['data'][:]
190/4: import matplotlib.pyplot as plt
190/5: plt.imshow(data[0,:,:])
190/6: plt.imshow(data[0,:,:],cmap='gray')
190/7: plt.imshow(data[10,:,:],cmap='gray')
190/8: plt.imshow(data[11,:,:],cmap='gray')
190/9: plt.imshow(data[2000,:,:],cmap='gray')
190/10: plt.imshow(data[2001,:,:],cmap='gray')
190/11: plt.imshow(data[3001,:,:],cmap='gray')
190/12: plt.imshow(data[4001,:,:],cmap='gray')
190/13: plt.imshow(data[3477,:,:],cmap='gray')
190/14: plt.imshow(data[3476,:,:],cmap='gray')
190/15: plt.imshow(data[3475,:,:],cmap='gray')
190/16: plt.imshow(data[3475,:,:],cmap='gray')
190/17: plt.imshow(data[3470,:,:],cmap='gray')
190/18: plt.imshow(data[350,:,:],cmap='gray')
190/19: plt.imshow(data[351,:,:],cmap='gray')
190/20: plt.imshow(data[352,:,:],cmap='gray')
190/21: plt.imshow(data[353,:,:],cmap='gray')
190/22: plt.imshow(data[368,:,:],cmap='gray')
190/23: plt.imshow(data[380,:,:],cmap='gray')
190/24: plt.imshow(data[3,:,:],cmap='gray')
191/1:
import h5py
import numpy as np
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape
from keras.models import Model
from keras.optimizers import RMSprop
191/2:
rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]
191/3: import pandas as pd
191/4: pd.read_excel?
191/5: df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low_Quality')
191/6: df_LQ
191/7: df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
191/8: df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
191/9: df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_C')
191/10: df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_C')
191/11: df_HQHT_C = pd.read_excel('Automated_Al')
191/12: df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_1')
191/13: df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
191/14: df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')')
191/15: df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
191/16: df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
191/17: df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
191/18: data
191/19: data[0]
191/20: import matplotlib.pyplot as plt
191/21: plt.imshow(data[3,:,:],cmap='gray')
191/22: plt.imshow(data[9,:,:],cmap='gray')
191/23: plt.imshow(data[90,:,:],cmap='gray')
191/24: np.append?
191/25: np.append(data[0],data[1],data)
192/1:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop
192/2:
def convolution_net(img1,img2,img3,img4): # 4 images of 2000x400x1                                                                                                                                          
    # Each picture should give us around 2000x4 pixles around the edge                                                                                                                                      

    # img1 convolution                                                                                                                                                                                      
    conv1_1 = Conv2D(24,(3,3),activation='relu',padding='same')(img1)    # 2000x400x24                                                                                                                      
    pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1)                     # 1000x200x24                                                                                                                      
    conv2_1 = Conv2D(12,(3,3),activation='relu',padding='same')(pool1_1) # 1000x200x12                                                                                                                      
    pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1)                     # 500 x100x12                                                                                                                      
    conv3_1 = Conv2D(6,(3,3),activation='relu',padding='same')(pool2_1)  # 500 x100x6                                                                                                                       
    pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1)                     # 250 x50 x6                                                                                                                       
    conv4_1 = Conv2D(3,(3,3),activation='relu',padding='same')(pool3_1)  # 250 x50 x6                                                                                                                       
    pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1)                     # 125 x25 x3                                                                                                                       
    flat_1  = Flatten()(pool4_1)                                         # 9375x1                                                                                                                           

    # img2 convolution                                                                                                                                                                                      
    conv1_2 = Conv2D(24,(3,3),activation='relu',padding='same')(img2)    # 2000x400x24                                                                                                                      
    pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2)                     # 1000x200x24                                                                                                                      
    conv2_2 = Conv2D(12,(3,3),activation='relu',padding='same')(pool1_2) # 1000x200x12                                                                                                                      
    pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2)                     # 500 x100x12                                                                                                                      
    conv3_2 = Conv2D(6,(3,3),activation='relu',padding='same')(pool2_2)  # 500 x100x6                                                                                                                       
    pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2)                     # 250 x50 x6                                                                                                                       
    conv4_2 = Conv2D(3,(3,3),activation='relu',padding='same')(pool3_2)  # 250 x50 x6                                                                                                                       
    pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2)                     # 125 x25 x3                                                                                                                       
    flat_2  = Flatten()(pool4_2)                                         # 9375x1                                                                                                                           

    # img3 convolution                                                                                                                                                                                      
    conv1_3 = Conv2D(24,(3,3),activation='relu',padding='same')(img3)    # 2000x400x24                                                                                                                      
    pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3)                     # 1000x200x24                                                                                                                      
    conv2_3 = Conv2D(12,(3,3),activation='relu',padding='same')(pool1_3) # 1000x200x12                                                                                                                      
    pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3)                     # 500 x100x12                                                                                                                      
    conv3_3 = Conv2D(6,(3,3),activation='relu',padding='same')(pool2_3)  # 500 x100x6                                                                                                                       
    pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3)                     # 250 x50 x6                                                                                                                       
    conv4_3 = Conv2D(3,(3,3),activation='relu',padding='same')(pool3_3)  # 250 x50 x6                                                                                                                       
    pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3)                     # 125 x25 x3                                                                                                                       
    flat_3  = Flatten()(pool4_3)                                         # 9375x1                                                                                                                           

    # img4 convolution                                                                                                                                                                                      
    conv1_4 = Conv2D(24,(3,3),activation='relu',padding='same')(img4)    # 2000x400x24                                                                                                                      
    pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4)                     # 1000x200x24                                                                                                                      
    conv2_4 = Conv2D(12,(3,3),activation='relu',padding='same')(pool1_4) # 1000x200x12                                                                                                                      
    pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4)                     # 500 x100x12                                                                                                                      
    conv3_4 = Conv2D(6,(3,3),activation='relu',padding='same')(pool2_4)  # 500 x100x6                                                                                                                       
    pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4)                     # 250 x50 x6                                                                                                                       
    conv4_4 = Conv2D(3,(3,3),activation='relu',padding='same')(pool3_4)  # 250 x50 x6                                                                                                                       
    pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4)                     # 125 x25 x3                                                                                                                       
    flat_4  = Flatten()(pool4_4)                                         # 9375x1         
    l1 = Concatenate([flat_1,flat_2,flat_3,flat_4])                      # 37500 x 1                                                                                                                        
    d1 = Dense(1000,activation='relu')(l1)
    d2 = Dense(500,activation='relu')(d1)
    d3 = Dense(200,activation='relu')(d2)
    d4 = Dense(1,activation='sigmoid')(d3)

    return d4
192/3:
rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]

df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low_Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_1')

df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
192/4: df_LQ
192/5: df_matches_HQHT
192/6: df_LQ
192/7:
rf.close()

df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low_Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_1')

df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
192/8: df_matches_LQHT
192/9: df_matches_LQHT[0]
192/10: df_matches_LQHT
192/11: df_matches_LQHT.values
192/12: df_matches_LQHT.values.astype(float)
192/13: df_matches_LQHT.values
192/14: df_matches_LQHT.values
193/1: import pandas as pd
193/2: df = pd.read_excel('Automated_Algorithm_Scans.xlsx')
193/3: df
194/1: import h5py
194/2:
rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]

df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low_Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_1')

df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
194/3: import pandas as pd
194/4:
rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]

df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low_Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_1')

df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
195/1:
rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]

df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low_Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_1')

df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
195/2: import h5py
195/3: import pandas as pd
195/4:
rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]

df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low_Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_1')

df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
195/5: df_matches_MQHT
195/6: df_matches_MQHT.iloc[0]
195/7: df_matches_MQHT.iloc[0][0]
195/8: df_matches_MQHT.iloc[0][1]
195/9: df_matches_MQHT.iloc[0][1].split()
195/10: df_matches_MQHT.iloc[0][1]
195/11: item1 = df_matches_MQHT.iloc[0][0]
195/12: item2 = df_matches_MQHT.iloc[0][1]
195/13: item
195/14: item1
195/15: df_MQHT['Tape']
195/16: item1[:-1]
195/17: item1[:-1]
195/18: item1[:-1] in df_MQHT['Tape']
195/19: df_MQHT['Tape'].str.find(item1[:-1])
195/20: df_MQHT['Tape'] == item1[:-1]
195/21: df_MQHT[df_MQHT['Tape'] == item1[:-1]]
195/22: df_MQHT['Tape']
195/23: df_MQHT[df_MQHT['Tape'] == item1[:-1].float()]
195/24: df_MQHT[df_MQHT['Tape'] == float(item1[:-1])]
195/25: df_MQHT[df_MQHT['Tape'] == float(item1[:-1])]
195/26: df_MQHT[df_MQHT['Tape'] == float(item1[:-1])]['Left Edge']
195/27: df_MQHT[df_MQHT['Tape'] == float(item1[:-1]))
195/28: df_MQHT[df_MQHT['Tape'] == float(item1[:-1])]
195/29: df_MQHT[df_MQHT['Tape'] == float(item1[:-1])]
195/30: item1[-1]
195/31: item2
195/32: sub_df = df_MQHT[df_MQHT['Tape'] == float(item1[:-1])]
195/33: sub_df.str.find(item1[-1])
195/34: sub_df.iloc[0]['Left Edge']
195/35: sub_df.iloc[0]['Left Edge'] == item1[-1]
195/36: sub_df.iloc[0]['Right Edge'] == item1[-1]
195/37: sub_df.iloc[0]['Scan Name']
195/38: sub_df.iloc[0]['Scan Name']+'_R'
195/39: sub_df.iloc[0]['Scan Name']+'_R.tif'
195/40: sub_df.iloc[0]['Scan Name']+'_R'
195/41: labels
195/42: labels == sub_df.iloc[0]['Scan Name']+'_R'
195/43: labels == np.string_(sub_df.iloc[0]['Scan Name']+'_R')
195/44: import numpy as np
195/45: labels == np.string_(sub_df.iloc[0]['Scan Name']+'_R')
195/46: data[labels == np.string_(sub_df.iloc[0]['Scan Name']+'_R')]
195/47: import matplotlib.pyplot as plt
195/48: plt.imshow(data[labels == np.string_(sub_df.iloc[0]['Scan Name']+'_R')])
195/49: plt.imshow(data[labels == np.string_(sub_df.iloc[0]['Scan Name']+'_R')][0])
195/50: plt.imshow(data[labels == np.string_(sub_df.iloc[0]['Scan Name']+'_R')][0],cmap='gray')
195/51: %history
196/1: cd ML-convlolutional_net/
196/2: ls
196/3:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]

df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low_Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT-Set_1')

df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
196/4: df_matches_MQHT.iloc[0]
196/5: df_matches_MQHT.shape
196/6:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    print(item1,item2)
196/7:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]

    print(item1,item2)
196/8:

# gather info for Medium Quality Hand Torn                                                                                                                                                                  
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = item1[:-1]
    tapeNo2 = item2[:-1]

    print(tapeNo1,tapeNo2)
196/9:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])

    print(tapeNo1,tapeNo2)
196/10: df_MQHT[df_MQHT['Tape'] == tapeNo2]
196/11: df_MQHT['Tape']3.
196/12: df_MQHT['Tape']
196/13: df_MQHT['Tape'] == tapeNo1
196/14: idx = df_MQHT['Tape'] == tapeNo1
196/15: df_MQHT[idx]
196/16: idx = df_MQHT['Tape'] == tapeNo2
196/17: df_MQHT[idx]
196/18: i = 0
196/19:
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
196/20: idx = df_MQHT['Tape'] == tapeNo2
196/21: df_MQHT[idx]
196/22:
# gather info for Medium Quality Hand Torn                                                                                                                                                                  
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    print(df_MQHT[idx1],df_MQHT[idx1])
196/23:
# gather info for Medium Quality Hand Torn                                                                                                                                                                  
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    print(df_MQHT[idx1].shape,df_MQHT[idx1].shape)
196/24:
# gather info for Medium Quality Hand Torn                                                                                                                                                                  
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2

    if df_MQHT[idx1].shape[0]<2  or df_MQHT[idx1].shape[0] < 2 :
        print(item1,item2,i)
196/25:
# gather info for Medium Quality Hand Torn                                                                                                                                                                  
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2

    if df_MQHT[idx1].shape[0]<2  or df_MQHT[idx1].shape[0] < 2 :
        print(item1,item2,i+2)
196/26:
# gather info for Medium Quality Hand Torn                                                                                                                                                                  
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2

    if df_MQHT[idx1].shape[0]<2  or df_MQHT[idx1].shape[0] < 2 :
        print(item1,item2,i+2)
197/1:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]

df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')

df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
197/2: pwd
197/3: cd ML-convlolutional_net/
197/4:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]

df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')

df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
197/5:
# gather info for Medium Quality Hand Torn                                                          
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    print(df_MQHT[idx1].shape,df_MQHT[idx1].shape)
197/6:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    print(df_MQHT[idx1].shape,df_MQHT[idx2].shape)
197/7:
# gather info for Medium Quality Hand Torn                                                          
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape != 2 :
        print(df_MQHT[idx1])
    if df_MQHT[idx2].shape != 2 :
        print(df_MQHT[idx2])
197/8:
# gather info for Medium Quality Hand Torn                                                          
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(df_MQHT[idx1])
    if df_MQHT[idx2].shape[0] != 2 :
        print(df_MQHT[idx2])
197/9:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2

    if df_MQHT[idx1].shape[0] != 2 :
    print(item1,item2)
        print(df_MQHT[idx1])
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2)
        print(df_MQHT[idx2])
197/10:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2

    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2)
        print(df_MQHT[idx1])
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2)
        print(df_MQHT[idx2])
197/11:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2

    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
197/12:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]

df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')

df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
197/13:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2

    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
197/14:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2

    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])

    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]
197/15: sub_df1
197/16: sub_df1.iloc[0]['Left Edge']
197/17: item1
197/18: item1[-1]
197/19: item1[-1]
198/1:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]

df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')

df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
199/1: %history
199/2:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]

df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')

df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
199/3:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2

    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])

    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]
199/4:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]
    print(item1,item2)
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2

#    if df_MQHT[idx1].shape[0] != 2 :
#        print(item1,item2,i+2)
#        print(df_MQHT[idx1])
#    if df_MQHT[idx2].shape[0] != 2 :
#        print(item1,item2,i+2)
#        print(df_MQHT[idx2])

    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]
199/5:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2

    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])

    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]
199/6:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]

df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')

df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
199/7:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2

    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])

    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]
199/8: df_MQSC
199/9: df_MQSC['Tapr']
199/10: df_MQSC['Tape']
199/11: df_MQSC['Tape'] == 701
199/12:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2

    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])

    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]
199/13:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2

    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])

    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]
199/14:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2

    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])

    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]
199/15:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_HQHT['Tape'] == tapeNo1
    idx2  = df_HQHT['Tape'] == tapeNo2

    if df_HQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_HQHT[idx1])
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])

    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]
199/16: df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
199/17:
for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQHT['Tape'] == tapeNo1
    idx2  = df_LQHT['Tape'] == tapeNo2

    if df_LQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQHT[idx1])
    if df_LQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQSC[idx2])

    sub_df1 = df_LQHT[idx1]
    sub_df2 = df_LQHT[idx2]
199/18:
for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQ['Tape'] == tapeNo1
    idx2  = df_LQ['Tape'] == tapeNo2

    if df_LQ[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx1])
    if df_LQ[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx2])

    sub_df1 = df_LQ[idx1]
    sub_df2 = df_LQ[idx2]
199/19:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_HQHT_1['Tape'] == tapeNo1
    idx2  = df_HQHT_1['Tape'] == tapeNo2

    if df_HQHT_1[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_HQHT_1[idx1])
    if df_HQHT_1[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_HQHT_1[idx2])

    sub_df1 = df_HQHT_1[idx1]
    sub_df2 = df_HQHT_1[idx2]
199/20:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_HQHT_1['Tape'] == tapeNo1
    idx2  = df_HQHT_1['Tape'] == tapeNo2

    if df_HQHT_1[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_HQHT_1[idx1])
    if df_HQHT_1[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_HQHT_1[idx2])

    sub_df1 = df_HQHT_1[idx1]
    sub_df2 = df_HQHT_1[idx2]
199/21:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_HQHT_1['Tape'] == tapeNo1
    idx2  = df_HQHT_1['Tape'] == tapeNo2

    if df_HQHT_1[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_HQHT_1[idx1])
    if df_HQHT_1[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_HQHT_1[idx2])

    sub_df1 = df_HQHT_1[idx1]
    sub_df2 = df_HQHT_1[idx2]
199/22: df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
199/23:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_HQHT_1['Tape'] == tapeNo1
    idx2  = df_HQHT_1['Tape'] == tapeNo2

    if df_HQHT_1[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_HQHT_1[idx1])
    if df_HQHT_1[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_HQHT_1[idx2])

    sub_df1 = df_HQHT_1[idx1]
    sub_df2 = df_HQHT_1[idx2]
199/24:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_HQHT_1['Tape'] == tapeNo1
    idx2  = df_HQHT_1['Tape'] == tapeNo2

    if df_HQHT_1[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_HQHT_1[idx1])
    else :
        idx1  = df_HQHT_C['Tape'] == tapeNo1
        idx2  = df_HQHT_C['Tape'] == tapeNo2
        if df_HQHT_C[idx1].shape[0] != 2 :
            print(item1,item2,i+2)
            print(df_HQHT_C[idx1])
    if df_HQHT_1[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_HQHT_1[idx2])
    else :
        idx1  = df_HQHT_C['Tape'] == tapeNo1
        idx2  = df_HQHT_C['Tape'] == tapeNo2
        if df_HQHT_C[idx2].shape[0] != 2 :
            print(item1,item2,i+2)
            print(df_HQHT_C[idx2])
    sub_df1 = df_HQHT_1[idx1]
    sub_df2 = df_HQHT_1[idx2]
199/25:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2

    if df_HQHT_1[idx1_1].shape[0] != 2 or df_HQHT_1[idx2_1].shape[0] != 2:
        if df_HQHT_C[idx1_C].shape[0] != 2 or df_HQHT_C[idx2_C].shape[0] != 2:
            print(item1,item2,i+2)
200/1:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
200/2:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]
200/3: sub_df1
200/4: sub_df1[0]
200/5: sub_df1
200/6: item1
200/7: item2
200/8: sub_df2
200/9:
matching_labels = []
for j in range(2):
    if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
        matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
    else :
        matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
    if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
        matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
    else :
        matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
200/10: matching_labels
200/11: labels
200/12: np.string_(matching_labels)
200/13: matching_labels = np.string_(matching_labels)
200/14: labels == matching_labels[0]
200/15: data[labels == matching_labels[0]]
200/16: data[labels == matching_labels[0]]
200/17: import matplotlib.pylab as plt
200/18: plt.imshow(data[labels == matching_labels[0]])
200/19: plt.imshow(data[labels == matching_labels[0]][0])
200/20: plt.imshow(data[labels == matching_labels[1]][0])
200/21: plt.imshow(data[labels == matching_labels[2]][0])
200/22: plt.imshow(data[labels == matching_labels[3]][0])
200/23: data[labels == matching_labels[0]]
200/24:
data_ready2use = []

for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel[0]][0])
200/25:
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel])
200/26: data_matched
200/27: np.array(data_matched)
200/28: np.array(data_matched)[0]
200/29: np.array(data_matched)[1]
200/30: np.array(data_matched).shape
200/31:
data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
200/32:
data_matched = []
for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
200/33: data_matched
200/34: np.array(data_matched)[0]
200/35: np.array(data_matched).shape
200/36: np.array(data_matched).shape
200/37:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
    continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
200/38:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
200/39: data_ready2use
200/40: np.array(data_ready2use)
200/41: np.array(data_ready2use).shape
200/42: np.array(data_ready2use)[20]
200/43: plt.imshow(np.array(data_ready2use)[20][0],cmap='gray')
200/44: plt.imshow(np.array(data_ready2use)[20][1],cmap='gray')
200/45: plt.imshow(np.array(data_ready2use)[20][2],cmap='gray')
200/46: plt.imshow(np.array(data_ready2use)[20][3],cmap='gray')
200/47: plt.imshow(np.array(data_ready2use)[20][0],cmap='gray')
200/48: plt.imshow(np.array(data_ready2use)[20][1],cmap='gray')
200/49: plt.imshow(np.array(data_ready2use)[20][2],cmap='gray')
200/50: plt.imshow(np.array(data_ready2use)[20][3],cmap='gray')
200/51:
for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQ['Tape'] == tapeNo1
    idx2  = df_LQ['Tape'] == tapeNo2
    if df_LQ[idx1].shape[0] != 2 :
    print(item1,item2,i+2)
        print(df_LQ[idx1])
    if df_LQ[idx2].shape[0] != 2 :
    print(item1,item2,i+2)
        print(df_LQ[idx2])
    sub_df1 = df_LQ[idx1]
    sub_df2 = df_LQ[idx2]
200/52:

for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQ['Tape'] == tapeNo1
    idx2  = df_LQ['Tape'] == tapeNo2
    if df_LQ[idx1].shape[0] != 2 :
    print(item1,item2,i+2)
        print(df_LQ[idx1])
    if df_LQ[idx2].shape[0] != 2 :
    print(item1,item2,i+2)
        print(df_LQ[idx2])
    sub_df1 = df_LQ[idx1]
    sub_df2 = df_LQ[idx2]
200/53:
for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQ['Tape'] == tapeNo1
    idx2  = df_LQ['Tape'] == tapeNo2
    if df_LQ[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx1])
        continue
    if df_LQ[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx2])
        continue
    sub_df1 = df_LQ[idx1]
    sub_df2 = df_LQ[idx2]
200/54: sub_df1
200/55: item1
200/56: sub_df2
200/57: item2
200/58:
matching_labels = []
for j in range(2):
    if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
        matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
    else :
        matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
    if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
        matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
    else :
        matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
200/59: matching_labels
200/60:
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
200/61:
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
200/62:     matching_labels = np.string_(matching_labels)
200/63:
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
200/64: data_matched
200/65: plt.imshow(data_matched)
200/66: plt.imshow(data_matched[0])
200/67: plt.imshow(data_matched[1])
200/68: plt.imshow(data_matched[0],cmap='gray')
200/69: plt.imshow(data_matched[1],cmap='gray')
200/70: plt.imshow(data_matched[2],cmap='gray')
200/71: plt.imshow(data_matched[3],cmap='gray')
200/72: matching_labels
200/73: matching_labels[3]
200/74:
matching_labels = []
for j in range(2):
    if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
        matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
    else :
        matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
    if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
        matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
    else :
        matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
200/75:     matching_labels = np.string_(matching_labels)
200/76:
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
200/77: plt.imshow(data_matched[0],cmap='gray')
200/78: plt.imshow(data_matched[1],cmap='gray')
200/79: plt.imshow(data_matched[2],cmap='gray')
200/80: plt.imshow(data_matched[3],cmap='gray')
200/81:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2
    if df_HQHT_1[idx1_1].shape[0] == 2 and df_HQHT_1[idx2_1].shape[0] == 2:
        sub_df1 = df_HQHT_1[idx1_1]
        sub_df2 = df_HQHT_1[idx2_1]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    else :
        print(item1,item2,i+2)
        continue
200/82:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2
    if df_HQHT_1[idx1_1].shape[0] == 2 and df_HQHT_1[idx2_1].shape[0] == 2:
        sub_df1 = df_HQHT_1[idx1_1]
        sub_df2 = df_HQHT_1[idx2_1]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        print(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        print(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    else :
        print(item1,item2,i+2)
        continue
200/83: sum(labels == b'HQC_173_L')
200/84: sum(labels == b'HQC_175_R')
200/85: sum(labels == b'HQC_174_R')
200/86: sum(labels == b'HQC_176_L')
200/87: sum(labels == b'HQC_161_L')
200/88:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2
    if df_HQHT_1[idx1_1].shape[0] == 2 and df_HQHT_1[idx2_1].shape[0] == 2:
        sub_df1 = df_HQHT_1[idx1_1]
        sub_df2 = df_HQHT_1[idx2_1]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        print(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        print(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    else :
        print(item1,item2,i+2)
        continue
200/89:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2
    if df_HQHT_1[idx1_1].shape[0] == 2 and df_HQHT_1[idx2_1].shape[0] == 2:
        sub_df1 = df_HQHT_1[idx1_1]
        sub_df2 = df_HQHT_1[idx2_1]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        print(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            try :
                data_matched.append(data[labels == ilabel][0])
            except :
                print('error')
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        print(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            try :
                data_matched.append(data[labels == ilabel][0])
            except :
                print('error')
        data_ready2use.append(np.array(data_matched))
    else :
        print(item1,item2,i+2)
        continue
201/1:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
201/2:
data_ready2use = []

for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
201/3:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
201/4:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
201/5: item1
201/6: sub_df1.iloc[j]['Left Edge']
201/7: sub_df1.iloc[j]
201/8: sub_df1
201/9: j
201/10: df_MQSC[idx2]
201/11: data_ready2use
201/12: data_ready2use[0]
201/13: data_ready2use[0]
201/14: data_ready2use[20]
201/15: import matplotlib.pylab as plt
201/16: plt.imshow(data_ready2use[20][0],cmap='gray')
201/17: plt.imshow(data_ready2use[20][1],cmap='gray')
201/18: plt.imshow(data_ready2use[20][2],cmap='gray')
201/19: plt.imshow(data_ready2use[20][3],cmap='gray')
201/20: plt.imshow(data_ready2use[20][0],cmap='gray')
201/21: plt.imshow(data_ready2use[20][1],cmap='gray')
201/22: plt.imshow(data_ready2use[20][2],cmap='gray')
201/23: plt.imshow(data_ready2use[20][3],cmap='gray')
201/24:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2
    if df_HQHT_1[idx1_1].shape[0] == 2 and df_HQHT_1[idx2_1].shape[0] == 2:
        sub_df1 = df_HQHT_1[idx1_1]
        sub_df2 = df_HQHT_1[idx2_1]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)

        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    else :
        print(item1,item2,i+2)
        continue
201/25:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2
    if df_HQHT_1[idx1_1].shape[0] == 2 and df_HQHT_1[idx2_1].shape[0] == 2:
        sub_df1 = df_HQHT_1[idx1_1]
        sub_df2 = df_HQHT_1[idx2_1]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        print(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            try :
                data_matched.append(data[labels == ilabel][0])
            except :
                print('error')
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        print(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            try :
                data_matched.append(data[labels == ilabel][0])
            except :
                print('error')
        data_ready2use.append(np.array(data_matched))
    else :
        print(item1,item2,i+2)
        continue
201/26: plt.imshow(data_ready2use[-1][3],cmap='gray')
201/27: plt.imshow(data_ready2use[-1][0],cmap='gray')
201/28: plt.imshow(data_ready2use[-1][2],cmap='gray')
201/29: plt.imshow(data_ready2use[-1][2])
201/30: data_ready2use[0][2]
202/1:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
202/2: data_ready2use = []
202/3:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
202/4:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]
    
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
203/1:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
204/1: import pychemia
204/2: pychemia.utils.periodic.covalent_radii
204/3: pychemia.utils.periodic.covalent_radii[0]
204/4: pychemia.utils.periodic.covalent_radius('He')
204/5: ls
205/1:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('1500x266.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
205/2:
data_ready2use = []

for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
205/3:

for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
205/4: j
205/5: sub_df1
205/6:

for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQSC[idx1]
    sub_df2 = df_MQSC[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
205/7:
for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQ['Tape'] == tapeNo1
    idx2  = df_LQ['Tape'] == tapeNo2
    if df_LQ[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx1])
    if df_LQ[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx2])
    sub_df1 = df_LQ[idx1]
    sub_df2 = df_LQ[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)

    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
205/8: j
205/9: sub_df1
205/10: tapeNo1
205/11: idf
205/12: idx1
205/13: sum(idx1)
205/14: tapeNo1
205/15: tapeNo2
205/16: df_LQ
205/17: df_matches_LQHT
205/18: df_LQ
205/19: tapeNo1
205/20: idx1
205/21: sum(idx1)
205/22: sum(idx2)
205/23: tapeNo1
205/24: labels == 'LQ_199_R'
205/25: labels == 'LQ_199_R'
205/26: labels
205/27: labels[:]
205/28: labels[:] == np.string_('LQ_199_R')
205/29: sum()labels[:] == np.string_('LQ_199_R')
205/30: sum(labels[:] == np.string_('LQ_199_R'))
205/31: sum(labels[:] == np.string_('LQ_199_L'))
205/32: sum(labels[:] == b'LQ_199_L')
205/33: df_LQ['Tape']
205/34: df_LQ['Tape'] == 769
205/35: sum(df_LQ['Tape'] == 769)
205/36: sum(df_LQ['Tape'] == 769.0)
205/37: df_LQ.iloc[200]
205/38: df_LQ.iloc[199]
206/1:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop
206/2:
rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
206/3: ls
206/4:
rf = h5py.File('1500x266.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
206/5: data_ready2use = []
206/6:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
206/7:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQSC[idx1]
    sub_df2 = df_MQSC[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
206/8: item1
206/9:
rf = h5py.File('1500x266.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
206/10:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQSC[idx1]
    sub_df2 = df_MQSC[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
206/11: item1
206/12: df_MSQC
206/13: df_MQSC
206/14: df_MQSC['Tape']
206/15: df_MQSC['Tape'] == 701
206/16:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQSC[idx1]
    sub_df2 = df_MQSC[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
206/17: idx1
206/18:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQSC[idx1]
    sub_df2 = df_MQSC[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
206/19: sub_df1
206/20: ilabel
206/21: labels
206/22: labels == b'MQSC_510_L'
206/23: sum(labels == b'MQSC_510_L')
206/24: data_ready2use
206/25: data_ready2use[0]
206/26: import matplotlib.pyplot as plt
206/27: plt.imshow(data_ready2use[0][0],cmap='gray')
206/28: plt.imshow(data_ready2use[0][1],cmap='gray')
206/29: plt.imshow(data_ready2use[0][2],cmap='gray')
206/30: plt.imshow(data_ready2use[0][3],cmap='gray')
206/31: plt.imshow(data_ready2use[100][3],cmap='gray')
206/32: plt.imshow(data_ready2use[85][3],cmap='gray')
206/33: plt.imshow(data_ready2use[89][3],cmap='gray')
206/34: plt.imshow(data_ready2use[600][3],cmap='gray')
206/35: plt.imshow(data_ready2use[70][3],cmap='gray')
206/36: plt.imshow(data_ready2use[70][3],cmap='gray')
206/37: plt.imshow(data_ready2use[70][0],cmap='gray')
206/38: plt.imshow(data_ready2use[70][1],cmap='gray')
206/39: plt.imshow(data_ready2use[70][2],cmap='gray')
206/40: plt.imshow(data_ready2use[70][3],cmap='gray')
206/41: plt.imshow(data_ready2use[75][3],cmap='gray')
206/42: plt.imshow(data_ready2use[75][2],cmap='gray')
206/43: plt.imshow(data_ready2use[75][1],cmap='gray')
206/44: plt.imshow(data_ready2use[75][0],cmap='gray')
207/1:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop
207/2:
rf = h5py.File('2000x400.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
207/3:
rf = h5py.File('1500x266.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
207/4: data_ready2use = []
207/5:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
207/6: ilabel
207/7: item1
207/8: sub_df1
207/9: sub_df2
207/10: item2
207/11: idx2
207/12: df_MQHT[idx2]
207/13: df_MQHT
207/14: df_MQHT.iloc[164]
207/15:
rf = h5py.File('1500x266.hdf5','r')
data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
207/16: data_ready2use = []
207/17:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
207/18:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQSC[idx1]
    sub_df2 = df_MQSC[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
207/19:
for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQ['Tape'] == tapeNo1
    idx2  = df_LQ['Tape'] == tapeNo2
    if df_LQ[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx1])
    if df_LQ[idx2].shape[0] != 2 :
    print(item1,item2,i+2)
        print(df_LQ[idx2])
    sub_df1 = df_LQ[idx1]
    sub_df2 = df_LQ[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)

    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
207/20:
for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQ['Tape'] == tapeNo1
    idx2  = df_LQ['Tape'] == tapeNo2
    if df_LQ[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx1])
    if df_LQ[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx2])
    sub_df1 = df_LQ[idx1]
    sub_df2 = df_LQ[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)

    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
207/21:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2
    if df_HQHT_1[idx1_1].shape[0] == 2 and df_HQHT_1[idx2_1].shape[0] == 2:
        sub_df1 = df_HQHT_1[idx1_1]
        sub_df2 = df_HQHT_1[idx2_1]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L')
        matching_labels = np.string_(matching_labels)

        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    else :
        print(item1,item2,i+2)
        continue
207/22: data_ready2use = np.array(data_ready2use)
207/23: data_ready2use
207/24: data_ready2use[-1]
207/25: data_ready2use[-1]
207/26: import matplotlib.pyplot as plt
207/27: plt.imshow(data_ready2use[-1][0])
207/28: plt.imshow(data_ready2use[-1][0],cmap='gray')
207/29: plt.imshow(data_ready2use[-1][1],cmap='gray')
207/30: plt.imshow(data_ready2use[-1][2],cmap='gray')
207/31: plt.imshow(data_ready2use[-1][3],cmap='gray')
207/32: plt.imshow(data_ready2use[-2][3],cmap='gray')
207/33: plt.imshow(data_ready2use[-2][2],cmap='gray')
207/34: plt.imshow(data_ready2use[-2][1],cmap='gray')
207/35: plt.imshow(data_ready2use[-2][0],cmap='gray')
207/36: data_ready2use.shape
207/37: plt.imshow(data_ready2use[-200][0],cmap='gray')
207/38: plt.imshow(data_ready2use[-200][1],cmap='gray')
207/39: plt.imshow(data_ready2use[-200][2],cmap='gray')
207/40: plt.imshow(data_ready2use[-200][3],cmap='gray')
207/41: plt.imshow(data_ready2use[-800][3],cmap='gray')
207/42: plt.imshow(data_ready2use[-100][3],cmap='gray')
207/43: plt.imshow(data_ready2use[-100][1],cmap='gray')
207/44: plt.imshow(data_ready2use[-100][0],cmap='gray')
207/45: df_MQHT['Tape']
207/46: np.array(df_MQHT['Tape'])
207/47: np.array(df_MQHT['Tape']).sort()
207/48: np.array(df_MQHT['Tape'])
207/49: a = np.array(df_MQHT['Tape'])
207/50: a
207/51: a.sort()
207/52: a
207/53: data_ready2use
207/54: data_ready2use[200]
207/55: plt.imshow(data_ready2use[200][0],cmap='gray')
207/56: plt.imshow(data_ready2use[200][1],cmap='gray')
207/57: plt.imshow(data_ready2use[200][2],cmap='gray')
207/58: plt.imshow(data_ready2use[200][3],cmap='gray')
207/59: data
207/60: data.shape
207/61: 3542/4
207/62: plt.imshow(data[200],cmap='gray')
207/63: plt.imshow(data[201],cmap='gray')
207/64: plt.imshow(data[202],cmap='gray')
207/65: plt.imshow(data[203],cmap='gray')
207/66: plt.imshow(data[204],cmap='gray')
207/67: plt.imshow(data[205],cmap='gray')
207/68: plt.imshow(data[206],cmap='gray')
208/1:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('1500x266.hdf5','r')

data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
208/2: data_ready2use = []
208/3:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
208/4:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('1500x266.hdf5','r')

data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
208/5:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
208/6:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]
    
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQSC[idx1]
    sub_df2 = df_MQSC[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
208/7:
for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQ['Tape'] == tapeNo1
    idx2  = df_LQ['Tape'] == tapeNo2
    if df_LQ[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx1])
    if df_LQ[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx2])
    sub_df1 = df_LQ[idx1]
    sub_df2 = df_LQ[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)

    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
208/8:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2
    if df_HQHT_1[idx1_1].shape[0] == 2 and df_HQHT_1[idx2_1].shape[0] == 2:
        sub_df1 = df_HQHT_1[idx1_1]
        sub_df2 = df_HQHT_1[idx2_1]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L')
        matching_labels = np.string_(matching_labels)

        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    else :
        print(item1,item2,i+2)            
        continue
208/9: len(data_ready2use)
208/10: labels
208/11: labels.shape
208/12: data.shape
208/13: data[0]
208/14: np.random.randint?
208/15: np.random.randint(0,len(data))
208/16: np.random.randint(0,len(data),4)
208/17: np.random.randint(0,len(data),4)
208/18: data[np.random.randint(0,len(data),4)]
208/19:
ntrues = len(data_ready2use)
nfalse = ntrues
208/20:
for i in range(nfalse):
    idxs = np.random.randint(0,len(data),4)
    data_ready2use.append(data[idx])
208/21:
for i in range(nfalse):
    idx = np.random.randint(0,len(data),4)
    data_ready2use.append(data[idx])
208/22: import matplotlib.pyplot as plt
208/23: plt.imshow(data_ready2use[-1][0],cmap='gray')
208/24: `
208/25: plt.imshow(data_ready2use[-1][1],cmap='gray')
208/26: plt.imshow(data_ready2use[-1][2],cmap='gray')
208/27: plt.imshow(data_ready2use[-1][3],cmap='gray')
208/28: plt.imshow(data_ready2use[-1][0],cmap='gray')
208/29: matches = np.zeros(shape=(ntrues+nfalse,))
208/30: matches
208/31: matches[0:ntrues] = np.ones(shape=(ntrues))
208/32: matches
208/33: matches[ntrues]
208/34: matches[ntrues-1]
208/35: matches[0:ntrues] = np.ones(shape=(ntrues))
208/36: data.shape
208/37: del data
208/38: data
208/39: data_ready2use
208/40: data_ready2use = np.array(data_ready2use)
208/41: data_ready2use
208/42: data_ready2use.shape
209/1:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('1500x266.hdf5','r')

data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
209/2: pwd
209/3: cd ..
209/4: cd ..
209/5: ls
209/6: cd Automated_Algorithm_Photos/
209/7: ls
209/8: cd Scans/
209/9: ls
209/10: cd images/
209/11: ls
209/12: cd ML-convlolutional_net/
209/13: ls
209/14:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('1500x266.hdf5','r')

data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
209/15: data_ready2use = []
209/16:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
209/17:
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQSC[idx1]
    sub_df2 = df_MQSC[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
209/18:
for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQ['Tape'] == tapeNo1
    idx2  = df_LQ['Tape'] == tapeNo2
    if df_LQ[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx1])
    if df_LQ[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx2])
    sub_df1 = df_LQ[idx1]
    sub_df2 = df_LQ[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)

    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
209/19:
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2
    if df_HQHT_1[idx1_1].shape[0] == 2 and df_HQHT_1[idx2_1].shape[0] == 2:
        sub_df1 = df_HQHT_1[idx1_1]
        sub_df2 = df_HQHT_1[idx2_1]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L')
        matching_labels = np.string_(matching_labels)

        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    else :
        print(item1,item2,i+2)
        continue

ntrues = len(data_ready2use)
nfalse = ntrues

matches = np.zeros(shape=(ntrues+nfalse,))
matches[0:ntrues] = np.ones(shape=(ntrues))
data_ready2use = np.array(data_ready2use)


for i in range(nfalse):
    idx = np.random.randint(0,len(data),4)
    data_ready2use.append(data[idx])
210/1:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('1500x266.hdf5','r')

data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
210/2: data_ready2use = []
210/3:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQSC[idx1]
    sub_df2 = df_MQSC[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQ['Tape'] == tapeNo1
    idx2  = df_LQ['Tape'] == tapeNo2
    if df_LQ[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx1])
    if df_LQ[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx2])
    sub_df1 = df_LQ[idx1]
    sub_df2 = df_LQ[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)

    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2
    if df_HQHT_1[idx1_1].shape[0] == 2 and df_HQHT_1[idx2_1].shape[0] == 2:
        sub_df1 = df_HQHT_1[idx1_1]
        sub_df2 = df_HQHT_1[idx2_1]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L')
        matching_labels = np.string_(matching_labels)

        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    else :
        print(item1,item2,i+2)
        continue

ntrues = len(data_ready2use)
nfalse = ntrues

matches = np.zeros(shape=(ntrues+nfalse,))
matches[0:ntrues] = np.ones(shape=(ntrues))



for i in range(nfalse):
    idx = np.random.randint(0,len(data),4)
    data_ready2use.append(data[idx])

data_ready2use = np.array(data_ready2use)

# data_ready2use.shape  (396, 4, 1500, 266)
210/4:
def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        flat_1 = Flatten()(conv4_1)  # 11904 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        flat_2 = Flatten()(conv4_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        flat_3 = Flatten()(conv4_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        flat_4 = Flatten()(conv4_4)  # 11904 x 1

        layer1 = Concatenate([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(10000,activation='relu')(layer1)# 10000
        layer3 = Dense(1000,activation='relu')(layer2)# 1000
        layer4 = Dense(200,activation='relu')(layer3)#200
        layer5 = Dense(1,activation='sigmoid')(layer4)#1

        return layer5
210/5:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
210/6: from keras.layers import Input
210/7:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
210/8: autoencoder = Model(input_img, learner(input_img,iput_img,input_img,input_img))
210/9:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
210/10: input_img
210/11: autoencoder = Model(input_img, learner(input_img,iput_img,input_img,input_img))
210/12: iput_img
210/13: autoencoder = Model(input_img, learner(input_img,input_img,input_img,input_img))
210/14:
def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        flat_1 = Flatten()(conv4_1)  # 11904 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        flat_2 = Flatten()(conv4_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        flat_3 = Flatten()(conv4_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        flat_4 = Flatten()(conv4_4)  # 11904 x 1

        layer1 = Concatenate((flat_1,flat_2,flat_3,flat_4)) # 47616
        layer2 = Dense(10000,activation='relu')(layer1)# 10000
        layer3 = Dense(1000,activation='relu')(layer2)# 1000
        layer4 = Dense(200,activation='relu')(layer3)#200
        layer5 = Dense(1,activation='sigmoid')(layer4)#1

        return layer5
210/15:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
210/16: autoencoder = Model(input_img, learner(input_img,input_img,input_img,input_img))
210/17:
def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        flat_1 = Flatten()(conv4_1)  # 11904 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        flat_2 = Flatten()(conv4_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        flat_3 = Flatten()(conv4_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        flat_4 = Flatten()(conv4_4)  # 11904 x 1

        layer1 = Concatenate([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(10000,activation='relu')(layer1)# 10000
        layer3 = Dense(1000,activation='relu')(layer2)# 1000
        layer4 = Dense(200,activation='relu')(layer3)#200
        layer5 = Dense(1,activation='sigmoid')(layer4)#1

        return layer5
210/18: autoencoder = Model(input_img, learner(input_img,input_img,input_img,input_img))
210/19:
def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        flat_1 = Flatten()(conv4_1)  # 11904 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        flat_2 = Flatten()(conv4_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        flat_3 = Flatten()(conv4_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        flat_4 = Flatten()(conv4_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(10000,activation='relu')(layer1)# 10000
        layer3 = Dense(1000,activation='relu')(layer2)# 1000
        layer4 = Dense(200,activation='relu')(layer3)#200
        layer5 = Dense(1,activation='sigmoid')(layer4)#1

        return layer5
210/20:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
210/21: autoencoder = Model(input_img, learner(input_img,input_img,input_img,input_img))
210/22:
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
211/1:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQSC[idx1]
    sub_df2 = df_MQSC[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQ['Tape'] == tapeNo1
    idx2  = df_LQ['Tape'] == tapeNo2
    if df_LQ[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx1])
    if df_LQ[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx2])
    sub_df1 = df_LQ[idx1]
    sub_df2 = df_LQ[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)

    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2
    if df_HQHT_1[idx1_1].shape[0] == 2 and df_HQHT_1[idx2_1].shape[0] == 2:
        sub_df1 = df_HQHT_1[idx1_1]
        sub_df2 = df_HQHT_1[idx2_1]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L')
        matching_labels = np.string_(matching_labels)

        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    else :
        print(item1,item2,i+2)
        continue

ntrues = len(data_ready2use)
nfalse = ntrues

matches = np.zeros(shape=(ntrues+nfalse,))
matches[0:ntrues] = np.ones(shape=(ntrues))



for i in range(nfalse):
    idx = np.random.randint(0,len(data),4)
    data_ready2use.append(data[idx])

data_ready2use = np.array(data_ready2use)

# data_ready2use.shape  (396, 4, 1500, 266)
211/2:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.models import Model
from keras.optimizers import RMSprop

rf = h5py.File('1500x266.hdf5','r')

data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
211/3:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQSC[idx1]
    sub_df2 = df_MQSC[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQ['Tape'] == tapeNo1
    idx2  = df_LQ['Tape'] == tapeNo2
    if df_LQ[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx1])
    if df_LQ[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx2])
    sub_df1 = df_LQ[idx1]
    sub_df2 = df_LQ[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)

    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2
    if df_HQHT_1[idx1_1].shape[0] == 2 and df_HQHT_1[idx2_1].shape[0] == 2:
        sub_df1 = df_HQHT_1[idx1_1]
        sub_df2 = df_HQHT_1[idx2_1]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L')
        matching_labels = np.string_(matching_labels)

        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    else :
        print(item1,item2,i+2)
        continue

ntrues = len(data_ready2use)
nfalse = ntrues

matches = np.zeros(shape=(ntrues+nfalse,))
matches[0:ntrues] = np.ones(shape=(ntrues))



for i in range(nfalse):
    idx = np.random.randint(0,len(data),4)
    data_ready2use.append(data[idx])

data_ready2use = np.array(data_ready2use)

# data_ready2use.shape  (396, 4, 1500, 266)
211/4: data_ready2use = []
211/5:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQSC[idx1]
    sub_df2 = df_MQSC[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQ['Tape'] == tapeNo1
    idx2  = df_LQ['Tape'] == tapeNo2
    if df_LQ[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx1])
    if df_LQ[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx2])
    sub_df1 = df_LQ[idx1]
    sub_df2 = df_LQ[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)

    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2
    if df_HQHT_1[idx1_1].shape[0] == 2 and df_HQHT_1[idx2_1].shape[0] == 2:
        sub_df1 = df_HQHT_1[idx1_1]
        sub_df2 = df_HQHT_1[idx2_1]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L')
        matching_labels = np.string_(matching_labels)

        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    else :
        print(item1,item2,i+2)
        continue

ntrues = len(data_ready2use)
nfalse = ntrues

matches = np.zeros(shape=(ntrues+nfalse,))
matches[0:ntrues] = np.ones(shape=(ntrues))



for i in range(nfalse):
    idx = np.random.randint(0,len(data),4)
    data_ready2use.append(data[idx])

data_ready2use = np.array(data_ready2use)

# data_ready2use.shape  (396, 4, 1500, 266)
211/6:
def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        flat_1 = Flatten()(conv4_1)  # 11904 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        flat_2 = Flatten()(conv4_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        flat_3 = Flatten()(conv4_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        flat_4 = Flatten()(conv4_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(10000,activation='relu')(layer1)# 10000
        layer3 = Dense(1000,activation='relu')(layer2)# 1000
        layer4 = Dense(200,activation='relu')(layer3)#200
        layer5 = Dense(1,activation='sigmoid')(layer4)#1

        return layer5
211/7:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
211/8: from keras.layers import Input
211/9:
def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        flat_1 = Flatten()(conv4_1)  # 11904 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        flat_2 = Flatten()(conv4_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        flat_3 = Flatten()(conv4_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        flat_4 = Flatten()(conv4_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(10000,activation='relu')(layer1)# 10000
        layer3 = Dense(1000,activation='relu')(layer2)# 1000
        layer4 = Dense(200,activation='relu')(layer3)#200
        layer5 = Dense(1,activation='sigmoid')(layer4)#1

        return layer5
211/10:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
211/11:
autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())
autoencoder.summary()
211/12:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
model = Model(input_img, learner(input_img,input_img,input_img,input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
211/13:

def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        flat_1 = Flatten()(pool4_1)  # 11904 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        flat_2 = Flatten()(pool4_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        flat_3 = Flatten()(pool4_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        flat_4 = Flatten()(pool4_4)  # 11904 x 1

        layer1 = Concatenate([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(10000,activation='relu')(layer1)# 10000
        layer3 = Dense(1000,activation='relu')(layer2)# 1000
        layer4 = Dense(200,activation='relu')(layer3)#200
        layer5 = Dense(1,activation='sigmoid')(layer4)#1
        
        return layer5
211/14:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
model = Model(input_img, learner(input_img,input_img,input_img,input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
211/15:
def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        flat_1 = Flatten()(pool4_1)  # 11904 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        flat_2 = Flatten()(pool4_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        flat_3 = Flatten()(pool4_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        flat_4 = Flatten()(pool4_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(10000,activation='relu')(layer1)# 10000
        layer3 = Dense(1000,activation='relu')(layer2)# 1000
        layer4 = Dense(200,activation='relu')(layer3)#200
        layer5 = Dense(1,activation='sigmoid')(layer4)#1
        
        return layer5
211/16:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
model = Model(input_img, learner(input_img,input_img,input_img,input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
211/17:
def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
    conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        flat_1 = Flatten()(pool5_1)  # 11904 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        flat_2 = Flatten()(pool5_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        flat_3 = Flatten()(pool5_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        flat_4 = Flatten()(pool5_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(10000,activation='relu')(layer1)# 10000
        layer3 = Dense(1000,activation='relu')(layer2)# 1000
        layer4 = Dense(200,activation='relu')(layer3)#200
        layer5 = Dense(1,activation='sigmoid')(layer4)#1
        
        return layer5
211/18:
def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        flat_1 = Flatten()(pool5_1)  # 11904 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        flat_2 = Flatten()(pool5_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        flat_3 = Flatten()(pool5_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        flat_4 = Flatten()(pool5_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(10000,activation='relu')(layer1)# 10000
        layer3 = Dense(1000,activation='relu')(layer2)# 1000
        layer4 = Dense(200,activation='relu')(layer3)#200
        layer5 = Dense(1,activation='sigmoid')(layer4)#1
        
        return layer5
211/19:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
model = Model(input_img, learner(input_img,input_img,input_img,input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
211/20:
def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(10000,activation='relu')(layer1)# 10000
        layer3 = Dense(1000,activation='relu')(layer2)# 1000
        layer4 = Dense(200,activation='relu')(layer3)#200
        layer5 = Dense(1,activation='sigmoid')(layer4)#1
        
        return layer5
211/21:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
model = Model(input_img, learner(input_img,input_img,input_img,input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
211/22:
def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1)# 10000
        layer3 = Dense(1000,activation='relu')(layer2)# 1000
        layer4 = Dense(200,activation='relu')(layer3)#200
        layer5 = Dense(1,activation='sigmoid')(layer4)#1
        
        return layer5
211/23:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
model = Model(input_img, learner(input_img,input_img,input_img,input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
211/24: from sklearn.model_selection import train_test_split
211/25:
def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1)# 10000
        layer3 = Dense(1000,activation='relu')(layer2)# 1000
        layer4 = Dense(1000,activation='relu')(layer2)# 1000
        layer5 = Dense(200,activation='relu')(layer3)#200
        layer6 = Dense(1,activation='sigmoid')(layer4)#1
        
        return layer6
211/26:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
model = Model(input_img, learner(input_img,input_img,input_img,input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
211/27:
def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1)# 10000
        layer3 = Dense(1000,activation='relu')(layer2)# 1000
        layer4 = Dense(1000,activation='relu')(layer3)# 1000
        layer5 = Dense(200,activation='relu')(layer4)#200
        layer6 = Dense(1,activation='sigmoid')(layer5)#1
        
        return layer6
211/28:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
model = Model(input_img, learner(input_img,input_img,input_img,input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
211/29:
train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,
                                                                                   train_data_procar,
                                                                                   test_size=0.2,
                                                                                   random_state=13)
211/30: data_ready2use.shape
211/31:
train_X_data,valid_X_data,train_ground_matches,valid_ground_matches = train_test_split(data_ready2use,
                                                                                   matches,
                                                                                   test_size=0.2,
                                                                                   random_state=13)
211/32: autoencoder_train = autoencoder.fit(train_X_data, train_ground_matches, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_data, valid_ground_matches))
211/33: autoencoder_train = model.fit(train_X_data, train_ground_matches, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_data, valid_ground_matches))
211/34: data_ready2use.shape
211/35: data_ready2use.reshape(-1,-1,-1,-1,1)
211/36: data_ready2use.reshape(798,4,1500,266,1)
211/37: data_ready2use.reshape(798,4,1500,266,1)[0]
211/38: import matplotlib.pylab as plt
211/39: plt.imshow(data_ready2use.reshape(798,4,1500,266,1)[0])
211/40: data_ready2use.reshape(798,4,1500,266,1)[0]
211/41: data_ready2use.reshape(798,4,1500,266,1).shape
211/42: data_ready2use.reshape(798,4,1500,266,1)[0].shape
211/43: data_ready2use.reshape(798,4,1500,266,1)[0][0].shape
211/44: data_ready2use.reshape(798,4,1500,266,1)[0][0][:,:,0].shape
211/45: plt.imshow(data_ready2use.reshape(798,4,1500,266,1)[0][0][:,:,0])
211/46: plt.imshow(data_ready2use.reshape(798,4,1500,266,1)[0][0][:,:,0],cmap='gray')
211/47: data_ready2use = data_ready2use.reshape(798,4,1500,266,1)
211/48: train_X_elf,valid_X_elf,train_ground_procar,valid_ground_procar = train_test_split(train_data_elf,train_data_procar,test_size=0.2,random_state=13)
211/49:
train_X_data,valid_X_data,train_ground_matches,valid_ground_matches = train_test_split(data_ready2use,
                                                                                   matches,
                                                                                   test_size=0.2,
                                                                                   random_state=13)
211/50: train_X_data,valid_X_data,train_ground_matches,valid_ground_matches = train_test_split(data_ready2use, matches,test_size=0.2, random_state=13)
211/51: autoencoder_train = model.fit(train_X_data, train_ground_matches, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_data, valid_ground_matches))
211/52:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
211/53:
def learner([img1,img2,img3,img4]): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
211/54:
def learner((img1,img2,img3,img4)): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
212/1:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.layers import Input
from keras.models import Model

from keras.optimizers import RMSprop

rf = h5py.File('1500x266.hdf5','r')

data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn')
212/2:
data_ready2use = []

for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQSC[idx1]
    sub_df2 = df_MQSC[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQ['Tape'] == tapeNo1
    idx2  = df_LQ['Tape'] == tapeNo2
    if df_LQ[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx1])
    if df_LQ[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx2])
    sub_df1 = df_LQ[idx1]
    sub_df2 = df_LQ[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)

    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2
    if df_HQHT_1[idx1_1].shape[0] == 2 and df_HQHT_1[idx2_1].shape[0] == 2:
        sub_df1 = df_HQHT_1[idx1_1]
        sub_df2 = df_HQHT_1[idx2_1]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L')
        matching_labels = np.string_(matching_labels)

        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    else :
        print(item1,item2,i+2)
        continue

ntrues = len(data_ready2use)
nfalse = ntrues

matches = np.zeros(shape=(ntrues+nfalse,))
matches[0:ntrues] = np.ones(shape=(ntrues))



for i in range(nfalse):
    idx = np.random.randint(0,len(data),4)
    data_ready2use.append(data[idx])

data_ready2use = np.array(data_ready2use)

# data_ready2use.shape  (396, 4, 1500, 266)
212/3:

def learner([img1,img2,img3,img4]): # 4 x 1500 x 266 x 1 each image
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1

        return layer6
212/4:

def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1

        return layer6
212/5:

data_ready2use = data_ready2use.reshape(798,4,1500,266,1)


batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()

from sklearn.model_selection import train_test_split
train_X_data,valid_X_data,train_ground_matches,valid_ground_matches = train_test_split(data_ready2use, matches,test_size=0.2, random_state=13)
   1:
import h5py
import numpy as np
import pandas as pd
from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Reshape, Concatenate
from keras.layers import Input
from keras.models import Model

from keras.optimizers import RMSprop

rf = h5py.File('1500x266.hdf5','r')

data = rf['data'][:]
labels = rf['labels'][:]
df_LQ = pd.read_excel('Automated_Algorithm_Scans.xlsx','Low Quality')
df_MQHT = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQHT')
df_MQSC = pd.read_excel('Automated_Algorithm_Scans.xlsx','MQSC')
df_HQHT_C = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set C')
df_HQHT_1 = pd.read_excel('Automated_Algorithm_Scans.xlsx','HQHT - Set 1')
df_matches_MQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Hand_Torn')
df_matches_MQSC = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Mid-Quality_Scissor_Cut')
df_matches_HQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','High-Quality_Hand_Torn')
df_matches_LQHT = pd.read_excel('Duct_Tape_True_Matches_all_sets.xlsx','Low-Quality_Hand_Torn') 

data_ready2use = []
   2:
for i in range(df_matches_MQHT.shape[0]):
    item1 = df_matches_MQHT.iloc[i][0]
    item2 = df_matches_MQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQHT['Tape'] == tapeNo1
    idx2  = df_MQHT['Tape'] == tapeNo2
    if df_MQHT[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx1])
        continue
    if df_MQHT[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQHT[idx2])
        continue
    sub_df1 = df_MQHT[idx1]
    sub_df2 = df_MQHT[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
        
                                                    
for i in range(df_matches_MQSC.shape[0]):
    item1 = df_matches_MQSC.iloc[i][0]
    item2 = df_matches_MQSC.iloc[i][1]
    
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_MQSC['Tape'] == tapeNo1
    idx2  = df_MQSC['Tape'] == tapeNo2
    if df_MQSC[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx1])
        continue
    if df_MQSC[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_MQSC[idx2])
        continue
    sub_df1 = df_MQSC[idx1]
    sub_df2 = df_MQSC[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)
    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))


for i in range(df_matches_LQHT.shape[0]):
    item1 = df_matches_LQHT.iloc[i][0]
    item2 = df_matches_LQHT.iloc[i][1]

    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1  = df_LQ['Tape'] == tapeNo1
    idx2  = df_LQ['Tape'] == tapeNo2
    if df_LQ[idx1].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx1])
    if df_LQ[idx2].shape[0] != 2 :
        print(item1,item2,i+2)
        print(df_LQ[idx2])
    sub_df1 = df_LQ[idx1]
    sub_df2 = df_LQ[idx2]

    matching_labels = []
    for j in range(2):
        if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
        if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
        else :
            matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
    matching_labels = np.string_(matching_labels)

    data_matched = []
    for ilabel in matching_labels :
        data_matched.append(data[labels == ilabel][0])
    data_ready2use.append(np.array(data_matched))
                            
                                                                        
for i in range(df_matches_HQHT.shape[0]):
    item1 = df_matches_HQHT.iloc[i][0]
    item2 = df_matches_HQHT.iloc[i][1]
    tapeNo1 = float(item1[:-1])
    tapeNo2 = float(item2[:-1])
    idx1_1  = df_HQHT_1['Tape'] == tapeNo1
    idx2_1  = df_HQHT_1['Tape'] == tapeNo2
    idx1_C  = df_HQHT_C['Tape'] == tapeNo1
    idx2_C  = df_HQHT_C['Tape'] == tapeNo2
    if df_HQHT_1[idx1_1].shape[0] == 2 and df_HQHT_1[idx2_1].shape[0] == 2:
        sub_df1 = df_HQHT_1[idx1_1]
        sub_df2 = df_HQHT_1[idx2_1]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Left Edge'] == item1[-1]:
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R')
            if sub_df2.iloc[j]['Left Edge'] == item2[-1]:
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R')
        matching_labels = np.string_(matching_labels)
        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    elif df_HQHT_C[idx1_C].shape[0] == 2 or df_HQHT_C[idx2_C].shape[0] == 2:
        sub_df1 = df_HQHT_C[idx1_C]
        sub_df2 = df_HQHT_C[idx2_C]
        matching_labels = []
        for j in range(2):
            if sub_df1.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df1.iloc[j]['Scan Name']+'_L')
            if sub_df2.iloc[j]['Obvious Cut'] == 'Left':
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_R' )
            else :
                matching_labels.append(sub_df2.iloc[j]['Scan Name']+'_L')
        matching_labels = np.string_(matching_labels)

        data_matched = []
        for ilabel in matching_labels :
            data_matched.append(data[labels == ilabel][0])
        data_ready2use.append(np.array(data_matched))
    else :
        print(item1,item2,i+2)            
        continue
    
ntrues = len(data_ready2use)
nfalse = ntrues

matches = np.zeros(shape=(ntrues+nfalse,))
matches[0:ntrues] = np.ones(shape=(ntrues))



for i in range(nfalse):
    idx = np.random.randint(0,len(data),4)
    data_ready2use.append(data[idx])

data_ready2use = np.array(data_ready2use)
   3:
def learner(img1,img2,img3,img4): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
   4:
def learner(array): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        img1,img2,img3,img4 = array[0],array[1],array[2],array[3]
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
   5: data_ready2use = data_ready2use.reshape(798,4,1500,266,1)
   6:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
   7:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
   8:
def learner(array): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        
        img1,img2,img3,img4 = array[0],array[1],array[2],array[3]
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
   9: from keras.layers import Lambda
  10:
def learner(array): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        img1 = Lambda(lamba x: x[0])(array)
        img2 = Lambda(lamba x: x[1])(array)
        img3 = Lambda(lamba x: x[2])(array)
        img4 = Lambda(lamba x: x[3])(array)

        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
  11:
def learner(array): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        img1 = Lambda(lambda x: x[0])(array)
        img2 = Lambda(lambda x: x[1])(array)
        img3 = Lambda(lambda x: x[2])(array)
        img4 = Lambda(lambda x: x[3])(array)

        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
  12:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  13: from sklearn.model_selection import train_test_split
  14: train_X_data,valid_X_data,train_ground_matches,valid_ground_matches = train_test_split(data_ready2use, matches,test_size=0.2, random_state=13)
  15: autoencoder_train = model.fit(train_X_data, train_ground_matches, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_data, valid_ground_matches))
  16:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = 'sgd')
model.summary()
  17: autoencoder_train = model.fit(train_X_data, train_ground_matches, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_data, valid_ground_matches))
  18: train_ground_matches.shape
  19: train_ground_matches
  20: train_X_data.shape
  21:
def learner(array): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        img1 = Lambda(lambda x: x[0])(array)
        img2 = Lambda(lambda x: x[1])(array)
        img3 = Lambda(lambda x: x[2])(array)
        img4 = Lambda(lambda x: x[3])(array)
        print(img1.shape)
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
  22: autoencoder_train = model.fit(train_X_data, train_ground_matches, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_data, valid_ground_matches))
  23:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  24: autoencoder_train = model.fit(train_X_data, train_ground_matches, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_data, valid_ground_matches))
  25: train_X_data.shape
  26: train_X_data[0]
  27: train_X_data[0].shape
  28: (lambda x: x[0])(train_X_data[0])
  29: a = (lambda x: x[0])(train_X_data[0])
  30: a.shape
  31: a = (lambda x: x[2])(train_X_data[0])
  32: a
  33: a.shape
  34: a[:,:,0]
  35: a[0]
  36:
batch_size = 20
epochs = 1
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  37: autoencoder_train = model.fit(train_X_data, train_ground_matches, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_data, valid_ground_matches))
  38:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  39:
def learner(array): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        img1 = Lambda(lambda x: x[0][0])(array)
        img2 = Lambda(lambda x: x[1][0])(array)
        img3 = Lambda(lambda x: x[2][0])(array)
        img4 = Lambda(lambda x: x[3][0])(array)
        print(img1.shape)
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
  40:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  41:
def learner(array): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        img1 = Lambda(lambda x: x[0])(array)
        img2 = Lambda(lambda x: x[1])(array)
        img3 = Lambda(lambda x: x[2])(array)
        img4 = Lambda(lambda x: x[3])(array)
        print(img1.shape)
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
  42:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  43: a.shape
  44:
def learner(array): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        img1 = Lambda(lambda x: x[0][1])(array)
        img2 = Lambda(lambda x: x[1])(array)
        img3 = Lambda(lambda x: x[2])(array)
        img4 = Lambda(lambda x: x[3])(array)
        print(img1.shape)
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
  45:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  46:
def learner(array): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        img1 = Lambda(lambda x: x[0][0])(array)
        img2 = Lambda(lambda x: x[0][1])(array)
        img3 = Lambda(lambda x: x[0][2])(array)
        img4 = Lambda(lambda x: x[0][3])(array)
        print(img1.shape)
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
  47:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  48:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  49:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  50:
def learner(array): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        img1 = Lambda(lambda x: x[0][0])(array)
        img2 = Lambda(lambda x: x[0][1])(array)
        img3 = Lambda(lambda x: x[0][2])(array)
        img4 = Lambda(lambda x: x[0][3])(array)
        print(img1)
        print(array.shape)
        
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
  51:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  52: a
  53: data_ready2use = data_ready2use.reshape(-1,4,1500,266,1)
  54: data_ready2use.shape
  55:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  56:
def learner(array): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        img1 = Lambda(lambda x: x[0])(array)
        img2 = Lambda(lambda x: x[1])(array)
        img3 = Lambda(lambda x: x[2])(array)
        img4 = Lambda(lambda x: x[3])(array)
        print(img1)
        print(array.shape)
        
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
  57:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  58:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  59: autoencoder_train = model.fit(train_X_data, train_ground_matches, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_data, valid_ground_matches))
  60: a = (lambda x: x[2])(train_X_data[0])
  61:
def learner(array): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        img1 = Lambda(lambda x: x[0])(array)
        img2 = Lambda(lambda x: x[1])(array)
        img3 = Lambda(lambda x: x[2])(array)
        img4 = Lambda(lambda x: x[3])(array)
        print(array.shape)
        print(img1.shape)
        
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
  62:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  63:
def learner(array): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        img1 = Lambda(lambda x: x[:][0])(array)
        img2 = Lambda(lambda x: x[:][1])(array)
        img3 = Lambda(lambda x: x[:][2])(array)
        img4 = Lambda(lambda x: x[:][3])(array)
        print(array.shape)
        print(img1.shape)
        
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
  64:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  65:
def learner(array): # 4 x 1500 x 266 x 1 each image 
        #encoder
        #in put = 1500 x 266 x 2
        img1 = Lambda(lambda x: x[:,0,:,:])(array)
        img2 = Lambda(lambda x: x[:,1,:,:])(array)
        img3 = Lambda(lambda x: x[:,2,:,:])(array)
        img4 = Lambda(lambda x: x[:,3,:,:])(array)
        print(array.shape)
        print(img1.shape)
        
        conv1_1 = Conv2D(16, (3,3), activation='relu', padding='same')(img1) # 1500 x 266 x 16
        pool1_1 = MaxPooling2D(pool_size=(2,2))(conv1_1) # 750 x 133 x 16
        conv2_1 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_1) # 750 x 133 x 8
        pool2_1 = MaxPooling2D(pool_size=(2,2))(conv2_1) # 375 x 66 x 8
        conv3_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_1) # 375 x 66x 8
        pool3_1 = MaxPooling2D(pool_size=(2,2))(conv3_1) # 187 x 33 x 8
        conv4_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_1) # 187x  33 x 8 
        pool4_1 = MaxPooling2D(pool_size=(2,2))(conv4_1) # 93 x 16 x 8
        conv5_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_1) # 93x16 x 8
        pool5_1 = MaxPooling2D(pool_size=(2,2))(conv5_1) # 46 x 8  x 8
        conv6_1 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_1) # 46 x 8 x 8
        pool6_1 = MaxPooling2D(pool_size=(2,2))(conv6_1) # 23 x 4  x 8
        flat_1 = Flatten()(pool6_1)  # 736 x 1

        conv1_2 = Conv2D(16, (3,3), activation='relu', padding='same')(img2) # 1500 x 266 x 16
        pool1_2 = MaxPooling2D(pool_size=(2,2))(conv1_2) # 750 x 133 x 16
        conv2_2 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_2) # 750 x 133 x 8
        pool2_2 = MaxPooling2D(pool_size=(2,2))(conv2_2) # 375 x 66 x 8
        conv3_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_2) # 375 x 66x 8
        pool3_2 = MaxPooling2D(pool_size=(2,2))(conv3_2) # 187 x 33 x 8
        conv4_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_2) # 187x  33 x 8 
        pool4_2 = MaxPooling2D(pool_size=(2,2))(conv4_2) # 93 x 16 x 8
        conv5_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_2) # 187x  33 x 8
        pool5_2 = MaxPooling2D(pool_size=(2,2))(conv5_2) # 93 x 16 x 8
        conv6_2 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_2) # 46 x 8 x 8
        pool6_2 = MaxPooling2D(pool_size=(2,2))(conv6_2) # 23 x 4  x 8
        flat_2 = Flatten()(pool6_2)  # 11904 x 1

        conv1_3 = Conv2D(16, (3,3), activation='relu', padding='same')(img3) # 1500 x 266 x 16
        pool1_3 = MaxPooling2D(pool_size=(2,2))(conv1_3) # 750 x 133 x 16
        conv2_3 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_3) # 750 x 133 x 8
        pool2_3 = MaxPooling2D(pool_size=(2,2))(conv2_3) # 375 x 66 x 8
        conv3_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_3) # 375 x 66x 8
        pool3_3 = MaxPooling2D(pool_size=(2,2))(conv3_3) # 187 x 33 x 8
        conv4_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_3) # 187x  33 x 8 
        pool4_3 = MaxPooling2D(pool_size=(2,2))(conv4_3) # 93 x 16 x 8
        conv5_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_3) # 187x  33 x 8
        pool5_3 = MaxPooling2D(pool_size=(2,2))(conv5_3) # 93 x 16 x 8
        conv6_3 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_3) # 46 x 8 x 8
        pool6_3 = MaxPooling2D(pool_size=(2,2))(conv6_3) # 23 x 4  x 8
        flat_3 = Flatten()(pool6_3)  # 11904 x 1

        conv1_4 = Conv2D(16, (3,3), activation='relu', padding='same')(img4) # 1500 x 266 x 16
        pool1_4 = MaxPooling2D(pool_size=(2,2))(conv1_4) # 750 x 133 x 16
        conv2_4 = Conv2D(8, (3, 3), activation='relu', padding='same')(pool1_4) # 750 x 133 x 8
        pool2_4 = MaxPooling2D(pool_size=(2,2))(conv2_4) # 375 x 66 x 8
        conv3_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool2_4) # 375 x 66x 8
        pool3_4 = MaxPooling2D(pool_size=(2,2))(conv3_4) # 187 x 33 x 8
        conv4_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool3_4) # 187x  33 x 8 
        pool4_4 = MaxPooling2D(pool_size=(2,2))(conv4_4) # 93 x 16 x 8
        conv5_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool4_4) # 187x  33 x 8
        pool5_4 = MaxPooling2D(pool_size=(2,2))(conv5_4) # 93 x 16 x 8
        conv6_4 = Conv2D(8, ( 3,3), activation='relu', padding='same')(pool5_4) # 46 x 8 x 8
        pool6_4 = MaxPooling2D(pool_size=(2,2))(conv6_4) # 23 x 4  x 8
        flat_4 = Flatten()(pool6_4)  # 11904 x 1

        layer1 = Concatenate()([flat_1,flat_2,flat_3,flat_4]) # 47616
        layer2 = Dense(1000,activation='relu')(layer1) # 10000
        layer3 = Dense(1000,activation='relu')(layer2) # 1000
        layer4 = Dense(1000,activation='relu')(layer3) # 1000
        layer5 = Dense(200,activation='relu')(layer4)  # 200
        layer6 = Dense(1,activation='sigmoid')(layer5) # 1
        
        return layer6
  66:
batch_size = 20
epochs = 50
inChannel = 1
input_img = Input(shape = (4,1500,266, inChannel))
model = Model(input_img, learner(input_img))
model.compile(loss='mean_squared_error', optimizer = RMSprop())
model.summary()
  67: autoencoder_train = model.fit(train_X_data, train_ground_matches, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_data, valid_ground_matches))
  68: autoencoder_train.predict?
  69: model.predict(valid_X_data)
  70: pred = model.predict(valid_X_data)
  71: pred
  72: valid_ground_matches
  73: pred1 = model.predict(train_X_data)
  74: pred1
  75: from keras import backend as K
  76: model.layers
  77: model.layers[20]
  78: get_mid_layer = K.function([model.layers[0].input],[model.layers[20].output])
  79: layer_out = get_mid_layer(valid_X_data)
  80: layer_out
  81: layer_out[0]
  82: layer_out[0][0]
  83: layer_out[0][0].shape
  84: layer_out[0][0].reshape(-1,66)
  85: import matplotlib.pylab as plt
  86: plt.imshow(layer_out[0][0].reshape(-1,66))
  87: plt.imshow(layer_out[0][0].reshape(-1,66),cmap='gray')
  88: model.layers[40]
  89: model.layers[41]
  90: model.layers[42]
  91: model.layers[43]
  92: model.layers[44]
  93: model.layers[45]
  94: model.layers[50]
  95: model.layers[60]
  96: model.layers[59]
  97: model.layers[58]
  98: model.layers[55]
  99: model.layers[52]
 100: model.layers[53]
 101: model.layers[52]
 102: get_mid_layer = K.function([model.layers[0].input],[model.layers[52].output])
 103: get_mid_layer = K.function([model.layers[0].input],[model.layers[52].output])
 104: layer_out = get_mid_layer(valid_X_data)
 105: layer_out[0][0].shape
 106: layer_out[0][0]
 107: layer_out[0][0].shape
 108: 23*4*8
 109: 14*14
 110: 30*30
 111: layer_out[0][0].reshape(-1,30)
 112: layer_out[0][0].reshape(-1,32)
 113: plt.imshow(layer_out[0][0].reshape(-1,32))
 114: plt.imshow(layer_out[0][0].reshape(-1,32),cmap='gray')
 115: plt.imshow(valid_X_data[0][3],cmap='gray')
 116: plt.imshow(valid_X_data[0][3][:,:,0],cmap='gray')
 117: plt.imshow(layer_out[0][0].reshape(-1,32),cmap='gray')
 118: plt.imshow(valid_X_data[0][3][:,:,0],cmap='gray')
 119: plt.imshow(layer_out[0][0].reshape(-1,32),cmap='gray')
 120: plt.imshow(layer_out[0][0].reshape(-1,32),cmap='gray')
 121: plt.imshow(layer_out[0][0].reshape(-1,4),cmap='gray')
 122: %history
 123: %history -g -f history
