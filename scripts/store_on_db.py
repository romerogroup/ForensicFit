#!/usr/bin/env python3

""" This script takes a metadata file generated by the script 
``create_metadata.py`` and stores all the images listed in that file
stores them in a MongoDB using GridFS.
"""

import os
from typing import Any, List, Dict, Union
from pathlib import Path
import json
import multiprocessing
from multiprocessing import Pool, cpu_count, current_process
import sys
import inspect
import argparse
from unicodedata import name

from numpy import insert
from .core import Tape
from .database import Database
from .utils.image_tools import IMAGE_EXTENSIONS


def get_chunks(files: List[Dict], n_processors: int) -> List[List[Dict]]:
    """divides list of files for multiprocessing

    Parameters
    ----------
    files : List[Dict]
        list of files in a dictionary format
    n_processors : int
        number of processors for Pool

    Returns
    -------
    List[List[Dict]]


    """
    
    ret = [ [] for x in range(n_processors)]
    n_files = len(files)
    for i, ifile in enumerate(files):
        ret[i % n_processors].append(ifile)
    return ret

def worker(args: Dict):
    """inserts images provided in the list to the MongoDB

    connects to a MongoDB, loads the images provided in the args, and 
    inserts them in the DB.

    Parameters
    ----------
    args : Dict
        dictionary containing the files, the database settings, and
        the inser options (skip, overwrite, etc)

    """
    
    files = args['files'] 
    db_settings = args['db_settings']
    insert_options = args['insert_options']
    db = Database(**db_settings)
    for _, entry in enumerate(files):
        file_path = Path(entry['source'])
        if not file_path.exists():
            print(f"{file_path.as_posix()} does not exist")
            return 
        if file_path.suffix not in IMAGE_EXTENSIONS:
            continue
        tape = Tape.from_file(file_path)
        # print(f"{file_path.stem}")
        for key in entry:
            tape.metadata[key] = entry[key]
        db.insert(tape, **insert_options)
        
def store_on_db(
        metadata_file: Union[str, Path],
        db_name: str,
        host:str ='localhost',
        port: int=27017,
        username: str="",
        password:str ="",
        n_processors: int=1,
        overwrite: bool=False,
        skip: bool=True):
    """given a metadata file about images, stores them on a database.

    Given a metadata file generated by create_metadata.py, it divides
    them into chunks, passes them to multiple processors, and inserts
    them on a MongoDB

    Parameters
    ----------
    metadata_file : Union[str, Path]
        Metadata file generated by ``create_metadata.py``
    db_name : str
        Name of the MongoDB to be stored on.
    host : str
        Address to the host of the MongoDB server.
    port : int
        Port of the MongoDB host
    username : str
        User name for the MongoDB host
    password : str
        Password for the MongoDB host
    n_processors : int
        Number of processors to be used.
    overwrite : bool
        If the file already exists, overwrite or create a new one
    skip : bool
        If the file already exists on the DB, skip or not.

    """

    if n_processors > cpu_count():
        n_processors = cpu_count()
        
    if metadata_file is not None:
        with open(metadata_file, 'r') as rf:
            metadata = json.load(rf)
    else:
        dir_path = Path(dir_path)
        
        metadata = get_files(dir_path)
    chunks = get_chunks(metadata, n_processors)
    
    db_settings = dict(name=db_name,
                       host=host,
                       port=port,
                       username=username,
                       password=password)
    insert_options = dict(ext=ext,
                          overwrite=overwrite,
                          skip=skip)
    
    args = [{
            'files': x,
            'db_settings': db_settings,
            'insert_options': insert_options,
        } for x in chunks]
    with Pool(n_processors) as p:
        p.map(worker, iterable=args)


# TODO add if __name_ == '__main__'    
